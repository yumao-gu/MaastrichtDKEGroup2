{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import uniform, normal\n",
    "from Auxillaries import *\n",
    "import math\n",
    "import datetime\n",
    "from ConfidenceIntervals import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Model to be fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Design of Model/Likelihood function to bet fitted\n",
    "'''\n",
    "def LogLikelihood(theta, x):\n",
    "\n",
    "    '''\n",
    "    This is the (log-)likelihood function that is supposed to be fitted. Note that this is the (log-)likelihood w.r.t.\n",
    "    one data point X_i. Thus, in later calculations like gradient ascent updates, the average of this function will be considered.\n",
    "    This can easily achieved by torch.mean(LogLikelihood(theta, X)) where X is the complete data set (X_1, ..., X_n).\n",
    "\n",
    "    Info:\n",
    "        - phi_torch(x, mu, sigma) gives the value of a density of a N(mu,sigma)-random variable at point x\n",
    "\n",
    "    Arguments:\n",
    "        - theta: parameter vector that needs to altered to fit the model\n",
    "        - x: a datapoint or a data set: the output will have the same dimensions as this\n",
    "\n",
    "    Output:\n",
    "        - model log-likelihood of theta given x // element-wise on x\n",
    "\n",
    "    '''\n",
    "\n",
    "    g_theta = (1-theta[0, 0])*phi_torch(x, 0, 0.2) + theta[0, 0]*phi_torch(x, theta[0, 1], 0.2)\n",
    "    log_g_theta = torch.log(g_theta)\n",
    "\n",
    "    return log_g_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create data of a gaussian mixture model\n",
    "'''\n",
    "# Specify parameters for mixture gaussian model\n",
    "weights = [.5, .45, .05]\n",
    "means = [[0.], [.75],[ 3.]]\n",
    "covs = [[.2**2], [.2**2], [.2**2]]\n",
    "n = 10**6\n",
    "\n",
    "# Create sampels of given model\n",
    "X = gaussian_mixture_model_sample(n, means, covs, weights, test=False) # we can alternatively use pytorchs MixtureFamily\n",
    "X = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contourplot of LogLikelihood-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Colourplot...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Creating Contourlpot of likelihood function in dependence of parameters \n",
    "'''\n",
    "# TODO: This is not well developed to be used for any setting: it needs limits for the parameters, works only for 2D, ... etc.\n",
    "make_Contourplot = False\n",
    "make_plots = True\n",
    "ticks = 5000\n",
    "\n",
    "if make_Contourplot:\n",
    "    print('Creating Colourplot...')\n",
    "    x_lin = np.linspace(0, 5, ticks)  # range for mu\n",
    "    y_lin = np.linspace(0, 0.6, ticks) # range for rho\n",
    "\n",
    "    #Colourplot = np.zeros((ticks, ticks))\n",
    "    Colourplot = torch.zeros(ticks, ticks)\n",
    "\n",
    "    for i in reversed(range(ticks)):\n",
    "        for j in range(ticks):\n",
    "            x = x_lin[j]\n",
    "            y = y_lin[ticks - i - 1]\n",
    "            #params = np.array([[y,x]])\n",
    "            params = torch.tensor([[y,x]])\n",
    "            Likelihoods = LogLikelihood(params, X) # dim 1xn\n",
    "            L_value = torch.mean(Likelihoods, axis = 1) # dim 1xn\n",
    "            Colourplot[i, j] = L_value\n",
    "\n",
    "    np.save('Contourmatrix', Colourplot)\n",
    "else:\n",
    "    print('Loading Colourplot...')\n",
    "    Colourplot = np.load('Contourmatrix.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth via epsilon netting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1434, 1040) 0.427885577115423 1.0402080416083217\n"
     ]
    }
   ],
   "source": [
    "x_lin = np.linspace(0, 5, ticks)  # range for mu\n",
    "y_lin = np.linspace(0, 0.6, ticks)\n",
    "ind = np.unravel_index(np.argmax(Colourplot, axis=None), Colourplot.shape)\n",
    "print(ind, y_lin[ticks-ind[0]-1], x_lin[ind[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximating Ground truth with gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 1\t| Iteration: 0 \t| Log-Likelihood:-3.202937202009177 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.118971  \n",
      "Run: 1\t| Iteration: 100 \t| Log-Likelihood:-3.190162779071696 \t|  theta: tensor([[0.4132, 1.0325]], requires_grad=True)  |  Time needed: 0:00:14.666031  \n",
      "Run: 1\t| Iteration: 200 \t| Log-Likelihood:-3.1875733949475653 \t|  theta: tensor([[0.4202, 1.0464]], requires_grad=True)  |  Time needed: 0:00:14.247020  \n",
      "Run: 1\t| Iteration: 300 \t| Log-Likelihood:-3.187008627886772 \t|  theta: tensor([[0.4242, 1.0526]], requires_grad=True)  |  Time needed: 0:00:17.677741  \n",
      "Run: 1\t| Iteration: 400 \t| Log-Likelihood:-3.186874831309641 \t|  theta: tensor([[0.4266, 1.0552]], requires_grad=True)  |  Time needed: 0:00:13.073046  \n",
      "Run: 1\t| Iteration: 500 \t| Log-Likelihood:-3.186838937082911 \t|  theta: tensor([[0.4281, 1.0563]], requires_grad=True)  |  Time needed: 0:00:12.551092  \n",
      "Run: 1\t| Iteration: 600 \t| Log-Likelihood:-3.186827523994887 \t|  theta: tensor([[0.4290, 1.0568]], requires_grad=True)  |  Time needed: 0:00:12.782849  \n",
      "Run: 1\t| Iteration: 700 \t| Log-Likelihood:-3.1868231964929343 \t|  theta: tensor([[0.4297, 1.0569]], requires_grad=True)  |  Time needed: 0:00:12.920662  \n",
      "Run: 1\t| Iteration: 800 \t| Log-Likelihood:-3.186821324114563 \t|  theta: tensor([[0.4301, 1.0570]], requires_grad=True)  |  Time needed: 0:00:12.639703  \n",
      "Run: 1\t| Iteration: 900 \t| Log-Likelihood:-3.1868204482535156 \t|  theta: tensor([[0.4304, 1.0569]], requires_grad=True)  |  Time needed: 0:00:14.149655  \n",
      "Run: 1\t| Iteration: 1000 \t| Log-Likelihood:-3.1868200220512986 \t|  theta: tensor([[0.4306, 1.0569]], requires_grad=True)  |  Time needed: 0:00:14.917810  \n",
      "Run: 1\t| Iteration: 1100 \t| Log-Likelihood:-3.186819811422513 \t|  theta: tensor([[0.4307, 1.0569]], requires_grad=True)  |  Time needed: 0:00:19.612000  \n",
      "Run: 1\t| Iteration: 1200 \t| Log-Likelihood:-3.1868197067360913 \t|  theta: tensor([[0.4308, 1.0569]], requires_grad=True)  |  Time needed: 0:00:14.894227  \n",
      "Run: 1\t| Iteration: 1300 \t| Log-Likelihood:-3.186819655043792 \t|  theta: tensor([[0.4309, 1.0569]], requires_grad=True)  |  Time needed: 0:00:13.241926  \n",
      "Run: 1\t| Iteration: 1400 \t| Log-Likelihood:-3.1868195989860744 \t|  theta: tensor([[0.4310, 1.0569]], requires_grad=True)  |  Time needed: 0:00:11.144183  \n",
      "Run: 1\t| Iteration: 1500 \t| Log-Likelihood:-3.186819645000147 \t|  theta: tensor([[0.4310, 1.0568]], requires_grad=True)  |  Time needed: 0:00:12.187149  \n",
      "Run: 1\t| Iteration: 1600 \t| Log-Likelihood:-3.186819608548796 \t|  theta: tensor([[0.4310, 1.0568]], requires_grad=True)  |  Time needed: 0:00:11.094057  \n",
      "Run: 1\t| Iteration: 1700 \t| Log-Likelihood:-3.1868196351223848 \t|  theta: tensor([[0.4310, 1.0568]], requires_grad=True)  |  Time needed: 0:00:11.406076  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 2\t| Iteration: 0 \t| Log-Likelihood:-3.2102451226855364 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.338498  \n",
      "Run: 2\t| Iteration: 100 \t| Log-Likelihood:-3.196748566721772 \t|  theta: tensor([[0.4131, 1.0336]], requires_grad=True)  |  Time needed: 0:00:16.035701  \n",
      "Run: 2\t| Iteration: 200 \t| Log-Likelihood:-3.194021621606564 \t|  theta: tensor([[0.4200, 1.0480]], requires_grad=True)  |  Time needed: 0:00:17.100436  \n",
      "Run: 2\t| Iteration: 300 \t| Log-Likelihood:-3.193431547544858 \t|  theta: tensor([[0.4239, 1.0544]], requires_grad=True)  |  Time needed: 0:00:15.148086  \n",
      "Run: 2\t| Iteration: 400 \t| Log-Likelihood:-3.193294286465924 \t|  theta: tensor([[0.4262, 1.0572]], requires_grad=True)  |  Time needed: 0:00:12.236606  \n",
      "Run: 2\t| Iteration: 500 \t| Log-Likelihood:-3.193258703869402 \t|  theta: tensor([[0.4276, 1.0584]], requires_grad=True)  |  Time needed: 0:00:11.970779  \n",
      "Run: 2\t| Iteration: 600 \t| Log-Likelihood:-3.193247927249018 \t|  theta: tensor([[0.4285, 1.0589]], requires_grad=True)  |  Time needed: 0:00:13.618969  \n",
      "Run: 2\t| Iteration: 700 \t| Log-Likelihood:-3.1932440841640877 \t|  theta: tensor([[0.4291, 1.0590]], requires_grad=True)  |  Time needed: 0:00:15.669069  \n",
      "Run: 2\t| Iteration: 800 \t| Log-Likelihood:-3.193242418206372 \t|  theta: tensor([[0.4295, 1.0591]], requires_grad=True)  |  Time needed: 0:00:11.405963  \n",
      "Run: 2\t| Iteration: 900 \t| Log-Likelihood:-3.1932416660607066 \t|  theta: tensor([[0.4298, 1.0591]], requires_grad=True)  |  Time needed: 0:00:14.419944  \n",
      "Run: 2\t| Iteration: 1000 \t| Log-Likelihood:-3.193241273386895 \t|  theta: tensor([[0.4300, 1.0591]], requires_grad=True)  |  Time needed: 0:00:12.244340  \n",
      "Run: 2\t| Iteration: 1100 \t| Log-Likelihood:-3.193241124283398 \t|  theta: tensor([[0.4301, 1.0591]], requires_grad=True)  |  Time needed: 0:00:12.718399  \n",
      "Run: 2\t| Iteration: 1200 \t| Log-Likelihood:-3.1932410065769106 \t|  theta: tensor([[0.4302, 1.0590]], requires_grad=True)  |  Time needed: 0:00:13.922314  \n",
      "Run: 2\t| Iteration: 1300 \t| Log-Likelihood:-3.1932410222461427 \t|  theta: tensor([[0.4303, 1.0590]], requires_grad=True)  |  Time needed: 0:00:14.729885  \n",
      "Run: 2\t| Iteration: 1400 \t| Log-Likelihood:-3.1932409699994624 \t|  theta: tensor([[0.4303, 1.0590]], requires_grad=True)  |  Time needed: 0:00:14.109837  \n",
      "Run: 2\t| Iteration: 1500 \t| Log-Likelihood:-3.1932409285841734 \t|  theta: tensor([[0.4303, 1.0590]], requires_grad=True)  |  Time needed: 0:00:13.580116  \n",
      "Run: 2\t| Iteration: 1600 \t| Log-Likelihood:-3.1932409528022596 \t|  theta: tensor([[0.4304, 1.0590]], requires_grad=True)  |  Time needed: 0:00:13.730644  \n",
      "Run: 2\t| Iteration: 1700 \t| Log-Likelihood:-3.1932409500584855 \t|  theta: tensor([[0.4304, 1.0590]], requires_grad=True)  |  Time needed: 0:00:10.941172  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 3\t| Iteration: 0 \t| Log-Likelihood:-3.179907588310168 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.104247  \n",
      "Run: 3\t| Iteration: 100 \t| Log-Likelihood:-3.1679700609064727 \t|  theta: tensor([[0.4130, 1.0313]], requires_grad=True)  |  Time needed: 0:00:11.968495  \n",
      "Run: 3\t| Iteration: 200 \t| Log-Likelihood:-3.165539264162886 \t|  theta: tensor([[0.4199, 1.0448]], requires_grad=True)  |  Time needed: 0:00:12.109252  \n",
      "Run: 3\t| Iteration: 300 \t| Log-Likelihood:-3.1650060176111467 \t|  theta: tensor([[0.4239, 1.0507]], requires_grad=True)  |  Time needed: 0:00:12.337531  \n",
      "Run: 3\t| Iteration: 400 \t| Log-Likelihood:-3.164878294519668 \t|  theta: tensor([[0.4263, 1.0532]], requires_grad=True)  |  Time needed: 0:00:12.448731  \n",
      "Run: 3\t| Iteration: 500 \t| Log-Likelihood:-3.1648434363706213 \t|  theta: tensor([[0.4278, 1.0543]], requires_grad=True)  |  Time needed: 0:00:13.899168  \n",
      "Run: 3\t| Iteration: 600 \t| Log-Likelihood:-3.164832065457492 \t|  theta: tensor([[0.4288, 1.0547]], requires_grad=True)  |  Time needed: 0:00:12.600118  \n",
      "Run: 3\t| Iteration: 700 \t| Log-Likelihood:-3.1648277110131837 \t|  theta: tensor([[0.4294, 1.0548]], requires_grad=True)  |  Time needed: 0:00:12.292442  \n",
      "Run: 3\t| Iteration: 800 \t| Log-Likelihood:-3.164825759686832 \t|  theta: tensor([[0.4298, 1.0548]], requires_grad=True)  |  Time needed: 0:00:12.165582  \n",
      "Run: 3\t| Iteration: 900 \t| Log-Likelihood:-3.1648248554831753 \t|  theta: tensor([[0.4301, 1.0548]], requires_grad=True)  |  Time needed: 0:00:12.616736  \n",
      "Run: 3\t| Iteration: 1000 \t| Log-Likelihood:-3.1648244448626826 \t|  theta: tensor([[0.4303, 1.0548]], requires_grad=True)  |  Time needed: 0:00:15.377658  \n",
      "Run: 3\t| Iteration: 1100 \t| Log-Likelihood:-3.164824227069037 \t|  theta: tensor([[0.4305, 1.0548]], requires_grad=True)  |  Time needed: 0:00:12.268761  \n",
      "Run: 3\t| Iteration: 1200 \t| Log-Likelihood:-3.16482414775641 \t|  theta: tensor([[0.4306, 1.0548]], requires_grad=True)  |  Time needed: 0:00:13.318673  \n",
      "Run: 3\t| Iteration: 1300 \t| Log-Likelihood:-3.1648240644385863 \t|  theta: tensor([[0.4307, 1.0547]], requires_grad=True)  |  Time needed: 0:00:13.719563  \n",
      "Run: 3\t| Iteration: 1400 \t| Log-Likelihood:-3.1648240670161827 \t|  theta: tensor([[0.4307, 1.0547]], requires_grad=True)  |  Time needed: 0:00:14.394457  \n",
      "Run: 3\t| Iteration: 1500 \t| Log-Likelihood:-3.164824023170398 \t|  theta: tensor([[0.4307, 1.0547]], requires_grad=True)  |  Time needed: 0:00:13.200421  \n",
      "Run: 3\t| Iteration: 1600 \t| Log-Likelihood:-3.1648239864577428 \t|  theta: tensor([[0.4308, 1.0547]], requires_grad=True)  |  Time needed: 0:00:13.236717  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 3\t| Iteration: 1700 \t| Log-Likelihood:-3.1648240129240417 \t|  theta: tensor([[0.4308, 1.0547]], requires_grad=True)  |  Time needed: 0:00:15.721811  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 4\t| Iteration: 0 \t| Log-Likelihood:-3.2251867751708403 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.181808  \n",
      "Run: 4\t| Iteration: 100 \t| Log-Likelihood:-3.211263010292619 \t|  theta: tensor([[0.4133, 1.0341]], requires_grad=True)  |  Time needed: 0:00:15.150564  \n",
      "Run: 4\t| Iteration: 200 \t| Log-Likelihood:-3.2084523153994113 \t|  theta: tensor([[0.4204, 1.0488]], requires_grad=True)  |  Time needed: 0:00:13.053035  \n",
      "Run: 4\t| Iteration: 300 \t| Log-Likelihood:-3.2078440969151263 \t|  theta: tensor([[0.4243, 1.0552]], requires_grad=True)  |  Time needed: 0:00:13.361296  \n",
      "Run: 4\t| Iteration: 400 \t| Log-Likelihood:-3.2077026309571472 \t|  theta: tensor([[0.4267, 1.0581]], requires_grad=True)  |  Time needed: 0:00:16.345809  \n",
      "Run: 4\t| Iteration: 500 \t| Log-Likelihood:-3.2076660011829645 \t|  theta: tensor([[0.4281, 1.0593]], requires_grad=True)  |  Time needed: 0:00:12.305611  \n",
      "Run: 4\t| Iteration: 600 \t| Log-Likelihood:-3.207654837407637 \t|  theta: tensor([[0.4290, 1.0598]], requires_grad=True)  |  Time needed: 0:00:12.455221  \n",
      "Run: 4\t| Iteration: 700 \t| Log-Likelihood:-3.207650846112097 \t|  theta: tensor([[0.4296, 1.0599]], requires_grad=True)  |  Time needed: 0:00:14.940723  \n",
      "Run: 4\t| Iteration: 800 \t| Log-Likelihood:-3.2076491598082857 \t|  theta: tensor([[0.4300, 1.0600]], requires_grad=True)  |  Time needed: 0:00:16.586755  \n",
      "Run: 4\t| Iteration: 900 \t| Log-Likelihood:-3.207648384216488 \t|  theta: tensor([[0.4303, 1.0600]], requires_grad=True)  |  Time needed: 0:00:11.256993  \n",
      "Run: 4\t| Iteration: 1000 \t| Log-Likelihood:-3.2076480096197093 \t|  theta: tensor([[0.4305, 1.0600]], requires_grad=True)  |  Time needed: 0:00:14.071110  \n",
      "Run: 4\t| Iteration: 1100 \t| Log-Likelihood:-3.2076478247222964 \t|  theta: tensor([[0.4306, 1.0600]], requires_grad=True)  |  Time needed: 0:00:12.181084  \n",
      "Run: 4\t| Iteration: 1200 \t| Log-Likelihood:-3.207647733701675 \t|  theta: tensor([[0.4307, 1.0599]], requires_grad=True)  |  Time needed: 0:00:11.762510  \n",
      "Run: 4\t| Iteration: 1300 \t| Log-Likelihood:-3.2076476882481346 \t|  theta: tensor([[0.4308, 1.0599]], requires_grad=True)  |  Time needed: 0:00:11.617633  \n",
      "Run: 4\t| Iteration: 1400 \t| Log-Likelihood:-3.207647694843579 \t|  theta: tensor([[0.4308, 1.0599]], requires_grad=True)  |  Time needed: 0:00:11.730336  \n",
      "Run: 4\t| Iteration: 1500 \t| Log-Likelihood:-3.2076476530114206 \t|  theta: tensor([[0.4308, 1.0599]], requires_grad=True)  |  Time needed: 0:00:13.232396  \n",
      "Run: 4\t| Iteration: 1600 \t| Log-Likelihood:-3.2076476173904327 \t|  theta: tensor([[0.4309, 1.0599]], requires_grad=True)  |  Time needed: 0:00:11.750705  \n",
      "Run: 4\t| Iteration: 1700 \t| Log-Likelihood:-3.20764764434861 \t|  theta: tensor([[0.4309, 1.0599]], requires_grad=True)  |  Time needed: 0:00:11.935496  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 5\t| Iteration: 0 \t| Log-Likelihood:-3.2021131958806155 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.130905  \n",
      "Run: 5\t| Iteration: 100 \t| Log-Likelihood:-3.189469947550929 \t|  theta: tensor([[0.4133, 1.0323]], requires_grad=True)  |  Time needed: 0:00:12.782687  \n",
      "Run: 5\t| Iteration: 200 \t| Log-Likelihood:-3.1868993596292032 \t|  theta: tensor([[0.4205, 1.0461]], requires_grad=True)  |  Time needed: 0:00:22.897272  \n",
      "Run: 5\t| Iteration: 300 \t| Log-Likelihood:-3.1863358975473424 \t|  theta: tensor([[0.4245, 1.0521]], requires_grad=True)  |  Time needed: 0:00:43.579369  \n",
      "Run: 5\t| Iteration: 400 \t| Log-Likelihood:-3.1862012473981993 \t|  theta: tensor([[0.4270, 1.0548]], requires_grad=True)  |  Time needed: 0:00:24.946751  \n",
      "Run: 5\t| Iteration: 500 \t| Log-Likelihood:-3.186164641713678 \t|  theta: tensor([[0.4285, 1.0559]], requires_grad=True)  |  Time needed: 0:00:14.573915  \n",
      "Run: 5\t| Iteration: 600 \t| Log-Likelihood:-3.186152783427123 \t|  theta: tensor([[0.4295, 1.0563]], requires_grad=True)  |  Time needed: 0:00:12.853740  \n",
      "Run: 5\t| Iteration: 700 \t| Log-Likelihood:-3.186148234331822 \t|  theta: tensor([[0.4301, 1.0564]], requires_grad=True)  |  Time needed: 0:00:21.022270  \n",
      "Run: 5\t| Iteration: 800 \t| Log-Likelihood:-3.186146276662662 \t|  theta: tensor([[0.4306, 1.0565]], requires_grad=True)  |  Time needed: 0:00:12.489154  \n",
      "Run: 5\t| Iteration: 900 \t| Log-Likelihood:-3.186145341391715 \t|  theta: tensor([[0.4309, 1.0565]], requires_grad=True)  |  Time needed: 0:00:14.925927  \n",
      "Run: 5\t| Iteration: 1000 \t| Log-Likelihood:-3.1861448557917167 \t|  theta: tensor([[0.4311, 1.0564]], requires_grad=True)  |  Time needed: 0:00:12.276885  \n",
      "Run: 5\t| Iteration: 1100 \t| Log-Likelihood:-3.1861446599929177 \t|  theta: tensor([[0.4312, 1.0564]], requires_grad=True)  |  Time needed: 0:00:14.559063  \n",
      "Run: 5\t| Iteration: 1200 \t| Log-Likelihood:-3.1861445166825355 \t|  theta: tensor([[0.4313, 1.0564]], requires_grad=True)  |  Time needed: 0:00:18.125124  \n",
      "Run: 5\t| Iteration: 1300 \t| Log-Likelihood:-3.1861444905326364 \t|  theta: tensor([[0.4314, 1.0564]], requires_grad=True)  |  Time needed: 0:00:13.317795  \n",
      "Run: 5\t| Iteration: 1400 \t| Log-Likelihood:-3.1861444919820237 \t|  theta: tensor([[0.4315, 1.0564]], requires_grad=True)  |  Time needed: 0:00:12.488239  \n",
      "Run: 5\t| Iteration: 1500 \t| Log-Likelihood:-3.1861444475447254 \t|  theta: tensor([[0.4315, 1.0563]], requires_grad=True)  |  Time needed: 0:00:33.747806  \n",
      "Run: 5\t| Iteration: 1600 \t| Log-Likelihood:-3.1861444104497094 \t|  theta: tensor([[0.4315, 1.0563]], requires_grad=True)  |  Time needed: 0:00:13.042374  \n",
      "Run: 5\t| Iteration: 1700 \t| Log-Likelihood:-3.1861444367501335 \t|  theta: tensor([[0.4315, 1.0563]], requires_grad=True)  |  Time needed: 0:00:25.830164  \n",
      "Run: 5\t| Iteration: 1800 \t| Log-Likelihood:-3.18614443497245 \t|  theta: tensor([[0.4315, 1.0563]], requires_grad=True)  |  Time needed: 0:00:25.403485  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 6\t| Iteration: 0 \t| Log-Likelihood:-3.1901389288024444 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.114827  \n",
      "Run: 6\t| Iteration: 100 \t| Log-Likelihood:-3.177746390234396 \t|  theta: tensor([[0.4132, 1.0320]], requires_grad=True)  |  Time needed: 0:00:12.618427  \n",
      "Run: 6\t| Iteration: 200 \t| Log-Likelihood:-3.175226023288517 \t|  theta: tensor([[0.4202, 1.0457]], requires_grad=True)  |  Time needed: 0:00:13.473491  \n",
      "Run: 6\t| Iteration: 300 \t| Log-Likelihood:-3.174674034066982 \t|  theta: tensor([[0.4242, 1.0517]], requires_grad=True)  |  Time needed: 0:00:16.676459  \n",
      "Run: 6\t| Iteration: 400 \t| Log-Likelihood:-3.174542338550235 \t|  theta: tensor([[0.4266, 1.0543]], requires_grad=True)  |  Time needed: 0:00:20.157049  \n",
      "Run: 6\t| Iteration: 500 \t| Log-Likelihood:-3.1745066575933536 \t|  theta: tensor([[0.4281, 1.0554]], requires_grad=True)  |  Time needed: 0:00:22.054021  \n",
      "Run: 6\t| Iteration: 600 \t| Log-Likelihood:-3.174495136563599 \t|  theta: tensor([[0.4291, 1.0558]], requires_grad=True)  |  Time needed: 0:00:27.136270  \n",
      "Run: 6\t| Iteration: 700 \t| Log-Likelihood:-3.1744907312979005 \t|  theta: tensor([[0.4297, 1.0559]], requires_grad=True)  |  Time needed: 0:00:19.387757  \n",
      "Run: 6\t| Iteration: 800 \t| Log-Likelihood:-3.174488810988849 \t|  theta: tensor([[0.4301, 1.0560]], requires_grad=True)  |  Time needed: 0:00:13.489006  \n",
      "Run: 6\t| Iteration: 900 \t| Log-Likelihood:-3.1744879093229286 \t|  theta: tensor([[0.4304, 1.0560]], requires_grad=True)  |  Time needed: 0:00:15.909107  \n",
      "Run: 6\t| Iteration: 1000 \t| Log-Likelihood:-3.174487440257314 \t|  theta: tensor([[0.4306, 1.0559]], requires_grad=True)  |  Time needed: 0:00:18.257768  \n",
      "Run: 6\t| Iteration: 1100 \t| Log-Likelihood:-3.174487252819171 \t|  theta: tensor([[0.4308, 1.0559]], requires_grad=True)  |  Time needed: 0:00:19.367155  \n",
      "Run: 6\t| Iteration: 1200 \t| Log-Likelihood:-3.174487173853903 \t|  theta: tensor([[0.4309, 1.0559]], requires_grad=True)  |  Time needed: 0:00:19.801381  \n",
      "Run: 6\t| Iteration: 1300 \t| Log-Likelihood:-3.174487060811202 \t|  theta: tensor([[0.4309, 1.0559]], requires_grad=True)  |  Time needed: 0:00:14.877345  \n",
      "Run: 6\t| Iteration: 1400 \t| Log-Likelihood:-3.1744870336168938 \t|  theta: tensor([[0.4310, 1.0559]], requires_grad=True)  |  Time needed: 0:00:16.545850  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 6\t| Iteration: 1500 \t| Log-Likelihood:-3.174487079166337 \t|  theta: tensor([[0.4310, 1.0559]], requires_grad=True)  |  Time needed: 0:00:16.202385  \n",
      "Run: 6\t| Iteration: 1600 \t| Log-Likelihood:-3.174487072231044 \t|  theta: tensor([[0.4311, 1.0558]], requires_grad=True)  |  Time needed: 0:00:16.603513  \n",
      "Run: 6\t| Iteration: 1700 \t| Log-Likelihood:-3.174487039086576 \t|  theta: tensor([[0.4311, 1.0558]], requires_grad=True)  |  Time needed: 0:00:16.518500  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 7\t| Iteration: 0 \t| Log-Likelihood:-3.197429942371876 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.115161  \n",
      "Run: 7\t| Iteration: 100 \t| Log-Likelihood:-3.1849061711115243 \t|  theta: tensor([[0.4133, 1.0321]], requires_grad=True)  |  Time needed: 0:00:13.334673  \n",
      "Run: 7\t| Iteration: 200 \t| Log-Likelihood:-3.182355215404251 \t|  theta: tensor([[0.4205, 1.0458]], requires_grad=True)  |  Time needed: 0:00:16.584504  \n",
      "Run: 7\t| Iteration: 300 \t| Log-Likelihood:-3.1817949433653445 \t|  theta: tensor([[0.4246, 1.0519]], requires_grad=True)  |  Time needed: 0:00:11.903131  \n",
      "Run: 7\t| Iteration: 400 \t| Log-Likelihood:-3.1816607383879107 \t|  theta: tensor([[0.4270, 1.0545]], requires_grad=True)  |  Time needed: 0:00:10.594352  \n",
      "Run: 7\t| Iteration: 500 \t| Log-Likelihood:-3.1816240963970914 \t|  theta: tensor([[0.4285, 1.0556]], requires_grad=True)  |  Time needed: 0:00:10.669154  \n",
      "Run: 7\t| Iteration: 600 \t| Log-Likelihood:-3.1816121991749955 \t|  theta: tensor([[0.4295, 1.0560]], requires_grad=True)  |  Time needed: 0:00:10.772259  \n",
      "Run: 7\t| Iteration: 700 \t| Log-Likelihood:-3.1816076222547407 \t|  theta: tensor([[0.4302, 1.0561]], requires_grad=True)  |  Time needed: 0:00:10.741825  \n",
      "Run: 7\t| Iteration: 800 \t| Log-Likelihood:-3.1816056785003757 \t|  theta: tensor([[0.4306, 1.0562]], requires_grad=True)  |  Time needed: 0:00:10.605351  \n",
      "Run: 7\t| Iteration: 900 \t| Log-Likelihood:-3.1816047349092256 \t|  theta: tensor([[0.4309, 1.0562]], requires_grad=True)  |  Time needed: 0:00:10.658879  \n",
      "Run: 7\t| Iteration: 1000 \t| Log-Likelihood:-3.1816042450142468 \t|  theta: tensor([[0.4311, 1.0561]], requires_grad=True)  |  Time needed: 0:00:12.093285  \n",
      "Run: 7\t| Iteration: 1100 \t| Log-Likelihood:-3.181603987265139 \t|  theta: tensor([[0.4313, 1.0561]], requires_grad=True)  |  Time needed: 0:00:12.802176  \n",
      "Run: 7\t| Iteration: 1200 \t| Log-Likelihood:-3.1816038725401485 \t|  theta: tensor([[0.4314, 1.0561]], requires_grad=True)  |  Time needed: 0:00:12.960042  \n",
      "Run: 7\t| Iteration: 1300 \t| Log-Likelihood:-3.1816038454198354 \t|  theta: tensor([[0.4314, 1.0561]], requires_grad=True)  |  Time needed: 0:00:16.975141  \n",
      "Run: 7\t| Iteration: 1400 \t| Log-Likelihood:-3.1816038465056184 \t|  theta: tensor([[0.4315, 1.0561]], requires_grad=True)  |  Time needed: 0:00:12.813741  \n",
      "Run: 7\t| Iteration: 1500 \t| Log-Likelihood:-3.181603801884123 \t|  theta: tensor([[0.4315, 1.0560]], requires_grad=True)  |  Time needed: 0:00:12.702995  \n",
      "Run: 7\t| Iteration: 1600 \t| Log-Likelihood:-3.1816037944827253 \t|  theta: tensor([[0.4316, 1.0560]], requires_grad=True)  |  Time needed: 0:00:14.825655  \n",
      "Run: 7\t| Iteration: 1700 \t| Log-Likelihood:-3.1816038207366306 \t|  theta: tensor([[0.4316, 1.0560]], requires_grad=True)  |  Time needed: 0:00:15.126183  \n",
      "Run: 7\t| Iteration: 1800 \t| Log-Likelihood:-3.1816038189375986 \t|  theta: tensor([[0.4316, 1.0560]], requires_grad=True)  |  Time needed: 0:00:11.989219  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 8\t| Iteration: 0 \t| Log-Likelihood:-3.2035721548029397 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.108063  \n",
      "Run: 8\t| Iteration: 100 \t| Log-Likelihood:-3.1905761306040397 \t|  theta: tensor([[0.4132, 1.0328]], requires_grad=True)  |  Time needed: 0:00:12.999728  \n",
      "Run: 8\t| Iteration: 200 \t| Log-Likelihood:-3.1879440427815844 \t|  theta: tensor([[0.4202, 1.0469]], requires_grad=True)  |  Time needed: 0:00:15.793574  \n",
      "Run: 8\t| Iteration: 300 \t| Log-Likelihood:-3.187371094502446 \t|  theta: tensor([[0.4242, 1.0531]], requires_grad=True)  |  Time needed: 0:00:14.361938  \n",
      "Run: 8\t| Iteration: 400 \t| Log-Likelihood:-3.1872359795852945 \t|  theta: tensor([[0.4266, 1.0558]], requires_grad=True)  |  Time needed: 0:00:11.863557  \n",
      "Run: 8\t| Iteration: 500 \t| Log-Likelihood:-3.1872000449303073 \t|  theta: tensor([[0.4280, 1.0569]], requires_grad=True)  |  Time needed: 0:00:11.911417  \n",
      "Run: 8\t| Iteration: 600 \t| Log-Likelihood:-3.1871887514714907 \t|  theta: tensor([[0.4290, 1.0574]], requires_grad=True)  |  Time needed: 0:00:12.003619  \n",
      "Run: 8\t| Iteration: 700 \t| Log-Likelihood:-3.18718448581111 \t|  theta: tensor([[0.4296, 1.0575]], requires_grad=True)  |  Time needed: 0:00:12.698008  \n",
      "Run: 8\t| Iteration: 800 \t| Log-Likelihood:-3.18718269514002 \t|  theta: tensor([[0.4300, 1.0576]], requires_grad=True)  |  Time needed: 0:00:12.199082  \n",
      "Run: 8\t| Iteration: 900 \t| Log-Likelihood:-3.1871818469277327 \t|  theta: tensor([[0.4303, 1.0576]], requires_grad=True)  |  Time needed: 0:00:12.057092  \n",
      "Run: 8\t| Iteration: 1000 \t| Log-Likelihood:-3.187181434754485 \t|  theta: tensor([[0.4305, 1.0575]], requires_grad=True)  |  Time needed: 0:00:12.125014  \n",
      "Run: 8\t| Iteration: 1100 \t| Log-Likelihood:-3.187181231018408 \t|  theta: tensor([[0.4307, 1.0575]], requires_grad=True)  |  Time needed: 0:00:12.162086  \n",
      "Run: 8\t| Iteration: 1200 \t| Log-Likelihood:-3.187181130182712 \t|  theta: tensor([[0.4308, 1.0575]], requires_grad=True)  |  Time needed: 0:00:11.870013  \n",
      "Run: 8\t| Iteration: 1300 \t| Log-Likelihood:-3.1871810504611684 \t|  theta: tensor([[0.4308, 1.0575]], requires_grad=True)  |  Time needed: 0:00:11.978024  \n",
      "Run: 8\t| Iteration: 1400 \t| Log-Likelihood:-3.1871810846179374 \t|  theta: tensor([[0.4309, 1.0575]], requires_grad=True)  |  Time needed: 0:00:12.115814  \n",
      "Run: 8\t| Iteration: 1500 \t| Log-Likelihood:-3.187181011871926 \t|  theta: tensor([[0.4309, 1.0575]], requires_grad=True)  |  Time needed: 0:00:11.947056  \n",
      "Run: 8\t| Iteration: 1600 \t| Log-Likelihood:-3.1871810650386285 \t|  theta: tensor([[0.4309, 1.0575]], requires_grad=True)  |  Time needed: 0:00:13.012524  \n",
      "Run: 8\t| Iteration: 1700 \t| Log-Likelihood:-3.187181061920314 \t|  theta: tensor([[0.4309, 1.0575]], requires_grad=True)  |  Time needed: 0:00:16.199238  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 9\t| Iteration: 0 \t| Log-Likelihood:-3.22662362108302 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.094159  \n",
      "Run: 9\t| Iteration: 100 \t| Log-Likelihood:-3.212533863653331 \t|  theta: tensor([[0.4132, 1.0344]], requires_grad=True)  |  Time needed: 0:00:09.270771  \n",
      "Run: 9\t| Iteration: 200 \t| Log-Likelihood:-3.2096845219866568 \t|  theta: tensor([[0.4202, 1.0492]], requires_grad=True)  |  Time needed: 0:00:09.264376  \n",
      "Run: 9\t| Iteration: 300 \t| Log-Likelihood:-3.209068804806337 \t|  theta: tensor([[0.4240, 1.0558]], requires_grad=True)  |  Time needed: 0:00:09.249096  \n",
      "Run: 9\t| Iteration: 400 \t| Log-Likelihood:-3.2089266411262343 \t|  theta: tensor([[0.4263, 1.0587]], requires_grad=True)  |  Time needed: 0:00:09.347213  \n",
      "Run: 9\t| Iteration: 500 \t| Log-Likelihood:-3.20889054064374 \t|  theta: tensor([[0.4276, 1.0600]], requires_grad=True)  |  Time needed: 0:00:09.215899  \n",
      "Run: 9\t| Iteration: 600 \t| Log-Likelihood:-3.20887987836487 \t|  theta: tensor([[0.4285, 1.0605]], requires_grad=True)  |  Time needed: 0:00:09.193864  \n",
      "Run: 9\t| Iteration: 700 \t| Log-Likelihood:-3.208876178880259 \t|  theta: tensor([[0.4291, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.248480  \n",
      "Run: 9\t| Iteration: 800 \t| Log-Likelihood:-3.208874681143166 \t|  theta: tensor([[0.4295, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.281579  \n",
      "Run: 9\t| Iteration: 900 \t| Log-Likelihood:-3.208873958411288 \t|  theta: tensor([[0.4297, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.191790  \n",
      "Run: 9\t| Iteration: 1000 \t| Log-Likelihood:-3.2088736261631756 \t|  theta: tensor([[0.4299, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.241176  \n",
      "Run: 9\t| Iteration: 1100 \t| Log-Likelihood:-3.208873462519315 \t|  theta: tensor([[0.4300, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.217115  \n",
      "Run: 9\t| Iteration: 1200 \t| Log-Likelihood:-3.20887338180378 \t|  theta: tensor([[0.4301, 1.0607]], requires_grad=True)  |  Time needed: 0:00:09.243831  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 9\t| Iteration: 1300 \t| Log-Likelihood:-3.2088733115670633 \t|  theta: tensor([[0.4302, 1.0607]], requires_grad=True)  |  Time needed: 0:00:10.638917  \n",
      "Run: 9\t| Iteration: 1400 \t| Log-Likelihood:-3.2088733206081783 \t|  theta: tensor([[0.4302, 1.0606]], requires_grad=True)  |  Time needed: 0:00:30.190431  \n",
      "Run: 9\t| Iteration: 1500 \t| Log-Likelihood:-3.208873339638086 \t|  theta: tensor([[0.4303, 1.0606]], requires_grad=True)  |  Time needed: 0:00:24.210433  \n",
      "Run: 9\t| Iteration: 1600 \t| Log-Likelihood:-3.208873334521411 \t|  theta: tensor([[0.4303, 1.0606]], requires_grad=True)  |  Time needed: 0:00:16.653636  \n",
      "Run: 9\t| Iteration: 1700 \t| Log-Likelihood:-3.2088732723814335 \t|  theta: tensor([[0.4303, 1.0606]], requires_grad=True)  |  Time needed: 0:00:18.468900  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 10\t| Iteration: 0 \t| Log-Likelihood:-3.198502610739704 \t|  theta: tensor([[0.4002, 1.0005]], requires_grad=True)  |  Time needed: 0:00:00.096612  \n",
      "Run: 10\t| Iteration: 100 \t| Log-Likelihood:-3.185757085065428 \t|  theta: tensor([[0.4133, 1.0324]], requires_grad=True)  |  Time needed: 0:00:10.895901  \n",
      "Run: 10\t| Iteration: 200 \t| Log-Likelihood:-3.183169618875989 \t|  theta: tensor([[0.4204, 1.0463]], requires_grad=True)  |  Time needed: 0:00:10.778725  \n",
      "Run: 10\t| Iteration: 300 \t| Log-Likelihood:-3.1826039424669856 \t|  theta: tensor([[0.4244, 1.0524]], requires_grad=True)  |  Time needed: 0:00:10.798799  \n",
      "Run: 10\t| Iteration: 400 \t| Log-Likelihood:-3.182469376158084 \t|  theta: tensor([[0.4268, 1.0551]], requires_grad=True)  |  Time needed: 0:00:11.954276  \n",
      "Run: 10\t| Iteration: 500 \t| Log-Likelihood:-3.182433043544668 \t|  theta: tensor([[0.4283, 1.0562]], requires_grad=True)  |  Time needed: 0:00:10.969748  \n",
      "Run: 10\t| Iteration: 600 \t| Log-Likelihood:-3.182421371605082 \t|  theta: tensor([[0.4293, 1.0566]], requires_grad=True)  |  Time needed: 0:00:11.638312  \n",
      "Run: 10\t| Iteration: 700 \t| Log-Likelihood:-3.1824169588449918 \t|  theta: tensor([[0.4299, 1.0568]], requires_grad=True)  |  Time needed: 0:00:14.369080  \n",
      "Run: 10\t| Iteration: 800 \t| Log-Likelihood:-3.1824149973125624 \t|  theta: tensor([[0.4304, 1.0568]], requires_grad=True)  |  Time needed: 0:00:21.226677  \n",
      "Run: 10\t| Iteration: 900 \t| Log-Likelihood:-3.182414090776382 \t|  theta: tensor([[0.4307, 1.0568]], requires_grad=True)  |  Time needed: 0:00:12.319687  \n",
      "Run: 10\t| Iteration: 1000 \t| Log-Likelihood:-3.1824136497030815 \t|  theta: tensor([[0.4309, 1.0568]], requires_grad=True)  |  Time needed: 0:00:14.113948  \n",
      "Run: 10\t| Iteration: 1100 \t| Log-Likelihood:-3.182413401695399 \t|  theta: tensor([[0.4310, 1.0567]], requires_grad=True)  |  Time needed: 0:00:14.618609  \n",
      "Run: 10\t| Iteration: 1200 \t| Log-Likelihood:-3.182413322320447 \t|  theta: tensor([[0.4311, 1.0567]], requires_grad=True)  |  Time needed: 0:00:14.841882  \n",
      "Run: 10\t| Iteration: 1300 \t| Log-Likelihood:-3.1824132388389326 \t|  theta: tensor([[0.4312, 1.0567]], requires_grad=True)  |  Time needed: 0:00:14.728268  \n",
      "Run: 10\t| Iteration: 1400 \t| Log-Likelihood:-3.1824132413266897 \t|  theta: tensor([[0.4312, 1.0567]], requires_grad=True)  |  Time needed: 0:00:13.639304  \n",
      "Run: 10\t| Iteration: 1500 \t| Log-Likelihood:-3.1824131974077554 \t|  theta: tensor([[0.4313, 1.0567]], requires_grad=True)  |  Time needed: 0:00:13.877640  \n",
      "Run: 10\t| Iteration: 1600 \t| Log-Likelihood:-3.1824132500177056 \t|  theta: tensor([[0.4313, 1.0567]], requires_grad=True)  |  Time needed: 0:00:16.912686  \n",
      "Run: 10\t| Iteration: 1700 \t| Log-Likelihood:-3.182413216859672 \t|  theta: tensor([[0.4313, 1.0567]], requires_grad=True)  |  Time needed: 0:00:11.679520  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Ascent\n",
    "'''\n",
    "#X = torch.from_numpy(X)\n",
    "# Set parameters here\n",
    "n_iterations = 5000 #max number of iterations # TODO: alternatively/ additionally a error-based threshold?\n",
    "lr = 0.001 # learning rate / stepsize\n",
    "n_runs = 10\n",
    "\n",
    "# Initializing Loss as minus infinity to make sure first run achieves higher likelihood\n",
    "max_likelihood = -1*np.inf\n",
    "# trajectory_dict is a cache to save the gradient ascent trajectory of all gradient ascent runs\n",
    "trajectory_dict = {}\n",
    "\n",
    "theta_gt_list = []\n",
    "\n",
    "# Running Gradient Ascent multiple (M=n_runs) times\n",
    "\n",
    "for run in range(n_runs):\n",
    "    \n",
    "    # Create sampels of given model\n",
    "    print('Sampling Data.../...\\...')\n",
    "    X = gaussian_mixture_model_sample(n, means, covs, weights, test=False) # we can alternatively use pytorchs MixtureFamily\n",
    "    X = torch.from_numpy(X)\n",
    "    print('Data sampled')\n",
    "    \n",
    "    # Create/ Initialize variable ' TODO: make initialization more flexible\n",
    "    theta = torch.tensor([[0.43, 1.058]], requires_grad = True)\n",
    "\n",
    "    # Run complete Gradient ascent\n",
    "    theta, L, trajectory = gradient_ascent_torch2(func = LogLikelihood,\n",
    "                                           param=theta,\n",
    "                                           data=X,\n",
    "                                           accuracy = 10**-16, \n",
    "                                           learningrate=lr,\n",
    "                                           run_id=run,\n",
    "                                           print_info=True)\n",
    "\n",
    "    # Save optimization trajectory\n",
    "    trajectory_dict.update({run : trajectory})\n",
    "    theta_gt_list.append(theta.clone().data.numpy())\n",
    "\n",
    "    # Updating Quantities if new max is found\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.43105388 1.056834  ]\n",
      " [0.430388   1.0589968 ]\n",
      " [0.43079117 1.0547081 ]\n",
      " [0.43089142 1.0598941 ]\n",
      " [0.43154448 1.056336  ]\n",
      " [0.4310907  1.0558412 ]\n",
      " [0.43158382 1.0560336 ]\n",
      " [0.4309605  1.0574625 ]\n",
      " [0.43030012 1.0606308 ]\n",
      " [0.4313304  1.0566736 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(theta_gt_list).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4309934 1.0573411]]\n"
     ]
    }
   ],
   "source": [
    "theta_1 = np.mean(theta_gt_list, axis = 0)\n",
    "print(theta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating local max with gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 1\t| Iteration: 0 \t| Log-Likelihood:-3.1705492297770212 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.262389  \n",
      "Run: 1\t| Iteration: 100 \t| Log-Likelihood:-3.1705490052486693 \t|  theta: tensor([[0.0500, 2.9999]], requires_grad=True)  |  Time needed: 0:00:14.253233  \n",
      "Run: 1\t| Iteration: 200 \t| Log-Likelihood:-3.170548890272284 \t|  theta: tensor([[0.0499, 2.9998]], requires_grad=True)  |  Time needed: 0:00:12.945521  \n",
      "Run: 1\t| Iteration: 300 \t| Log-Likelihood:-3.1705488178992436 \t|  theta: tensor([[0.0499, 2.9997]], requires_grad=True)  |  Time needed: 0:00:13.759476  \n",
      "Run: 1\t| Iteration: 400 \t| Log-Likelihood:-3.170548737393462 \t|  theta: tensor([[0.0499, 2.9996]], requires_grad=True)  |  Time needed: 0:00:13.010718  \n",
      "Run: 1\t| Iteration: 500 \t| Log-Likelihood:-3.170548681910487 \t|  theta: tensor([[0.0499, 2.9995]], requires_grad=True)  |  Time needed: 0:00:16.769358  \n",
      "Run: 1\t| Iteration: 600 \t| Log-Likelihood:-3.1705486327767956 \t|  theta: tensor([[0.0499, 2.9994]], requires_grad=True)  |  Time needed: 0:00:10.586170  \n",
      "Run: 1\t| Iteration: 700 \t| Log-Likelihood:-3.170548596275817 \t|  theta: tensor([[0.0499, 2.9994]], requires_grad=True)  |  Time needed: 0:00:10.126000  \n",
      "Run: 1\t| Iteration: 800 \t| Log-Likelihood:-3.1705485706170675 \t|  theta: tensor([[0.0499, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.706466  \n",
      "Run: 1\t| Iteration: 900 \t| Log-Likelihood:-3.17054854778019 \t|  theta: tensor([[0.0499, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.810336  \n",
      "Run: 1\t| Iteration: 1000 \t| Log-Likelihood:-3.1705485277651753 \t|  theta: tensor([[0.0499, 2.9992]], requires_grad=True)  |  Time needed: 0:00:11.052079  \n",
      "Run: 1\t| Iteration: 1100 \t| Log-Likelihood:-3.170548514194445 \t|  theta: tensor([[0.0499, 2.9992]], requires_grad=True)  |  Time needed: 0:00:14.347178  \n",
      "Run: 1\t| Iteration: 1200 \t| Log-Likelihood:-3.170548506338599 \t|  theta: tensor([[0.0499, 2.9992]], requires_grad=True)  |  Time needed: 0:00:11.268126  \n",
      "Run: 1\t| Iteration: 1300 \t| Log-Likelihood:-3.170548499188214 \t|  theta: tensor([[0.0499, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.356479  \n",
      "Run: 1\t| Iteration: 1400 \t| Log-Likelihood:-3.170548492743288 \t|  theta: tensor([[0.0499, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.659247  \n",
      "Run: 1\t| Iteration: 1500 \t| Log-Likelihood:-3.170548487003822 \t|  theta: tensor([[0.0499, 2.9991]], requires_grad=True)  |  Time needed: 0:00:10.078307  \n",
      "Run: 1\t| Iteration: 1600 \t| Log-Likelihood:-3.1705484819698118 \t|  theta: tensor([[0.0499, 2.9991]], requires_grad=True)  |  Time needed: 0:00:10.623780  \n",
      "Run: 1\t| Iteration: 1700 \t| Log-Likelihood:-3.1705484776412582 \t|  theta: tensor([[0.0499, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.881347  \n",
      "Run: 1\t| Iteration: 1800 \t| Log-Likelihood:-3.1705484740181604 \t|  theta: tensor([[0.0499, 2.9990]], requires_grad=True)  |  Time needed: 0:00:10.042378  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 2\t| Iteration: 0 \t| Log-Likelihood:-3.1743217151055365 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.159501  \n",
      "Run: 2\t| Iteration: 100 \t| Log-Likelihood:-3.1743209550734153 \t|  theta: tensor([[0.0498, 3.0000]], requires_grad=True)  |  Time needed: 0:00:13.733616  \n",
      "Run: 2\t| Iteration: 200 \t| Log-Likelihood:-3.1743209678632547 \t|  theta: tensor([[0.0497, 2.9999]], requires_grad=True)  |  Time needed: 0:00:12.430027  \n",
      "Run: 2\t| Iteration: 300 \t| Log-Likelihood:-3.1743209116454594 \t|  theta: tensor([[0.0497, 2.9999]], requires_grad=True)  |  Time needed: 0:00:11.112633  \n",
      "Run: 2\t| Iteration: 400 \t| Log-Likelihood:-3.174320949401008 \t|  theta: tensor([[0.0497, 2.9999]], requires_grad=True)  |  Time needed: 0:00:10.047235  \n",
      "Run: 2\t| Iteration: 500 \t| Log-Likelihood:-3.1743209431576234 \t|  theta: tensor([[0.0497, 2.9999]], requires_grad=True)  |  Time needed: 0:00:11.748298  \n",
      "Run: 2\t| Iteration: 600 \t| Log-Likelihood:-3.1743209376169172 \t|  theta: tensor([[0.0497, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.674683  \n",
      "Run: 2\t| Iteration: 700 \t| Log-Likelihood:-3.1743209327788864 \t|  theta: tensor([[0.0497, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.340542  \n",
      "Run: 2\t| Iteration: 800 \t| Log-Likelihood:-3.1743209286435317 \t|  theta: tensor([[0.0497, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.387738  \n",
      "Run: 2\t| Iteration: 900 \t| Log-Likelihood:-3.1743209252108513 \t|  theta: tensor([[0.0497, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.616638  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 3\t| Iteration: 0 \t| Log-Likelihood:-3.17713660550965 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.088555  \n",
      "Run: 3\t| Iteration: 100 \t| Log-Likelihood:-3.1771365229462387 \t|  theta: tensor([[0.0501, 3.0000]], requires_grad=True)  |  Time needed: 0:00:09.123613  \n",
      "Run: 3\t| Iteration: 200 \t| Log-Likelihood:-3.1771365189236764 \t|  theta: tensor([[0.0501, 3.0000]], requires_grad=True)  |  Time needed: 0:00:09.228222  \n",
      "Run: 3\t| Iteration: 300 \t| Log-Likelihood:-3.1771364682329652 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.185192  \n",
      "Run: 3\t| Iteration: 400 \t| Log-Likelihood:-3.177136522572682 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.186305  \n",
      "Run: 3\t| Iteration: 500 \t| Log-Likelihood:-3.177136518015136 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.196816  \n",
      "Run: 3\t| Iteration: 600 \t| Log-Likelihood:-3.177136514164813 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.151594  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 4\t| Iteration: 0 \t| Log-Likelihood:-3.1677683567444412 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.138383  \n",
      "Run: 4\t| Iteration: 100 \t| Log-Likelihood:-3.1677683206135483 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:13.746952  \n",
      "Run: 4\t| Iteration: 200 \t| Log-Likelihood:-3.1677682979904818 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:13.695022  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 5\t| Iteration: 0 \t| Log-Likelihood:-3.1771082009749656 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.117145  \n",
      "Run: 5\t| Iteration: 100 \t| Log-Likelihood:-3.177107018985713 \t|  theta: tensor([[0.0497, 2.9999]], requires_grad=True)  |  Time needed: 0:00:12.038530  \n",
      "Run: 5\t| Iteration: 200 \t| Log-Likelihood:-3.17710689559495 \t|  theta: tensor([[0.0497, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.823466  \n",
      "Run: 5\t| Iteration: 300 \t| Log-Likelihood:-3.177106879212878 \t|  theta: tensor([[0.0497, 2.9997]], requires_grad=True)  |  Time needed: 0:00:11.843728  \n",
      "Run: 5\t| Iteration: 400 \t| Log-Likelihood:-3.177106791126408 \t|  theta: tensor([[0.0497, 2.9997]], requires_grad=True)  |  Time needed: 0:00:11.293426  \n",
      "Run: 5\t| Iteration: 500 \t| Log-Likelihood:-3.1771067604660477 \t|  theta: tensor([[0.0497, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.723792  \n",
      "Run: 5\t| Iteration: 600 \t| Log-Likelihood:-3.177106735673897 \t|  theta: tensor([[0.0497, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.255562  \n",
      "Run: 5\t| Iteration: 700 \t| Log-Likelihood:-3.1771067136891293 \t|  theta: tensor([[0.0497, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.175756  \n",
      "Run: 5\t| Iteration: 800 \t| Log-Likelihood:-3.177106694511735 \t|  theta: tensor([[0.0497, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.102480  \n",
      "Run: 5\t| Iteration: 900 \t| Log-Likelihood:-3.1771066838714184 \t|  theta: tensor([[0.0497, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.141303  \n",
      "Run: 5\t| Iteration: 1000 \t| Log-Likelihood:-3.1771066762198004 \t|  theta: tensor([[0.0497, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.092521  \n",
      "Run: 5\t| Iteration: 1100 \t| Log-Likelihood:-3.177106669270021 \t|  theta: tensor([[0.0497, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.107217  \n",
      "Run: 5\t| Iteration: 1200 \t| Log-Likelihood:-3.177106663022079 \t|  theta: tensor([[0.0497, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.112119  \n",
      "Run: 5\t| Iteration: 1300 \t| Log-Likelihood:-3.1771066574759708 \t|  theta: tensor([[0.0497, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.114770  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 5\t| Iteration: 1400 \t| Log-Likelihood:-3.177106652631698 \t|  theta: tensor([[0.0497, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.074672  \n",
      "Run: 5\t| Iteration: 1500 \t| Log-Likelihood:-3.177106648489257 \t|  theta: tensor([[0.0497, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.130343  \n",
      "Run: 5\t| Iteration: 1600 \t| Log-Likelihood:-3.177106645048649 \t|  theta: tensor([[0.0497, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.127295  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 6\t| Iteration: 0 \t| Log-Likelihood:-3.180844760167378 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.090040  \n",
      "Run: 6\t| Iteration: 100 \t| Log-Likelihood:-3.1808440850709263 \t|  theta: tensor([[0.0498, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.264271  \n",
      "Run: 6\t| Iteration: 200 \t| Log-Likelihood:-3.1808440594870593 \t|  theta: tensor([[0.0498, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.310339  \n",
      "Run: 6\t| Iteration: 300 \t| Log-Likelihood:-3.18084402757711 \t|  theta: tensor([[0.0498, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.712330  \n",
      "Run: 6\t| Iteration: 400 \t| Log-Likelihood:-3.1808439613467727 \t|  theta: tensor([[0.0498, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.337628  \n",
      "Run: 6\t| Iteration: 500 \t| Log-Likelihood:-3.180843942631645 \t|  theta: tensor([[0.0498, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.301267  \n",
      "Run: 6\t| Iteration: 600 \t| Log-Likelihood:-3.1808439335361105 \t|  theta: tensor([[0.0498, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.308347  \n",
      "Run: 6\t| Iteration: 700 \t| Log-Likelihood:-3.1808439260050805 \t|  theta: tensor([[0.0498, 2.9997]], requires_grad=True)  |  Time needed: 0:00:11.879857  \n",
      "Run: 6\t| Iteration: 800 \t| Log-Likelihood:-3.180843919176562 \t|  theta: tensor([[0.0498, 2.9997]], requires_grad=True)  |  Time needed: 0:00:10.179323  \n",
      "Run: 6\t| Iteration: 900 \t| Log-Likelihood:-3.1808439130505537 \t|  theta: tensor([[0.0498, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.262812  \n",
      "Run: 6\t| Iteration: 1000 \t| Log-Likelihood:-3.1808439076270534 \t|  theta: tensor([[0.0498, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.296207  \n",
      "Run: 6\t| Iteration: 1100 \t| Log-Likelihood:-3.1808439029060627 \t|  theta: tensor([[0.0498, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.278604  \n",
      "Run: 6\t| Iteration: 1200 \t| Log-Likelihood:-3.180843898887578 \t|  theta: tensor([[0.0498, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.289295  \n",
      "Run: 6\t| Iteration: 1300 \t| Log-Likelihood:-3.1808438955716 \t|  theta: tensor([[0.0498, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.294169  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 7\t| Iteration: 0 \t| Log-Likelihood:-3.179146798661589 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.089055  \n",
      "Run: 7\t| Iteration: 100 \t| Log-Likelihood:-3.1791463980261394 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.146054  \n",
      "Run: 7\t| Iteration: 200 \t| Log-Likelihood:-3.1791460780919127 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.110034  \n",
      "Run: 7\t| Iteration: 300 \t| Log-Likelihood:-3.1791459095793693 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.142522  \n",
      "Run: 7\t| Iteration: 400 \t| Log-Likelihood:-3.1791457154402005 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.370794  \n",
      "Run: 7\t| Iteration: 500 \t| Log-Likelihood:-3.179145556168096 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:13.611234  \n",
      "Run: 7\t| Iteration: 600 \t| Log-Likelihood:-3.1791455036092966 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:11.781352  \n",
      "Run: 7\t| Iteration: 700 \t| Log-Likelihood:-3.179145392097322 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:10.895160  \n",
      "Run: 7\t| Iteration: 800 \t| Log-Likelihood:-3.1791453201892153 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:14.167236  \n",
      "Run: 7\t| Iteration: 900 \t| Log-Likelihood:-3.179145322099843 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:11.303001  \n",
      "Run: 7\t| Iteration: 1000 \t| Log-Likelihood:-3.1791452674214344 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:11.776004  \n",
      "Run: 7\t| Iteration: 1100 \t| Log-Likelihood:-3.1791452263794437 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:10.954375  \n",
      "Run: 7\t| Iteration: 1200 \t| Log-Likelihood:-3.1791451918915166 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.932997  \n",
      "Run: 7\t| Iteration: 1300 \t| Log-Likelihood:-3.179145160232351 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:10.163354  \n",
      "Run: 7\t| Iteration: 1400 \t| Log-Likelihood:-3.1791451374285815 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.199547  \n",
      "Run: 7\t| Iteration: 1500 \t| Log-Likelihood:-3.1791451853434363 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:11.448974  \n",
      "Run: 7\t| Iteration: 1600 \t| Log-Likelihood:-3.1791451780861366 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:10.592222  \n",
      "Run: 7\t| Iteration: 1700 \t| Log-Likelihood:-3.179145167810727 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:11.847436  \n",
      "Run: 7\t| Iteration: 1800 \t| Log-Likelihood:-3.1791451545172094 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:16.848921  \n",
      "Run: 7\t| Iteration: 1900 \t| Log-Likelihood:-3.179145145656174 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:11.217855  \n",
      "Run: 7\t| Iteration: 2000 \t| Log-Likelihood:-3.1791451375023256 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:12.992913  \n",
      "Run: 7\t| Iteration: 2100 \t| Log-Likelihood:-3.179145122605069 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:10.542813  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 8\t| Iteration: 0 \t| Log-Likelihood:-3.17698427065958 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.096785  \n",
      "Run: 8\t| Iteration: 100 \t| Log-Likelihood:-3.1769837382084094 \t|  theta: tensor([[0.0500, 2.9998]], requires_grad=True)  |  Time needed: 0:00:13.797132  \n",
      "Run: 8\t| Iteration: 200 \t| Log-Likelihood:-3.176983370740844 \t|  theta: tensor([[0.0500, 2.9996]], requires_grad=True)  |  Time needed: 0:00:15.455810  \n",
      "Run: 8\t| Iteration: 300 \t| Log-Likelihood:-3.1769830124546603 \t|  theta: tensor([[0.0500, 2.9994]], requires_grad=True)  |  Time needed: 0:00:20.580640  \n",
      "Run: 8\t| Iteration: 400 \t| Log-Likelihood:-3.1769827733205602 \t|  theta: tensor([[0.0500, 2.9992]], requires_grad=True)  |  Time needed: 0:00:18.669434  \n",
      "Run: 8\t| Iteration: 500 \t| Log-Likelihood:-3.1769825837272507 \t|  theta: tensor([[0.0500, 2.9991]], requires_grad=True)  |  Time needed: 0:00:17.061815  \n",
      "Run: 8\t| Iteration: 600 \t| Log-Likelihood:-3.176982439616354 \t|  theta: tensor([[0.0500, 2.9990]], requires_grad=True)  |  Time needed: 0:00:17.691125  \n",
      "Run: 8\t| Iteration: 700 \t| Log-Likelihood:-3.1769823266578396 \t|  theta: tensor([[0.0500, 2.9989]], requires_grad=True)  |  Time needed: 0:00:22.615687  \n",
      "Run: 8\t| Iteration: 800 \t| Log-Likelihood:-3.176982236548373 \t|  theta: tensor([[0.0500, 2.9988]], requires_grad=True)  |  Time needed: 0:00:11.321153  \n",
      "Run: 8\t| Iteration: 900 \t| Log-Likelihood:-3.1769822202287354 \t|  theta: tensor([[0.0500, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.413288  \n",
      "Run: 8\t| Iteration: 1000 \t| Log-Likelihood:-3.1769821561467113 \t|  theta: tensor([[0.0500, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.512407  \n",
      "Run: 8\t| Iteration: 1100 \t| Log-Likelihood:-3.1769820872328234 \t|  theta: tensor([[0.0500, 2.9986]], requires_grad=True)  |  Time needed: 0:00:11.965247  \n",
      "Run: 8\t| Iteration: 1200 \t| Log-Likelihood:-3.1769820469786167 \t|  theta: tensor([[0.0500, 2.9985]], requires_grad=True)  |  Time needed: 0:00:15.141065  \n",
      "Run: 8\t| Iteration: 1300 \t| Log-Likelihood:-3.176982070879124 \t|  theta: tensor([[0.0500, 2.9985]], requires_grad=True)  |  Time needed: 0:00:19.058504  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 8\t| Iteration: 1400 \t| Log-Likelihood:-3.176982041719825 \t|  theta: tensor([[0.0500, 2.9984]], requires_grad=True)  |  Time needed: 0:00:18.536151  \n",
      "Run: 8\t| Iteration: 1500 \t| Log-Likelihood:-3.176982011654757 \t|  theta: tensor([[0.0500, 2.9984]], requires_grad=True)  |  Time needed: 0:00:18.299808  \n",
      "Run: 8\t| Iteration: 1600 \t| Log-Likelihood:-3.1769819870897513 \t|  theta: tensor([[0.0500, 2.9983]], requires_grad=True)  |  Time needed: 0:00:17.564148  \n",
      "Run: 8\t| Iteration: 1700 \t| Log-Likelihood:-3.1769819757948454 \t|  theta: tensor([[0.0500, 2.9983]], requires_grad=True)  |  Time needed: 0:00:11.626445  \n",
      "Run: 8\t| Iteration: 1800 \t| Log-Likelihood:-3.1769819614795205 \t|  theta: tensor([[0.0500, 2.9983]], requires_grad=True)  |  Time needed: 0:00:13.593133  \n",
      "Run: 8\t| Iteration: 1900 \t| Log-Likelihood:-3.1769819515943687 \t|  theta: tensor([[0.0500, 2.9983]], requires_grad=True)  |  Time needed: 0:00:19.409664  \n",
      "Run: 8\t| Iteration: 2000 \t| Log-Likelihood:-3.176981938688796 \t|  theta: tensor([[0.0500, 2.9982]], requires_grad=True)  |  Time needed: 0:00:16.062812  \n",
      "Run: 8\t| Iteration: 2100 \t| Log-Likelihood:-3.1769819302133944 \t|  theta: tensor([[0.0500, 2.9982]], requires_grad=True)  |  Time needed: 0:00:15.719382  \n",
      "Run: 8\t| Iteration: 2200 \t| Log-Likelihood:-3.1769819820475056 \t|  theta: tensor([[0.0500, 2.9982]], requires_grad=True)  |  Time needed: 0:00:18.219262  \n",
      "Run: 8\t| Iteration: 2300 \t| Log-Likelihood:-3.176981974981849 \t|  theta: tensor([[0.0500, 2.9982]], requires_grad=True)  |  Time needed: 0:00:16.358672  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 9\t| Iteration: 0 \t| Log-Likelihood:-3.1741293555038768 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.107965  \n",
      "Run: 9\t| Iteration: 100 \t| Log-Likelihood:-3.1741284451223297 \t|  theta: tensor([[0.0498, 2.9998]], requires_grad=True)  |  Time needed: 0:00:10.771741  \n",
      "Run: 9\t| Iteration: 200 \t| Log-Likelihood:-3.174128205915642 \t|  theta: tensor([[0.0498, 2.9997]], requires_grad=True)  |  Time needed: 0:00:10.722032  \n",
      "Run: 9\t| Iteration: 300 \t| Log-Likelihood:-3.1741279970433953 \t|  theta: tensor([[0.0498, 2.9995]], requires_grad=True)  |  Time needed: 0:00:10.781329  \n",
      "Run: 9\t| Iteration: 400 \t| Log-Likelihood:-3.17412779504319 \t|  theta: tensor([[0.0498, 2.9994]], requires_grad=True)  |  Time needed: 0:00:10.736921  \n",
      "Run: 9\t| Iteration: 500 \t| Log-Likelihood:-3.17412766616402 \t|  theta: tensor([[0.0498, 2.9993]], requires_grad=True)  |  Time needed: 0:00:10.667934  \n",
      "Run: 9\t| Iteration: 600 \t| Log-Likelihood:-3.1741275715712884 \t|  theta: tensor([[0.0498, 2.9992]], requires_grad=True)  |  Time needed: 0:00:10.897505  \n",
      "Run: 9\t| Iteration: 700 \t| Log-Likelihood:-3.1741274913101685 \t|  theta: tensor([[0.0498, 2.9991]], requires_grad=True)  |  Time needed: 0:00:11.611260  \n",
      "Run: 9\t| Iteration: 800 \t| Log-Likelihood:-3.1741274357955724 \t|  theta: tensor([[0.0498, 2.9990]], requires_grad=True)  |  Time needed: 0:00:12.513533  \n",
      "Run: 9\t| Iteration: 900 \t| Log-Likelihood:-3.174127386587427 \t|  theta: tensor([[0.0498, 2.9989]], requires_grad=True)  |  Time needed: 0:00:14.057419  \n",
      "Run: 9\t| Iteration: 1000 \t| Log-Likelihood:-3.174127345993622 \t|  theta: tensor([[0.0498, 2.9989]], requires_grad=True)  |  Time needed: 0:00:13.768718  \n",
      "Run: 9\t| Iteration: 1100 \t| Log-Likelihood:-3.1741273686941165 \t|  theta: tensor([[0.0498, 2.9988]], requires_grad=True)  |  Time needed: 0:00:14.160854  \n",
      "Run: 9\t| Iteration: 1200 \t| Log-Likelihood:-3.17412733086749 \t|  theta: tensor([[0.0498, 2.9988]], requires_grad=True)  |  Time needed: 0:00:14.121260  \n",
      "Run: 9\t| Iteration: 1300 \t| Log-Likelihood:-3.1741272921183725 \t|  theta: tensor([[0.0498, 2.9987]], requires_grad=True)  |  Time needed: 0:00:13.514263  \n",
      "Run: 9\t| Iteration: 1400 \t| Log-Likelihood:-3.1741272668623868 \t|  theta: tensor([[0.0498, 2.9987]], requires_grad=True)  |  Time needed: 0:00:10.822223  \n",
      "Run: 9\t| Iteration: 1500 \t| Log-Likelihood:-3.174127251522638 \t|  theta: tensor([[0.0498, 2.9987]], requires_grad=True)  |  Time needed: 0:00:10.701836  \n",
      "Run: 9\t| Iteration: 1600 \t| Log-Likelihood:-3.1741273002135206 \t|  theta: tensor([[0.0498, 2.9987]], requires_grad=True)  |  Time needed: 0:00:10.743949  \n",
      "Run: 9\t| Iteration: 1700 \t| Log-Likelihood:-3.1741272862751586 \t|  theta: tensor([[0.0498, 2.9986]], requires_grad=True)  |  Time needed: 0:00:13.981351  \n",
      "Run: 9\t| Iteration: 1800 \t| Log-Likelihood:-3.1741272730374885 \t|  theta: tensor([[0.0498, 2.9986]], requires_grad=True)  |  Time needed: 0:00:19.157583  \n",
      "Run: 9\t| Iteration: 1900 \t| Log-Likelihood:-3.1741272567752117 \t|  theta: tensor([[0.0498, 2.9986]], requires_grad=True)  |  Time needed: 0:00:16.470818  \n",
      "Run: 9\t| Iteration: 2000 \t| Log-Likelihood:-3.1741272449389197 \t|  theta: tensor([[0.0498, 2.9986]], requires_grad=True)  |  Time needed: 0:00:17.579754  \n",
      "Run: 9\t| Iteration: 2100 \t| Log-Likelihood:-3.174127233803314 \t|  theta: tensor([[0.0498, 2.9985]], requires_grad=True)  |  Time needed: 0:00:17.976305  \n",
      "Sampling Data.../...\\...\n",
      "Data sampled\n",
      "Run: 10\t| Iteration: 0 \t| Log-Likelihood:-3.1872386700919013 \t|  theta: tensor([[0.0500, 3.0000]], requires_grad=True)  |  Time needed: 0:00:00.091273  \n",
      "Run: 10\t| Iteration: 100 \t| Log-Likelihood:-3.187238327783006 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:11.029506  \n",
      "Run: 10\t| Iteration: 200 \t| Log-Likelihood:-3.1872382431450488 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.176363  \n",
      "Run: 10\t| Iteration: 300 \t| Log-Likelihood:-3.187238105125084 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:10.019841  \n",
      "Run: 10\t| Iteration: 400 \t| Log-Likelihood:-3.1872380558270197 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.012467  \n",
      "Run: 10\t| Iteration: 500 \t| Log-Likelihood:-3.187237988737768 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.338277  \n",
      "Run: 10\t| Iteration: 600 \t| Log-Likelihood:-3.1872379267221214 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.082979  \n",
      "Run: 10\t| Iteration: 700 \t| Log-Likelihood:-3.1872378665381937 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:08.998751  \n",
      "Run: 10\t| Iteration: 800 \t| Log-Likelihood:-3.1872378326915864 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.017198  \n",
      "Run: 10\t| Iteration: 900 \t| Log-Likelihood:-3.187237801679439 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:08.971855  \n",
      "Run: 10\t| Iteration: 1000 \t| Log-Likelihood:-3.187237836831684 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.459950  \n",
      "Run: 10\t| Iteration: 1100 \t| Log-Likelihood:-3.1872378168754585 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.040701  \n",
      "Run: 10\t| Iteration: 1200 \t| Log-Likelihood:-3.1872378013997404 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:08.924252  \n",
      "Run: 10\t| Iteration: 1300 \t| Log-Likelihood:-3.1872377903579325 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:08.861529  \n",
      "Run: 10\t| Iteration: 1400 \t| Log-Likelihood:-3.187237780024736 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:08.852767  \n",
      "Run: 10\t| Iteration: 1500 \t| Log-Likelihood:-3.1872377704001527 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:08.842922  \n",
      "Run: 10\t| Iteration: 1600 \t| Log-Likelihood:-3.1872377577588837 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:08.848895  \n",
      "Run: 10\t| Iteration: 1700 \t| Log-Likelihood:-3.1872377458262267 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:08.874404  \n",
      "Run: 10\t| Iteration: 1800 \t| Log-Likelihood:-3.187237738327477 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:08.890647  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Ascent\n",
    "'''\n",
    "#X = torch.from_numpy(X)\n",
    "# Set parameters here\n",
    "n_iterations = 5000 #max number of iterations # TODO: alternatively/ additionally a error-based threshold?\n",
    "lr = 0.001 # learning rate / stepsize\n",
    "n_runs = 10\n",
    "\n",
    "# Initializing Loss as minus infinity to make sure first run achieves higher likelihood\n",
    "max_likelihood = -1*np.inf\n",
    "# trajectory_dict is a cache to save the gradient ascent trajectory of all gradient ascent runs\n",
    "trajectory_dict = {}\n",
    "\n",
    "theta_loc_list = []\n",
    "\n",
    "# Running Gradient Ascent multiple (M=n_runs) times\n",
    "\n",
    "for run in range(n_runs):\n",
    "    \n",
    "    # Create sampels of given model\n",
    "    print('Sampling Data.../...\\...')\n",
    "    X = gaussian_mixture_model_sample(n, means, covs, weights, test=False) # we can alternatively use pytorchs MixtureFamily\n",
    "    X = torch.from_numpy(X)\n",
    "    print('Data sampled')\n",
    "    \n",
    "    # Create/ Initialize variable ' TODO: make initialization more flexible\n",
    "    theta = torch.tensor([[0.05, 3]], requires_grad = True)\n",
    "\n",
    "    # Run complete Gradient ascent\n",
    "    theta, L, trajectory = gradient_ascent_torch2(func = LogLikelihood,\n",
    "                                           param=theta,\n",
    "                                           data=X,\n",
    "                                           accuracy = 10**-16, \n",
    "                                           learningrate=lr,\n",
    "                                           run_id=run,\n",
    "                                           print_info=True)\n",
    "\n",
    "    # Save optimization trajectory\n",
    "    trajectory_dict.update({run : trajectory})\n",
    "    theta_loc_list.append(theta.clone().data.numpy())\n",
    "\n",
    "    # Updating Quantities if new max is found\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04994409 2.9990084 ]\n",
      " [0.0497372  2.999747  ]\n",
      " [0.05008504 3.0001652 ]\n",
      " [0.04995714 3.0000162 ]\n",
      " [0.04967513 2.9992764 ]\n",
      " [0.04975339 2.9995391 ]\n",
      " [0.05007071 2.9984834 ]\n",
      " [0.04996041 2.9981716 ]\n",
      " [0.04976925 2.9985156 ]\n",
      " [0.05011119 2.9989712 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(theta_loc_list).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04990635 2.9991894 ]]\n"
     ]
    }
   ],
   "source": [
    "theta_loc = np.mean(theta_loc_list, axis = 0)\n",
    "print(theta_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\t| Iteration: 0 \t| Log-Likelihood:-3.442436769318044 \t|  theta: tensor([[0.2288, 0.9123]], requires_grad=True)  |  Time needed: 0:00:00.123140  \n",
      "Run: 1\t| Iteration: 100 \t| Log-Likelihood:-3.1904917286184666 \t|  theta: tensor([[0.4291, 1.0580]], requires_grad=True)  |  Time needed: 0:00:09.876190  \n",
      "Run: 1\t| Iteration: 200 \t| Log-Likelihood:-3.190462758827881 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.987045  \n",
      "Run: 1\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327526622 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.691370  \n",
      "Run: 1\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.061423  \n",
      "Run: 1\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.865562  \n",
      "Run: 1\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.625770  \n",
      "Run: 1\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.446317  \n",
      "Run: 1\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.476868  \n",
      "Run: 1\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.487777  \n",
      "Run: 2\t| Iteration: 0 \t| Log-Likelihood:-4.918294410394803 \t|  theta: tensor([[0.2563, 4.5622]], requires_grad=True)  |  Time needed: 0:00:00.098994  \n",
      "Run: 2\t| Iteration: 100 \t| Log-Likelihood:-3.3134585911658165 \t|  theta: tensor([[0.0501, 3.4427]], requires_grad=True)  |  Time needed: 0:00:09.487980  \n",
      "Run: 2\t| Iteration: 200 \t| Log-Likelihood:-3.1974310068889045 \t|  theta: tensor([[0.0501, 3.1251]], requires_grad=True)  |  Time needed: 0:00:09.355451  \n",
      "Run: 2\t| Iteration: 300 \t| Log-Likelihood:-3.1880652211592597 \t|  theta: tensor([[0.0501, 3.0349]], requires_grad=True)  |  Time needed: 0:00:09.371777  \n",
      "Run: 2\t| Iteration: 400 \t| Log-Likelihood:-3.187304999276503 \t|  theta: tensor([[0.0501, 3.0091]], requires_grad=True)  |  Time needed: 0:00:09.294618  \n",
      "Run: 2\t| Iteration: 500 \t| Log-Likelihood:-3.1872432122628376 \t|  theta: tensor([[0.0501, 3.0018]], requires_grad=True)  |  Time needed: 0:00:09.321047  \n",
      "Run: 2\t| Iteration: 600 \t| Log-Likelihood:-3.187238164289986 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.274350  \n",
      "Run: 2\t| Iteration: 700 \t| Log-Likelihood:-3.1872377700549466 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.397667  \n",
      "Run: 2\t| Iteration: 800 \t| Log-Likelihood:-3.1872377665553207 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.383601  \n",
      "Run: 2\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564330603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.389204  \n",
      "Run: 3\t| Iteration: 0 \t| Log-Likelihood:-3.4710208117551975 \t|  theta: tensor([[0.1386, 1.2304]], requires_grad=True)  |  Time needed: 0:00:00.094392  \n",
      "Run: 3\t| Iteration: 100 \t| Log-Likelihood:-3.190593426477704 \t|  theta: tensor([[0.4249, 1.0593]], requires_grad=True)  |  Time needed: 0:00:09.299554  \n",
      "Run: 3\t| Iteration: 200 \t| Log-Likelihood:-3.1904627900652263 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.264745  \n",
      "Run: 3\t| Iteration: 300 \t| Log-Likelihood:-3.190462703031275 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.247498  \n",
      "Run: 3\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.359659  \n",
      "Run: 3\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.340558  \n",
      "Run: 3\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.257492  \n",
      "Run: 3\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.235181  \n",
      "Run: 3\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.211989  \n",
      "Run: 3\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.276229  \n",
      "Run: 4\t| Iteration: 0 \t| Log-Likelihood:-3.337626838834826 \t|  theta: tensor([[0.2181, 2.7836]], requires_grad=True)  |  Time needed: 0:00:00.097309  \n",
      "Run: 4\t| Iteration: 100 \t| Log-Likelihood:-3.1896801401493597 \t|  theta: tensor([[0.0501, 2.9370]], requires_grad=True)  |  Time needed: 0:00:09.240375  \n",
      "Run: 4\t| Iteration: 200 \t| Log-Likelihood:-3.1874367887059623 \t|  theta: tensor([[0.0501, 2.9812]], requires_grad=True)  |  Time needed: 0:00:09.230520  \n",
      "Run: 4\t| Iteration: 300 \t| Log-Likelihood:-3.187253919896528 \t|  theta: tensor([[0.0501, 2.9938]], requires_grad=True)  |  Time needed: 0:00:09.208861  \n",
      "Run: 4\t| Iteration: 400 \t| Log-Likelihood:-3.1872390379000026 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.275904  \n",
      "Run: 4\t| Iteration: 500 \t| Log-Likelihood:-3.1872378334353613 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.172871  \n",
      "Run: 4\t| Iteration: 600 \t| Log-Likelihood:-3.1872377276360484 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.204811  \n",
      "Run: 4\t| Iteration: 700 \t| Log-Likelihood:-3.1872377345331544 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.226808  \n",
      "Run: 4\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.196660  \n",
      "Run: 4\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.318535  \n",
      "Run: 5\t| Iteration: 0 \t| Log-Likelihood:-3.524774532143942 \t|  theta: tensor([[0.4269, 1.4018]], requires_grad=True)  |  Time needed: 0:00:00.098443  \n",
      "Run: 5\t| Iteration: 100 \t| Log-Likelihood:-3.1905045770674856 \t|  theta: tensor([[0.4284, 1.0584]], requires_grad=True)  |  Time needed: 0:00:09.549260  \n",
      "Run: 5\t| Iteration: 200 \t| Log-Likelihood:-3.1904627105229846 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.429677  \n",
      "Run: 5\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327628394 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.406399  \n",
      "Run: 5\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.468306  \n",
      "Run: 5\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.379805  \n",
      "Run: 5\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.456938  \n",
      "Run: 5\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.403540  \n",
      "Run: 5\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.300486  \n",
      "Run: 5\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.298005  \n",
      "Run: 6\t| Iteration: 0 \t| Log-Likelihood:-3.4258430805722204 \t|  theta: tensor([[0.0709, 2.3731]], requires_grad=True)  |  Time needed: 0:00:00.089863  \n",
      "Run: 6\t| Iteration: 100 \t| Log-Likelihood:-3.2097000547771835 \t|  theta: tensor([[0.0502, 2.8110]], requires_grad=True)  |  Time needed: 0:00:09.410527  \n",
      "Run: 6\t| Iteration: 200 \t| Log-Likelihood:-3.189088005339644 \t|  theta: tensor([[0.0501, 2.9451]], requires_grad=True)  |  Time needed: 0:00:09.391160  \n",
      "Run: 6\t| Iteration: 300 \t| Log-Likelihood:-3.1873885332104517 \t|  theta: tensor([[0.0501, 2.9835]], requires_grad=True)  |  Time needed: 0:00:09.416972  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 6\t| Iteration: 400 \t| Log-Likelihood:-3.187249991221496 \t|  theta: tensor([[0.0501, 2.9945]], requires_grad=True)  |  Time needed: 0:00:09.476408  \n",
      "Run: 6\t| Iteration: 500 \t| Log-Likelihood:-3.1872387590561537 \t|  theta: tensor([[0.0501, 2.9976]], requires_grad=True)  |  Time needed: 0:00:09.356054  \n",
      "Run: 6\t| Iteration: 600 \t| Log-Likelihood:-3.1872378187943826 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.503719  \n",
      "Run: 6\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254989575 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.582346  \n",
      "Run: 6\t| Iteration: 800 \t| Log-Likelihood:-3.1872377343266196 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.408098  \n",
      "Run: 6\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.430640  \n",
      "Run: 7\t| Iteration: 0 \t| Log-Likelihood:-5.564680138849629 \t|  theta: tensor([[0.1728, 4.8930]], requires_grad=True)  |  Time needed: 0:00:00.088342  \n",
      "Run: 7\t| Iteration: 100 \t| Log-Likelihood:-3.372640741849926 \t|  theta: tensor([[0.0501, 3.5367]], requires_grad=True)  |  Time needed: 0:00:09.326221  \n",
      "Run: 7\t| Iteration: 200 \t| Log-Likelihood:-3.202198969227424 \t|  theta: tensor([[0.0501, 3.1518]], requires_grad=True)  |  Time needed: 0:00:09.401067  \n",
      "Run: 7\t| Iteration: 300 \t| Log-Likelihood:-3.1884515797942443 \t|  theta: tensor([[0.0501, 3.0424]], requires_grad=True)  |  Time needed: 0:00:09.389980  \n",
      "Run: 7\t| Iteration: 400 \t| Log-Likelihood:-3.1873364127101276 \t|  theta: tensor([[0.0501, 3.0113]], requires_grad=True)  |  Time needed: 0:00:09.448890  \n",
      "Run: 7\t| Iteration: 500 \t| Log-Likelihood:-3.187245764951379 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.466887  \n",
      "Run: 7\t| Iteration: 600 \t| Log-Likelihood:-3.1872384024526625 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.530155  \n",
      "Run: 7\t| Iteration: 700 \t| Log-Likelihood:-3.1872377980187583 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.378236  \n",
      "Run: 7\t| Iteration: 800 \t| Log-Likelihood:-3.1872377716348312 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.381974  \n",
      "Run: 7\t| Iteration: 900 \t| Log-Likelihood:-3.1872377565351164 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.444945  \n",
      "Run: 8\t| Iteration: 0 \t| Log-Likelihood:-3.718629794538104 \t|  theta: tensor([[0.1301, 1.9189]], requires_grad=True)  |  Time needed: 0:00:00.092774  \n",
      "Run: 8\t| Iteration: 100 \t| Log-Likelihood:-3.324321676770126 \t|  theta: tensor([[0.0517, 2.5291]], requires_grad=True)  |  Time needed: 0:00:09.344462  \n",
      "Run: 8\t| Iteration: 200 \t| Log-Likelihood:-3.1992610538513886 \t|  theta: tensor([[0.0502, 2.8615]], requires_grad=True)  |  Time needed: 0:00:09.386762  \n",
      "Run: 8\t| Iteration: 300 \t| Log-Likelihood:-3.188222926546947 \t|  theta: tensor([[0.0501, 2.9596]], requires_grad=True)  |  Time needed: 0:00:09.365288  \n",
      "Run: 8\t| Iteration: 400 \t| Log-Likelihood:-3.187317965805051 \t|  theta: tensor([[0.0501, 2.9877]], requires_grad=True)  |  Time needed: 0:00:09.369470  \n",
      "Run: 8\t| Iteration: 500 \t| Log-Likelihood:-3.1872442865986077 \t|  theta: tensor([[0.0501, 2.9957]], requires_grad=True)  |  Time needed: 0:00:09.602573  \n",
      "Run: 8\t| Iteration: 600 \t| Log-Likelihood:-3.1872382911977963 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.614439  \n",
      "Run: 8\t| Iteration: 700 \t| Log-Likelihood:-3.1872377957295273 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.378618  \n",
      "Run: 8\t| Iteration: 800 \t| Log-Likelihood:-3.187237729901938 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.397377  \n",
      "Run: 8\t| Iteration: 900 \t| Log-Likelihood:-3.1872377341267497 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.345455  \n",
      "Run: 9\t| Iteration: 0 \t| Log-Likelihood:-3.704659445161379 \t|  theta: tensor([[0.1354, 1.6382]], requires_grad=True)  |  Time needed: 0:00:00.095555  \n",
      "Run: 9\t| Iteration: 100 \t| Log-Likelihood:-3.1923441561440304 \t|  theta: tensor([[0.4039, 1.0691]], requires_grad=True)  |  Time needed: 0:00:09.290741  \n",
      "Run: 9\t| Iteration: 200 \t| Log-Likelihood:-3.1904643248742057 \t|  theta: tensor([[0.4320, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.318730  \n",
      "Run: 9\t| Iteration: 300 \t| Log-Likelihood:-3.190462674557229 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.358598  \n",
      "Run: 9\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731270542 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.306698  \n",
      "Run: 9\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.426764  \n",
      "Run: 9\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.373767  \n",
      "Run: 9\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.356827  \n",
      "Run: 9\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.438655  \n",
      "Run: 9\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.382028  \n",
      "Run: 10\t| Iteration: 0 \t| Log-Likelihood:-3.6253473079985294 \t|  theta: tensor([[0.5608, 0.7701]], requires_grad=True)  |  Time needed: 0:00:00.093633  \n",
      "Run: 10\t| Iteration: 100 \t| Log-Likelihood:-3.190516323230547 \t|  theta: tensor([[0.4381, 1.0556]], requires_grad=True)  |  Time needed: 0:00:09.570844  \n",
      "Run: 10\t| Iteration: 200 \t| Log-Likelihood:-3.19046275147796 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.518247  \n",
      "Run: 10\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029700667 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.508042  \n",
      "Run: 10\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.531808  \n",
      "Run: 10\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.509653  \n",
      "Run: 10\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.444684  \n",
      "Run: 10\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.514680  \n",
      "Run: 10\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.537666  \n",
      "Run: 10\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.463015  \n",
      "Run: 11\t| Iteration: 0 \t| Log-Likelihood:-3.2790165720811646 \t|  theta: tensor([[0.0395, 2.6236]], requires_grad=True)  |  Time needed: 0:00:00.094344  \n",
      "Run: 11\t| Iteration: 100 \t| Log-Likelihood:-3.1947675758111194 \t|  theta: tensor([[0.0501, 2.8902]], requires_grad=True)  |  Time needed: 0:00:09.588250  \n",
      "Run: 11\t| Iteration: 200 \t| Log-Likelihood:-3.187853220253897 \t|  theta: tensor([[0.0501, 2.9678]], requires_grad=True)  |  Time needed: 0:00:09.398357  \n",
      "Run: 11\t| Iteration: 300 \t| Log-Likelihood:-3.1872878835510865 \t|  theta: tensor([[0.0501, 2.9900]], requires_grad=True)  |  Time needed: 0:00:09.458781  \n",
      "Run: 11\t| Iteration: 400 \t| Log-Likelihood:-3.1872418393959245 \t|  theta: tensor([[0.0501, 2.9963]], requires_grad=True)  |  Time needed: 0:00:09.443410  \n",
      "Run: 11\t| Iteration: 500 \t| Log-Likelihood:-3.1872380656639887 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.400699  \n",
      "Run: 11\t| Iteration: 600 \t| Log-Likelihood:-3.18723779057671 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.840538  \n",
      "Run: 11\t| Iteration: 700 \t| Log-Likelihood:-3.1872377285761333 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.534671  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 11\t| Iteration: 800 \t| Log-Likelihood:-3.187237734010984 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.545120  \n",
      "Run: 11\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.499638  \n",
      "Run: 12\t| Iteration: 0 \t| Log-Likelihood:-3.3735121898983773 \t|  theta: tensor([[0.0702, 2.4527]], requires_grad=True)  |  Time needed: 0:00:00.097315  \n",
      "Run: 12\t| Iteration: 100 \t| Log-Likelihood:-3.203844015556984 \t|  theta: tensor([[0.0502, 2.8374]], requires_grad=True)  |  Time needed: 0:00:09.472834  \n",
      "Run: 12\t| Iteration: 200 \t| Log-Likelihood:-3.188601647195543 \t|  theta: tensor([[0.0501, 2.9527]], requires_grad=True)  |  Time needed: 0:00:09.435150  \n",
      "Run: 12\t| Iteration: 300 \t| Log-Likelihood:-3.1873488688651705 \t|  theta: tensor([[0.0501, 2.9857]], requires_grad=True)  |  Time needed: 0:00:09.466254  \n",
      "Run: 12\t| Iteration: 400 \t| Log-Likelihood:-3.187246814396041 \t|  theta: tensor([[0.0501, 2.9951]], requires_grad=True)  |  Time needed: 0:00:09.730912  \n",
      "Run: 12\t| Iteration: 500 \t| Log-Likelihood:-3.1872384656648878 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.991970  \n",
      "Run: 12\t| Iteration: 600 \t| Log-Likelihood:-3.187237804901599 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.441839  \n",
      "Run: 12\t| Iteration: 700 \t| Log-Likelihood:-3.187237727517275 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.362553  \n",
      "Run: 12\t| Iteration: 800 \t| Log-Likelihood:-3.187237734220697 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.377756  \n",
      "Run: 12\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.478695  \n",
      "Run: 13\t| Iteration: 0 \t| Log-Likelihood:-7.0102335811947585 \t|  theta: tensor([[0.1735, 0.3156]], requires_grad=True)  |  Time needed: 0:00:00.098306  \n",
      "Run: 13\t| Iteration: 100 \t| Log-Likelihood:-3.1904716990258515 \t|  theta: tensor([[0.4308, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.367765  \n",
      "Run: 13\t| Iteration: 200 \t| Log-Likelihood:-3.19046271091564 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.387577  \n",
      "Run: 13\t| Iteration: 300 \t| Log-Likelihood:-3.190462732737007 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.371439  \n",
      "Run: 13\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.386732  \n",
      "Run: 13\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.320904  \n",
      "Run: 13\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.350451  \n",
      "Run: 13\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.370474  \n",
      "Run: 13\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.417807  \n",
      "Run: 13\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.451659  \n",
      "Run: 14\t| Iteration: 0 \t| Log-Likelihood:-3.8395708205602763 \t|  theta: tensor([[0.3868, 3.7031]], requires_grad=True)  |  Time needed: 0:00:00.097369  \n",
      "Run: 14\t| Iteration: 100 \t| Log-Likelihood:-3.2128706710810118 \t|  theta: tensor([[0.0501, 3.1990]], requires_grad=True)  |  Time needed: 0:00:09.323345  \n",
      "Run: 14\t| Iteration: 200 \t| Log-Likelihood:-3.1893151878960326 \t|  theta: tensor([[0.0501, 3.0559]], requires_grad=True)  |  Time needed: 0:00:09.497354  \n",
      "Run: 14\t| Iteration: 300 \t| Log-Likelihood:-3.187406575938029 \t|  theta: tensor([[0.0501, 3.0151]], requires_grad=True)  |  Time needed: 0:00:09.374683  \n",
      "Run: 14\t| Iteration: 400 \t| Log-Likelihood:-3.1872514767611997 \t|  theta: tensor([[0.0501, 3.0035]], requires_grad=True)  |  Time needed: 0:00:09.298506  \n",
      "Run: 14\t| Iteration: 500 \t| Log-Likelihood:-3.1872388663769606 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.345573  \n",
      "Run: 14\t| Iteration: 600 \t| Log-Likelihood:-3.1872378509819934 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.338294  \n",
      "Run: 14\t| Iteration: 700 \t| Log-Likelihood:-3.187237778472953 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.395046  \n",
      "Run: 14\t| Iteration: 800 \t| Log-Likelihood:-3.1872377604842868 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.253602  \n",
      "Run: 14\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.343992  \n",
      "Run: 15\t| Iteration: 0 \t| Log-Likelihood:-3.9680461499366677 \t|  theta: tensor([[0.1219, 4.0772]], requires_grad=True)  |  Time needed: 0:00:00.091979  \n",
      "Run: 15\t| Iteration: 100 \t| Log-Likelihood:-3.247305502469116 \t|  theta: tensor([[0.0501, 3.3051]], requires_grad=True)  |  Time needed: 0:00:09.474691  \n",
      "Run: 15\t| Iteration: 200 \t| Log-Likelihood:-3.192096633453987 \t|  theta: tensor([[0.0501, 3.0860]], requires_grad=True)  |  Time needed: 0:00:09.422714  \n",
      "Run: 15\t| Iteration: 300 \t| Log-Likelihood:-3.187632494364146 \t|  theta: tensor([[0.0501, 3.0237]], requires_grad=True)  |  Time needed: 0:00:09.444299  \n",
      "Run: 15\t| Iteration: 400 \t| Log-Likelihood:-3.1872698557703925 \t|  theta: tensor([[0.0501, 3.0060]], requires_grad=True)  |  Time needed: 0:00:09.486949  \n",
      "Run: 15\t| Iteration: 500 \t| Log-Likelihood:-3.187240365981323 \t|  theta: tensor([[0.0501, 3.0009]], requires_grad=True)  |  Time needed: 0:00:09.720647  \n",
      "Run: 15\t| Iteration: 600 \t| Log-Likelihood:-3.187237946391783 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.513394  \n",
      "Run: 15\t| Iteration: 700 \t| Log-Likelihood:-3.1872377399152447 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.434447  \n",
      "Run: 15\t| Iteration: 800 \t| Log-Likelihood:-3.1872377612770126 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.440630  \n",
      "Run: 15\t| Iteration: 900 \t| Log-Likelihood:-3.187237756276779 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.434340  \n",
      "Run: 16\t| Iteration: 0 \t| Log-Likelihood:-3.366811488675528 \t|  theta: tensor([[0.4247, 0.8717]], requires_grad=True)  |  Time needed: 0:00:00.090041  \n",
      "Run: 16\t| Iteration: 100 \t| Log-Likelihood:-3.190464393733036 \t|  theta: tensor([[0.4339, 1.0567]], requires_grad=True)  |  Time needed: 0:00:09.478006  \n",
      "Run: 16\t| Iteration: 200 \t| Log-Likelihood:-3.1904627342491456 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.456096  \n",
      "Run: 16\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327312696 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.453444  \n",
      "Run: 16\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.500893  \n",
      "Run: 16\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.447053  \n",
      "Run: 16\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.457489  \n",
      "Run: 16\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.474990  \n",
      "Run: 16\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.494922  \n",
      "Run: 16\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.446870  \n",
      "Run: 17\t| Iteration: 0 \t| Log-Likelihood:-3.2450799123374057 \t|  theta: tensor([[0.2775, 1.0633]], requires_grad=True)  |  Time needed: 0:00:00.094858  \n",
      "Run: 17\t| Iteration: 100 \t| Log-Likelihood:-3.1904937736751102 \t|  theta: tensor([[0.4290, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.379912  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 17\t| Iteration: 200 \t| Log-Likelihood:-3.1904627308266917 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.315235  \n",
      "Run: 17\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327541157 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.331843  \n",
      "Run: 17\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.502967  \n",
      "Run: 17\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.457052  \n",
      "Run: 17\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.458332  \n",
      "Run: 17\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.521498  \n",
      "Run: 17\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.352555  \n",
      "Run: 17\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.858318  \n",
      "Run: 18\t| Iteration: 0 \t| Log-Likelihood:-4.034087028669407 \t|  theta: tensor([[0.4779, 1.8449]], requires_grad=True)  |  Time needed: 0:00:00.093210  \n",
      "Run: 18\t| Iteration: 100 \t| Log-Likelihood:-3.294624107518678 \t|  theta: tensor([[0.2972, 1.2232]], requires_grad=True)  |  Time needed: 0:00:09.436669  \n",
      "Run: 18\t| Iteration: 200 \t| Log-Likelihood:-3.190515409862332 \t|  theta: tensor([[0.4278, 1.0585]], requires_grad=True)  |  Time needed: 0:00:09.430891  \n",
      "Run: 18\t| Iteration: 300 \t| Log-Likelihood:-3.1904627502029443 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.409145  \n",
      "Run: 18\t| Iteration: 400 \t| Log-Likelihood:-3.190462673166942 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.467890  \n",
      "Run: 18\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.497420  \n",
      "Run: 18\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.393487  \n",
      "Run: 18\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.461235  \n",
      "Run: 18\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.424257  \n",
      "Run: 18\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.419441  \n",
      "Run: 19\t| Iteration: 0 \t| Log-Likelihood:-3.9838486906896877 \t|  theta: tensor([[0.4961, 2.2727]], requires_grad=True)  |  Time needed: 0:00:00.096627  \n",
      "Run: 19\t| Iteration: 100 \t| Log-Likelihood:-3.221879541008543 \t|  theta: tensor([[0.0503, 2.7653]], requires_grad=True)  |  Time needed: 0:00:09.348166  \n",
      "Run: 19\t| Iteration: 200 \t| Log-Likelihood:-3.1901083005533346 \t|  theta: tensor([[0.0501, 2.9318]], requires_grad=True)  |  Time needed: 0:00:09.298027  \n",
      "Run: 19\t| Iteration: 300 \t| Log-Likelihood:-3.187471806912023 \t|  theta: tensor([[0.0501, 2.9797]], requires_grad=True)  |  Time needed: 0:00:09.456445  \n",
      "Run: 19\t| Iteration: 400 \t| Log-Likelihood:-3.187256801718771 \t|  theta: tensor([[0.0501, 2.9934]], requires_grad=True)  |  Time needed: 0:00:09.346201  \n",
      "Run: 19\t| Iteration: 500 \t| Log-Likelihood:-3.1872393025476096 \t|  theta: tensor([[0.0501, 2.9973]], requires_grad=True)  |  Time needed: 0:00:09.327026  \n",
      "Run: 19\t| Iteration: 600 \t| Log-Likelihood:-3.187237845260484 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.357381  \n",
      "Run: 19\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254508732 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.325349  \n",
      "Run: 19\t| Iteration: 800 \t| Log-Likelihood:-3.187237730946029 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.332155  \n",
      "Run: 19\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.308500  \n",
      "Run: 20\t| Iteration: 0 \t| Log-Likelihood:-3.8824775150623116 \t|  theta: tensor([[0.3691, 1.8021]], requires_grad=True)  |  Time needed: 0:00:00.093095  \n",
      "Run: 20\t| Iteration: 100 \t| Log-Likelihood:-3.218125380214558 \t|  theta: tensor([[0.3464, 1.1288]], requires_grad=True)  |  Time needed: 0:00:09.508734  \n",
      "Run: 20\t| Iteration: 200 \t| Log-Likelihood:-3.1904796362238668 \t|  theta: tensor([[0.4300, 1.0578]], requires_grad=True)  |  Time needed: 0:00:09.538598  \n",
      "Run: 20\t| Iteration: 300 \t| Log-Likelihood:-3.190462747940058 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.524592  \n",
      "Run: 20\t| Iteration: 400 \t| Log-Likelihood:-3.1904627029412826 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.503053  \n",
      "Run: 20\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.528676  \n",
      "Run: 20\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.540234  \n",
      "Run: 20\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.544244  \n",
      "Run: 20\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.528494  \n",
      "Run: 20\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.596829  \n",
      "Run: 21\t| Iteration: 0 \t| Log-Likelihood:-3.8732154056318646 \t|  theta: tensor([[0.5714, 2.9346]], requires_grad=True)  |  Time needed: 0:00:00.092356  \n",
      "Run: 21\t| Iteration: 100 \t| Log-Likelihood:-3.1874558034512632 \t|  theta: tensor([[0.0501, 2.9804]], requires_grad=True)  |  Time needed: 0:00:09.449796  \n",
      "Run: 21\t| Iteration: 200 \t| Log-Likelihood:-3.187255486168676 \t|  theta: tensor([[0.0501, 2.9936]], requires_grad=True)  |  Time needed: 0:00:09.572604  \n",
      "Run: 21\t| Iteration: 300 \t| Log-Likelihood:-3.1872392068916615 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.485808  \n",
      "Run: 21\t| Iteration: 400 \t| Log-Likelihood:-3.187237840178933 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.495950  \n",
      "Run: 21\t| Iteration: 500 \t| Log-Likelihood:-3.187237724665191 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.547416  \n",
      "Run: 21\t| Iteration: 600 \t| Log-Likelihood:-3.187237730880773 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.501363  \n",
      "Run: 21\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.475491  \n",
      "Run: 21\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.522567  \n",
      "Run: 21\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.462756  \n",
      "Run: 22\t| Iteration: 0 \t| Log-Likelihood:-3.3749588118108536 \t|  theta: tensor([[0.4714, 0.8641]], requires_grad=True)  |  Time needed: 0:00:00.095497  \n",
      "Run: 22\t| Iteration: 100 \t| Log-Likelihood:-3.190472778310884 \t|  theta: tensor([[0.4352, 1.0564]], requires_grad=True)  |  Time needed: 0:00:09.420351  \n",
      "Run: 22\t| Iteration: 200 \t| Log-Likelihood:-3.1904627418431386 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.482052  \n",
      "Run: 22\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731334784 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.394981  \n",
      "Run: 22\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.394499  \n",
      "Run: 22\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.803388  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 22\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.586154  \n",
      "Run: 22\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.603714  \n",
      "Run: 22\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.553588  \n",
      "Run: 22\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.537903  \n",
      "Run: 23\t| Iteration: 0 \t| Log-Likelihood:-4.839580678395582 \t|  theta: tensor([[0.2735, 4.5123]], requires_grad=True)  |  Time needed: 0:00:00.094138  \n",
      "Run: 23\t| Iteration: 100 \t| Log-Likelihood:-3.305516181906513 \t|  theta: tensor([[0.0501, 3.4285]], requires_grad=True)  |  Time needed: 0:00:09.414758  \n",
      "Run: 23\t| Iteration: 200 \t| Log-Likelihood:-3.1967910479847417 \t|  theta: tensor([[0.0501, 3.1211]], requires_grad=True)  |  Time needed: 0:00:09.452010  \n",
      "Run: 23\t| Iteration: 300 \t| Log-Likelihood:-3.188013262044644 \t|  theta: tensor([[0.0501, 3.0337]], requires_grad=True)  |  Time needed: 0:00:09.384385  \n",
      "Run: 23\t| Iteration: 400 \t| Log-Likelihood:-3.187300782028091 \t|  theta: tensor([[0.0501, 3.0088]], requires_grad=True)  |  Time needed: 0:00:09.468683  \n",
      "Run: 23\t| Iteration: 500 \t| Log-Likelihood:-3.1872428452560007 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.409106  \n",
      "Run: 23\t| Iteration: 600 \t| Log-Likelihood:-3.1872381323837393 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.339842  \n",
      "Run: 23\t| Iteration: 700 \t| Log-Likelihood:-3.1872377677975603 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.373721  \n",
      "Run: 23\t| Iteration: 800 \t| Log-Likelihood:-3.1872377663544182 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.367405  \n",
      "Run: 23\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564145626 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.409404  \n",
      "Run: 24\t| Iteration: 0 \t| Log-Likelihood:-3.8014689965292323 \t|  theta: tensor([[0.2746, 1.9696]], requires_grad=True)  |  Time needed: 0:00:00.099581  \n",
      "Run: 24\t| Iteration: 100 \t| Log-Likelihood:-3.3046695429075563 \t|  theta: tensor([[0.0513, 2.5651]], requires_grad=True)  |  Time needed: 0:00:09.357857  \n",
      "Run: 24\t| Iteration: 200 \t| Log-Likelihood:-3.197405816507082 \t|  theta: tensor([[0.0502, 2.8726]], requires_grad=True)  |  Time needed: 0:00:09.425271  \n",
      "Run: 24\t| Iteration: 300 \t| Log-Likelihood:-3.1880700895534813 \t|  theta: tensor([[0.0501, 2.9628]], requires_grad=True)  |  Time needed: 0:00:09.339473  \n",
      "Run: 24\t| Iteration: 400 \t| Log-Likelihood:-3.1873055120090505 \t|  theta: tensor([[0.0501, 2.9886]], requires_grad=True)  |  Time needed: 0:00:09.414876  \n",
      "Run: 24\t| Iteration: 500 \t| Log-Likelihood:-3.1872432609611767 \t|  theta: tensor([[0.0501, 2.9959]], requires_grad=True)  |  Time needed: 0:00:09.373488  \n",
      "Run: 24\t| Iteration: 600 \t| Log-Likelihood:-3.1872381603511313 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.357260  \n",
      "Run: 24\t| Iteration: 700 \t| Log-Likelihood:-3.1872377926196886 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.453971  \n",
      "Run: 24\t| Iteration: 800 \t| Log-Likelihood:-3.1872377293222556 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.308652  \n",
      "Run: 24\t| Iteration: 900 \t| Log-Likelihood:-3.187237734081123 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.376809  \n",
      "Run: 25\t| Iteration: 0 \t| Log-Likelihood:-3.850229294250993 \t|  theta: tensor([[0.3076, 3.8257]], requires_grad=True)  |  Time needed: 0:00:00.096908  \n",
      "Run: 25\t| Iteration: 100 \t| Log-Likelihood:-3.2225661414768947 \t|  theta: tensor([[0.0501, 3.2338]], requires_grad=True)  |  Time needed: 0:00:09.534372  \n",
      "Run: 25\t| Iteration: 200 \t| Log-Likelihood:-3.190098888310664 \t|  theta: tensor([[0.0501, 3.0658]], requires_grad=True)  |  Time needed: 0:00:09.488487  \n",
      "Run: 25\t| Iteration: 300 \t| Log-Likelihood:-3.1874702278494196 \t|  theta: tensor([[0.0501, 3.0179]], requires_grad=True)  |  Time needed: 0:00:09.557204  \n",
      "Run: 25\t| Iteration: 400 \t| Log-Likelihood:-3.1872566818517942 \t|  theta: tensor([[0.0501, 3.0043]], requires_grad=True)  |  Time needed: 0:00:09.477010  \n",
      "Run: 25\t| Iteration: 500 \t| Log-Likelihood:-3.1872392713365185 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.467220  \n",
      "Run: 25\t| Iteration: 600 \t| Log-Likelihood:-3.1872378364800995 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.491092  \n",
      "Run: 25\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254139557 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.514308  \n",
      "Run: 25\t| Iteration: 800 \t| Log-Likelihood:-3.1872377607486975 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.497599  \n",
      "Run: 25\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.519452  \n",
      "Run: 26\t| Iteration: 0 \t| Log-Likelihood:-4.848361043416889 \t|  theta: tensor([[0.1808, 4.5665]], requires_grad=True)  |  Time needed: 0:00:00.093940  \n",
      "Run: 26\t| Iteration: 100 \t| Log-Likelihood:-3.3141442979501545 \t|  theta: tensor([[0.0501, 3.4439]], requires_grad=True)  |  Time needed: 0:00:09.460088  \n",
      "Run: 26\t| Iteration: 200 \t| Log-Likelihood:-3.1974864127681863 \t|  theta: tensor([[0.0501, 3.1255]], requires_grad=True)  |  Time needed: 0:00:09.510746  \n",
      "Run: 26\t| Iteration: 300 \t| Log-Likelihood:-3.1880697100757494 \t|  theta: tensor([[0.0501, 3.0350]], requires_grad=True)  |  Time needed: 0:00:09.507515  \n",
      "Run: 26\t| Iteration: 400 \t| Log-Likelihood:-3.187305370985056 \t|  theta: tensor([[0.0501, 3.0092]], requires_grad=True)  |  Time needed: 0:00:09.507835  \n",
      "Run: 26\t| Iteration: 500 \t| Log-Likelihood:-3.1872432433288918 \t|  theta: tensor([[0.0501, 3.0018]], requires_grad=True)  |  Time needed: 0:00:09.524102  \n",
      "Run: 26\t| Iteration: 600 \t| Log-Likelihood:-3.1872381665540206 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.548088  \n",
      "Run: 26\t| Iteration: 700 \t| Log-Likelihood:-3.187237770198443 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.545447  \n",
      "Run: 26\t| Iteration: 800 \t| Log-Likelihood:-3.1872377665553207 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.466993  \n",
      "Run: 26\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564330603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.544588  \n",
      "Run: 27\t| Iteration: 0 \t| Log-Likelihood:-3.775377496845635 \t|  theta: tensor([[0.4853, 2.6191]], requires_grad=True)  |  Time needed: 0:00:00.090233  \n",
      "Run: 27\t| Iteration: 100 \t| Log-Likelihood:-3.195105249895443 \t|  theta: tensor([[0.0501, 2.8878]], requires_grad=True)  |  Time needed: 0:00:09.395897  \n",
      "Run: 27\t| Iteration: 200 \t| Log-Likelihood:-3.1878809709687177 \t|  theta: tensor([[0.0501, 2.9671]], requires_grad=True)  |  Time needed: 0:00:09.423493  \n",
      "Run: 27\t| Iteration: 300 \t| Log-Likelihood:-3.18729010327743 \t|  theta: tensor([[0.0501, 2.9898]], requires_grad=True)  |  Time needed: 0:00:09.441062  \n",
      "Run: 27\t| Iteration: 400 \t| Log-Likelihood:-3.187242016470924 \t|  theta: tensor([[0.0501, 2.9963]], requires_grad=True)  |  Time needed: 0:00:09.369517  \n",
      "Run: 27\t| Iteration: 500 \t| Log-Likelihood:-3.1872380770712256 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.498912  \n",
      "Run: 27\t| Iteration: 600 \t| Log-Likelihood:-3.1872377881653686 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.559028  \n",
      "Run: 27\t| Iteration: 700 \t| Log-Likelihood:-3.1872377286839066 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.496902  \n",
      "Run: 27\t| Iteration: 800 \t| Log-Likelihood:-3.1872377340219655 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.534321  \n",
      "Run: 27\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.399592  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 28\t| Iteration: 0 \t| Log-Likelihood:-4.9280729355126285 \t|  theta: tensor([[0.1013, 4.6362]], requires_grad=True)  |  Time needed: 0:00:00.095261  \n",
      "Run: 28\t| Iteration: 100 \t| Log-Likelihood:-3.325691018340557 \t|  theta: tensor([[0.0501, 3.4637]], requires_grad=True)  |  Time needed: 0:00:09.439145  \n",
      "Run: 28\t| Iteration: 200 \t| Log-Likelihood:-3.1984168147867797 \t|  theta: tensor([[0.0501, 3.1311]], requires_grad=True)  |  Time needed: 0:00:09.537175  \n",
      "Run: 28\t| Iteration: 300 \t| Log-Likelihood:-3.1881450590910045 \t|  theta: tensor([[0.0501, 3.0365]], requires_grad=True)  |  Time needed: 0:00:09.374299  \n",
      "Run: 28\t| Iteration: 400 \t| Log-Likelihood:-3.1873115135563532 \t|  theta: tensor([[0.0501, 3.0096]], requires_grad=True)  |  Time needed: 0:00:09.340517  \n",
      "Run: 28\t| Iteration: 500 \t| Log-Likelihood:-3.1872437685728046 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.385615  \n",
      "Run: 28\t| Iteration: 600 \t| Log-Likelihood:-3.1872382149489784 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.422736  \n",
      "Run: 28\t| Iteration: 700 \t| Log-Likelihood:-3.1872377773023706 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.418096  \n",
      "Run: 28\t| Iteration: 800 \t| Log-Likelihood:-3.187237770595251 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.367321  \n",
      "Run: 28\t| Iteration: 900 \t| Log-Likelihood:-3.187237756452196 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.361357  \n",
      "Run: 29\t| Iteration: 0 \t| Log-Likelihood:-4.0616960338547266 \t|  theta: tensor([[0.3990, 3.9005]], requires_grad=True)  |  Time needed: 0:00:00.098877  \n",
      "Run: 29\t| Iteration: 100 \t| Log-Likelihood:-3.2292431853326393 \t|  theta: tensor([[0.0501, 3.2550]], requires_grad=True)  |  Time needed: 0:00:09.364395  \n",
      "Run: 29\t| Iteration: 200 \t| Log-Likelihood:-3.1906383876504254 \t|  theta: tensor([[0.0501, 3.0718]], requires_grad=True)  |  Time needed: 0:00:09.302284  \n",
      "Run: 29\t| Iteration: 300 \t| Log-Likelihood:-3.187514112192635 \t|  theta: tensor([[0.0501, 3.0197]], requires_grad=True)  |  Time needed: 0:00:09.283104  \n",
      "Run: 29\t| Iteration: 400 \t| Log-Likelihood:-3.18726020673394 \t|  theta: tensor([[0.0501, 3.0048]], requires_grad=True)  |  Time needed: 0:00:09.336337  \n",
      "Run: 29\t| Iteration: 500 \t| Log-Likelihood:-3.18723958770572 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.711297  \n",
      "Run: 29\t| Iteration: 600 \t| Log-Likelihood:-3.1872378675839967 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.372575  \n",
      "Run: 29\t| Iteration: 700 \t| Log-Likelihood:-3.1872377310491458 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.343991  \n",
      "Run: 29\t| Iteration: 800 \t| Log-Likelihood:-3.1872377608988662 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.379956  \n",
      "Run: 29\t| Iteration: 900 \t| Log-Likelihood:-3.187237756225673 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.295326  \n",
      "Run: 30\t| Iteration: 0 \t| Log-Likelihood:-3.953343739882096 \t|  theta: tensor([[0.1189, 1.7500]], requires_grad=True)  |  Time needed: 0:00:00.096173  \n",
      "Run: 30\t| Iteration: 100 \t| Log-Likelihood:-3.2362850195774633 \t|  theta: tensor([[0.3295, 1.1557]], requires_grad=True)  |  Time needed: 0:00:09.522750  \n",
      "Run: 30\t| Iteration: 200 \t| Log-Likelihood:-3.19048852950788 \t|  theta: tensor([[0.4293, 1.0580]], requires_grad=True)  |  Time needed: 0:00:09.487255  \n",
      "Run: 30\t| Iteration: 300 \t| Log-Likelihood:-3.190462755921059 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.461047  \n",
      "Run: 30\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731462296 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.512718  \n",
      "Run: 30\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.537751  \n",
      "Run: 30\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.573860  \n",
      "Run: 30\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.518267  \n",
      "Run: 30\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.552638  \n",
      "Run: 30\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.505056  \n",
      "Run: 31\t| Iteration: 0 \t| Log-Likelihood:-4.58152460063557 \t|  theta: tensor([[0.2459, 4.3908]], requires_grad=True)  |  Time needed: 0:00:00.096164  \n",
      "Run: 31\t| Iteration: 100 \t| Log-Likelihood:-3.2873007565117773 \t|  theta: tensor([[0.0501, 3.3941]], requires_grad=True)  |  Time needed: 0:00:09.435919  \n",
      "Run: 31\t| Iteration: 200 \t| Log-Likelihood:-3.1953227593643603 \t|  theta: tensor([[0.0501, 3.1113]], requires_grad=True)  |  Time needed: 0:00:09.446328  \n",
      "Run: 31\t| Iteration: 300 \t| Log-Likelihood:-3.187894301091408 \t|  theta: tensor([[0.0501, 3.0309]], requires_grad=True)  |  Time needed: 0:00:09.761429  \n",
      "Run: 31\t| Iteration: 400 \t| Log-Likelihood:-3.187291143901638 \t|  theta: tensor([[0.0501, 3.0080]], requires_grad=True)  |  Time needed: 0:00:09.470201  \n",
      "Run: 31\t| Iteration: 500 \t| Log-Likelihood:-3.1872420790420715 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.439528  \n",
      "Run: 31\t| Iteration: 600 \t| Log-Likelihood:-3.187238116622363 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.444613  \n",
      "Run: 31\t| Iteration: 700 \t| Log-Likelihood:-3.1872377587462637 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.607786  \n",
      "Run: 31\t| Iteration: 800 \t| Log-Likelihood:-3.1872377659738733 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.506207  \n",
      "Run: 31\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563738805 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.548904  \n",
      "Run: 32\t| Iteration: 0 \t| Log-Likelihood:-3.912039201917673 \t|  theta: tensor([[0.3745, 1.9336]], requires_grad=True)  |  Time needed: 0:00:00.095465  \n",
      "Run: 32\t| Iteration: 100 \t| Log-Likelihood:-3.3607518861300516 \t|  theta: tensor([[0.0526, 2.4676]], requires_grad=True)  |  Time needed: 0:00:09.559938  \n",
      "Run: 32\t| Iteration: 200 \t| Log-Likelihood:-3.202866008725352 \t|  theta: tensor([[0.0502, 2.8422]], requires_grad=True)  |  Time needed: 0:00:09.518995  \n",
      "Run: 32\t| Iteration: 300 \t| Log-Likelihood:-3.188520647349179 \t|  theta: tensor([[0.0501, 2.9541]], requires_grad=True)  |  Time needed: 0:00:09.490160  \n",
      "Run: 32\t| Iteration: 400 \t| Log-Likelihood:-3.1873422278716315 \t|  theta: tensor([[0.0501, 2.9861]], requires_grad=True)  |  Time needed: 0:00:09.445878  \n",
      "Run: 32\t| Iteration: 500 \t| Log-Likelihood:-3.1872462364240404 \t|  theta: tensor([[0.0501, 2.9952]], requires_grad=True)  |  Time needed: 0:00:09.467509  \n",
      "Run: 32\t| Iteration: 600 \t| Log-Likelihood:-3.1872384301732573 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.452715  \n",
      "Run: 32\t| Iteration: 700 \t| Log-Likelihood:-3.187237801361511 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.444030  \n",
      "Run: 32\t| Iteration: 800 \t| Log-Likelihood:-3.1872377271810546 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.393925  \n",
      "Run: 32\t| Iteration: 900 \t| Log-Likelihood:-3.187237734197954 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.668752  \n",
      "Run: 33\t| Iteration: 0 \t| Log-Likelihood:-3.2756393809173736 \t|  theta: tensor([[0.0952, 2.6616]], requires_grad=True)  |  Time needed: 0:00:00.100359  \n",
      "Run: 33\t| Iteration: 100 \t| Log-Likelihood:-3.1932957281321297 \t|  theta: tensor([[0.0501, 2.9014]], requires_grad=True)  |  Time needed: 0:00:09.378720  \n",
      "Run: 33\t| Iteration: 200 \t| Log-Likelihood:-3.1877325187260417 \t|  theta: tensor([[0.0501, 2.9710]], requires_grad=True)  |  Time needed: 0:00:09.385792  \n",
      "Run: 33\t| Iteration: 300 \t| Log-Likelihood:-3.1872780460599266 \t|  theta: tensor([[0.0501, 2.9909]], requires_grad=True)  |  Time needed: 0:00:09.392752  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 33\t| Iteration: 400 \t| Log-Likelihood:-3.187241026515992 \t|  theta: tensor([[0.0501, 2.9966]], requires_grad=True)  |  Time needed: 0:00:09.418080  \n",
      "Run: 33\t| Iteration: 500 \t| Log-Likelihood:-3.1872380122367816 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.409924  \n",
      "Run: 33\t| Iteration: 600 \t| Log-Likelihood:-3.187237789024741 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.384800  \n",
      "Run: 33\t| Iteration: 700 \t| Log-Likelihood:-3.187237731863886 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.381901  \n",
      "Run: 33\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339650764 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.336522  \n",
      "Run: 33\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.422094  \n",
      "Run: 34\t| Iteration: 0 \t| Log-Likelihood:-3.3071406091822686 \t|  theta: tensor([[0.1030, 3.3900]], requires_grad=True)  |  Time needed: 0:00:00.094325  \n",
      "Run: 34\t| Iteration: 100 \t| Log-Likelihood:-3.195155621612506 \t|  theta: tensor([[0.0501, 3.1101]], requires_grad=True)  |  Time needed: 0:00:09.317774  \n",
      "Run: 34\t| Iteration: 200 \t| Log-Likelihood:-3.187880697082008 \t|  theta: tensor([[0.0501, 3.0306]], requires_grad=True)  |  Time needed: 0:00:09.355170  \n",
      "Run: 34\t| Iteration: 300 \t| Log-Likelihood:-3.187290028935465 \t|  theta: tensor([[0.0501, 3.0079]], requires_grad=True)  |  Time needed: 0:00:09.325970  \n",
      "Run: 34\t| Iteration: 400 \t| Log-Likelihood:-3.1872419848014077 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.327785  \n",
      "Run: 34\t| Iteration: 500 \t| Log-Likelihood:-3.1872381055543753 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.438738  \n",
      "Run: 34\t| Iteration: 600 \t| Log-Likelihood:-3.1872377582386053 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.438074  \n",
      "Run: 34\t| Iteration: 700 \t| Log-Likelihood:-3.1872377659373776 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.298634  \n",
      "Run: 34\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563738805 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.321450  \n",
      "Run: 34\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.328268  \n",
      "Run: 35\t| Iteration: 0 \t| Log-Likelihood:-3.369348070700469 \t|  theta: tensor([[0.0363, 2.4695]], requires_grad=True)  |  Time needed: 0:00:00.094663  \n",
      "Run: 35\t| Iteration: 100 \t| Log-Likelihood:-3.2027318190835685 \t|  theta: tensor([[0.0502, 2.8429]], requires_grad=True)  |  Time needed: 0:00:09.477828  \n",
      "Run: 35\t| Iteration: 200 \t| Log-Likelihood:-3.1885096257361827 \t|  theta: tensor([[0.0501, 2.9543]], requires_grad=True)  |  Time needed: 0:00:09.576868  \n",
      "Run: 35\t| Iteration: 300 \t| Log-Likelihood:-3.187341332760375 \t|  theta: tensor([[0.0501, 2.9861]], requires_grad=True)  |  Time needed: 0:00:09.447105  \n",
      "Run: 35\t| Iteration: 400 \t| Log-Likelihood:-3.1872461656694 \t|  theta: tensor([[0.0501, 2.9952]], requires_grad=True)  |  Time needed: 0:00:09.471128  \n",
      "Run: 35\t| Iteration: 500 \t| Log-Likelihood:-3.187238423297642 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.537706  \n",
      "Run: 35\t| Iteration: 600 \t| Log-Likelihood:-3.1872378007375186 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.453818  \n",
      "Run: 35\t| Iteration: 700 \t| Log-Likelihood:-3.1872377271303916 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.465244  \n",
      "Run: 35\t| Iteration: 800 \t| Log-Likelihood:-3.187237734197954 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.476893  \n",
      "Run: 35\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.482117  \n",
      "Run: 36\t| Iteration: 0 \t| Log-Likelihood:-4.185486961306641 \t|  theta: tensor([[0.5754, 2.2007]], requires_grad=True)  |  Time needed: 0:00:00.091883  \n",
      "Run: 36\t| Iteration: 100 \t| Log-Likelihood:-3.233849454458401 \t|  theta: tensor([[0.0504, 2.7276]], requires_grad=True)  |  Time needed: 0:00:09.479780  \n",
      "Run: 36\t| Iteration: 200 \t| Log-Likelihood:-3.191122407917809 \t|  theta: tensor([[0.0501, 2.9209]], requires_grad=True)  |  Time needed: 0:00:09.482249  \n",
      "Run: 36\t| Iteration: 300 \t| Log-Likelihood:-3.187554604827299 \t|  theta: tensor([[0.0501, 2.9766]], requires_grad=True)  |  Time needed: 0:00:09.488179  \n",
      "Run: 36\t| Iteration: 400 \t| Log-Likelihood:-3.1872635578442203 \t|  theta: tensor([[0.0501, 2.9925]], requires_grad=True)  |  Time needed: 0:00:09.665103  \n",
      "Run: 36\t| Iteration: 500 \t| Log-Likelihood:-3.1872398660618915 \t|  theta: tensor([[0.0501, 2.9971]], requires_grad=True)  |  Time needed: 0:00:09.660423  \n",
      "Run: 36\t| Iteration: 600 \t| Log-Likelihood:-3.1872379379554743 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.490106  \n",
      "Run: 36\t| Iteration: 700 \t| Log-Likelihood:-3.1872377253134547 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.600275  \n",
      "Run: 36\t| Iteration: 800 \t| Log-Likelihood:-3.1872377312325644 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.519533  \n",
      "Run: 36\t| Iteration: 900 \t| Log-Likelihood:-3.18723773761577 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.461759  \n",
      "Run: 37\t| Iteration: 0 \t| Log-Likelihood:-5.0387556387271735 \t|  theta: tensor([[0.2817, 4.6068]], requires_grad=True)  |  Time needed: 0:00:00.091297  \n",
      "Run: 37\t| Iteration: 100 \t| Log-Likelihood:-3.320764033684883 \t|  theta: tensor([[0.0501, 3.4554]], requires_grad=True)  |  Time needed: 0:00:09.505301  \n",
      "Run: 37\t| Iteration: 200 \t| Log-Likelihood:-3.198019964094606 \t|  theta: tensor([[0.0501, 3.1287]], requires_grad=True)  |  Time needed: 0:00:09.439751  \n",
      "Run: 37\t| Iteration: 300 \t| Log-Likelihood:-3.188112929503681 \t|  theta: tensor([[0.0501, 3.0359]], requires_grad=True)  |  Time needed: 0:00:09.416188  \n",
      "Run: 37\t| Iteration: 400 \t| Log-Likelihood:-3.1873089377632624 \t|  theta: tensor([[0.0501, 3.0094]], requires_grad=True)  |  Time needed: 0:00:09.418980  \n",
      "Run: 37\t| Iteration: 500 \t| Log-Likelihood:-3.187243547154565 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.524008  \n",
      "Run: 37\t| Iteration: 600 \t| Log-Likelihood:-3.1872381937519996 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.494100  \n",
      "Run: 37\t| Iteration: 700 \t| Log-Likelihood:-3.1872377758149737 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.390574  \n",
      "Run: 37\t| Iteration: 800 \t| Log-Likelihood:-3.187237770446435 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.421228  \n",
      "Run: 37\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564457466 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.430170  \n",
      "Run: 38\t| Iteration: 0 \t| Log-Likelihood:-5.544105458586434 \t|  theta: tensor([[0.3841, 4.7762]], requires_grad=True)  |  Time needed: 0:00:00.095727  \n",
      "Run: 38\t| Iteration: 100 \t| Log-Likelihood:-3.3504014081808084 \t|  theta: tensor([[0.0501, 3.5034]], requires_grad=True)  |  Time needed: 0:00:09.404234  \n",
      "Run: 38\t| Iteration: 200 \t| Log-Likelihood:-3.2004074521311874 \t|  theta: tensor([[0.0501, 3.1424]], requires_grad=True)  |  Time needed: 0:00:09.399695  \n",
      "Run: 38\t| Iteration: 300 \t| Log-Likelihood:-3.1883063765129607 \t|  theta: tensor([[0.0501, 3.0398]], requires_grad=True)  |  Time needed: 0:00:09.513271  \n",
      "Run: 38\t| Iteration: 400 \t| Log-Likelihood:-3.18732459961233 \t|  theta: tensor([[0.0501, 3.0105]], requires_grad=True)  |  Time needed: 0:00:09.442426  \n",
      "Run: 38\t| Iteration: 500 \t| Log-Likelihood:-3.187244822745486 \t|  theta: tensor([[0.0501, 3.0022]], requires_grad=True)  |  Time needed: 0:00:09.376410  \n",
      "Run: 38\t| Iteration: 600 \t| Log-Likelihood:-3.1872383128167803 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.495393  \n",
      "Run: 38\t| Iteration: 700 \t| Log-Likelihood:-3.1872377879902882 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.388576  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 38\t| Iteration: 800 \t| Log-Likelihood:-3.18723777115508 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.445162  \n",
      "Run: 38\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564993264 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.401350  \n",
      "Run: 39\t| Iteration: 0 \t| Log-Likelihood:-3.4874100219941737 \t|  theta: tensor([[0.0668, 2.2836]], requires_grad=True)  |  Time needed: 0:00:00.095564  \n",
      "Run: 39\t| Iteration: 100 \t| Log-Likelihood:-3.217972063301079 \t|  theta: tensor([[0.0503, 2.7789]], requires_grad=True)  |  Time needed: 0:00:09.335580  \n",
      "Run: 39\t| Iteration: 200 \t| Log-Likelihood:-3.189779734628712 \t|  theta: tensor([[0.0501, 2.9358]], requires_grad=True)  |  Time needed: 0:00:09.324259  \n",
      "Run: 39\t| Iteration: 300 \t| Log-Likelihood:-3.187444964475977 \t|  theta: tensor([[0.0501, 2.9809]], requires_grad=True)  |  Time needed: 0:00:09.362915  \n",
      "Run: 39\t| Iteration: 400 \t| Log-Likelihood:-3.1872546236812713 \t|  theta: tensor([[0.0501, 2.9937]], requires_grad=True)  |  Time needed: 0:00:09.300287  \n",
      "Run: 39\t| Iteration: 500 \t| Log-Likelihood:-3.1872390828417254 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.348002  \n",
      "Run: 39\t| Iteration: 600 \t| Log-Likelihood:-3.1872378379161246 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.388973  \n",
      "Run: 39\t| Iteration: 700 \t| Log-Likelihood:-3.1872377279555506 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.408255  \n",
      "Run: 39\t| Iteration: 800 \t| Log-Likelihood:-3.187237730838686 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.716526  \n",
      "Run: 39\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.999899  \n",
      "Run: 40\t| Iteration: 0 \t| Log-Likelihood:-6.742850185307838 \t|  theta: tensor([[0.1894, 0.3407]], requires_grad=True)  |  Time needed: 0:00:00.097023  \n",
      "Run: 40\t| Iteration: 100 \t| Log-Likelihood:-3.1904705694700155 \t|  theta: tensor([[0.4309, 1.0574]], requires_grad=True)  |  Time needed: 0:00:10.036519  \n",
      "Run: 40\t| Iteration: 200 \t| Log-Likelihood:-3.1904627396980914 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.622652  \n",
      "Run: 40\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327362642 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.642343  \n",
      "Run: 40\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.555058  \n",
      "Run: 40\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.571400  \n",
      "Run: 40\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.559387  \n",
      "Run: 40\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.534190  \n",
      "Run: 40\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.568757  \n",
      "Run: 40\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.518290  \n",
      "Run: 41\t| Iteration: 0 \t| Log-Likelihood:-3.483545200746887 \t|  theta: tensor([[0.0741, 2.2917]], requires_grad=True)  |  Time needed: 0:00:00.090675  \n",
      "Run: 41\t| Iteration: 100 \t| Log-Likelihood:-3.217168687344541 \t|  theta: tensor([[0.0503, 2.7818]], requires_grad=True)  |  Time needed: 0:00:09.520020  \n",
      "Run: 41\t| Iteration: 200 \t| Log-Likelihood:-3.1897122967290645 \t|  theta: tensor([[0.0501, 2.9366]], requires_grad=True)  |  Time needed: 0:00:09.541346  \n",
      "Run: 41\t| Iteration: 300 \t| Log-Likelihood:-3.1874394581999166 \t|  theta: tensor([[0.0501, 2.9811]], requires_grad=True)  |  Time needed: 0:00:09.510078  \n",
      "Run: 41\t| Iteration: 400 \t| Log-Likelihood:-3.1872541833744608 \t|  theta: tensor([[0.0501, 2.9938]], requires_grad=True)  |  Time needed: 0:00:09.485198  \n",
      "Run: 41\t| Iteration: 500 \t| Log-Likelihood:-3.187239050655211 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.588012  \n",
      "Run: 41\t| Iteration: 600 \t| Log-Likelihood:-3.187237835042821 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.547106  \n",
      "Run: 41\t| Iteration: 700 \t| Log-Likelihood:-3.187237727741912 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.489870  \n",
      "Run: 41\t| Iteration: 800 \t| Log-Likelihood:-3.1872377345433573 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.538523  \n",
      "Run: 41\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.524188  \n",
      "Run: 42\t| Iteration: 0 \t| Log-Likelihood:-3.7474441387657387 \t|  theta: tensor([[0.2377, 1.7164]], requires_grad=True)  |  Time needed: 0:00:00.091271  \n",
      "Run: 42\t| Iteration: 100 \t| Log-Likelihood:-3.1949320477059246 \t|  theta: tensor([[0.3903, 1.0786]], requires_grad=True)  |  Time needed: 0:00:09.569251  \n",
      "Run: 42\t| Iteration: 200 \t| Log-Likelihood:-3.190466284570104 \t|  theta: tensor([[0.4316, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.518719  \n",
      "Run: 42\t| Iteration: 300 \t| Log-Likelihood:-3.1904627061246926 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.466648  \n",
      "Run: 42\t| Iteration: 400 \t| Log-Likelihood:-3.1904627029304726 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.525724  \n",
      "Run: 42\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.491560  \n",
      "Run: 42\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.455309  \n",
      "Run: 42\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.486154  \n",
      "Run: 42\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.473380  \n",
      "Run: 42\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.527671  \n",
      "Run: 43\t| Iteration: 0 \t| Log-Likelihood:-3.590987587530527 \t|  theta: tensor([[0.4109, 1.4555]], requires_grad=True)  |  Time needed: 0:00:00.094221  \n",
      "Run: 43\t| Iteration: 100 \t| Log-Likelihood:-3.1905460707580233 \t|  theta: tensor([[0.4266, 1.0590]], requires_grad=True)  |  Time needed: 0:00:09.717304  \n",
      "Run: 43\t| Iteration: 200 \t| Log-Likelihood:-3.1904627475147445 \t|  theta: tensor([[0.4327, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.373956  \n",
      "Run: 43\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731905807 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.388336  \n",
      "Run: 43\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.502358  \n",
      "Run: 43\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.452356  \n",
      "Run: 43\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.397927  \n",
      "Run: 43\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.460141  \n",
      "Run: 43\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.417640  \n",
      "Run: 43\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.392967  \n",
      "Run: 44\t| Iteration: 0 \t| Log-Likelihood:-5.166016934066741 \t|  theta: tensor([[0.0798, 4.7513]], requires_grad=True)  |  Time needed: 0:00:00.095301  \n",
      "Run: 44\t| Iteration: 100 \t| Log-Likelihood:-3.3458666303421674 \t|  theta: tensor([[0.0501, 3.4964]], requires_grad=True)  |  Time needed: 0:00:09.327052  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 44\t| Iteration: 200 \t| Log-Likelihood:-3.200042176970976 \t|  theta: tensor([[0.0501, 3.1404]], requires_grad=True)  |  Time needed: 0:00:09.369269  \n",
      "Run: 44\t| Iteration: 300 \t| Log-Likelihood:-3.1882767976124704 \t|  theta: tensor([[0.0501, 3.0392]], requires_grad=True)  |  Time needed: 0:00:09.423939  \n",
      "Run: 44\t| Iteration: 400 \t| Log-Likelihood:-3.187322238722425 \t|  theta: tensor([[0.0501, 3.0104]], requires_grad=True)  |  Time needed: 0:00:09.352696  \n",
      "Run: 44\t| Iteration: 500 \t| Log-Likelihood:-3.187244615793977 \t|  theta: tensor([[0.0501, 3.0022]], requires_grad=True)  |  Time needed: 0:00:09.380314  \n",
      "Run: 44\t| Iteration: 600 \t| Log-Likelihood:-3.1872382966562434 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.386341  \n",
      "Run: 44\t| Iteration: 700 \t| Log-Likelihood:-3.1872377867774837 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.456258  \n",
      "Run: 44\t| Iteration: 800 \t| Log-Likelihood:-3.1872377710625313 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.401342  \n",
      "Run: 44\t| Iteration: 900 \t| Log-Likelihood:-3.187237756492381 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.394580  \n",
      "Run: 45\t| Iteration: 0 \t| Log-Likelihood:-5.318233845796595 \t|  theta: tensor([[0.1864, 0.5122]], requires_grad=True)  |  Time needed: 0:00:00.098101  \n",
      "Run: 45\t| Iteration: 100 \t| Log-Likelihood:-3.190476510494883 \t|  theta: tensor([[0.4303, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.465422  \n",
      "Run: 45\t| Iteration: 200 \t| Log-Likelihood:-3.1904626854440283 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.130108  \n",
      "Run: 45\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327405057 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.494900  \n",
      "Run: 45\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.462939  \n",
      "Run: 45\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.492694  \n",
      "Run: 45\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.704472  \n",
      "Run: 45\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.616571  \n",
      "Run: 45\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.465197  \n",
      "Run: 45\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.480736  \n",
      "Run: 46\t| Iteration: 0 \t| Log-Likelihood:-3.2520754179717297 \t|  theta: tensor([[0.0390, 2.6875]], requires_grad=True)  |  Time needed: 0:00:00.091442  \n",
      "Run: 46\t| Iteration: 100 \t| Log-Likelihood:-3.1923786633083635 \t|  theta: tensor([[0.0501, 2.9091]], requires_grad=True)  |  Time needed: 0:00:09.504023  \n",
      "Run: 46\t| Iteration: 200 \t| Log-Likelihood:-3.1876574010145453 \t|  theta: tensor([[0.0501, 2.9732]], requires_grad=True)  |  Time needed: 0:00:09.510622  \n",
      "Run: 46\t| Iteration: 300 \t| Log-Likelihood:-3.187271932630729 \t|  theta: tensor([[0.0501, 2.9916]], requires_grad=True)  |  Time needed: 0:00:09.529760  \n",
      "Run: 46\t| Iteration: 400 \t| Log-Likelihood:-3.1872404998195747 \t|  theta: tensor([[0.0501, 2.9968]], requires_grad=True)  |  Time needed: 0:00:09.576344  \n",
      "Run: 46\t| Iteration: 500 \t| Log-Likelihood:-3.1872379784073854 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.616661  \n",
      "Run: 46\t| Iteration: 600 \t| Log-Likelihood:-3.1872377857742817 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.699316  \n",
      "Run: 46\t| Iteration: 700 \t| Log-Likelihood:-3.1872377315744402 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.490667  \n",
      "Run: 46\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339376596 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.509609  \n",
      "Run: 46\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.527866  \n",
      "Run: 47\t| Iteration: 0 \t| Log-Likelihood:-3.769488938721113 \t|  theta: tensor([[0.5565, 1.4866]], requires_grad=True)  |  Time needed: 0:00:00.092430  \n",
      "Run: 47\t| Iteration: 100 \t| Log-Likelihood:-3.1904753069223446 \t|  theta: tensor([[0.4305, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.374990  \n",
      "Run: 47\t| Iteration: 200 \t| Log-Likelihood:-3.190462713892142 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.433070  \n",
      "Run: 47\t| Iteration: 300 \t| Log-Likelihood:-3.190462702937097 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.419187  \n",
      "Run: 47\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.378750  \n",
      "Run: 47\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.399506  \n",
      "Run: 47\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.381828  \n",
      "Run: 47\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.440413  \n",
      "Run: 47\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.399849  \n",
      "Run: 47\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.374932  \n",
      "Run: 48\t| Iteration: 0 \t| Log-Likelihood:-4.205573337673023 \t|  theta: tensor([[0.4827, 3.9016]], requires_grad=True)  |  Time needed: 0:00:00.096218  \n",
      "Run: 48\t| Iteration: 100 \t| Log-Likelihood:-3.229343217455691 \t|  theta: tensor([[0.0501, 3.2553]], requires_grad=True)  |  Time needed: 0:00:09.412264  \n",
      "Run: 48\t| Iteration: 200 \t| Log-Likelihood:-3.190646400608804 \t|  theta: tensor([[0.0501, 3.0719]], requires_grad=True)  |  Time needed: 0:00:09.372078  \n",
      "Run: 48\t| Iteration: 300 \t| Log-Likelihood:-3.1875147484312794 \t|  theta: tensor([[0.0501, 3.0197]], requires_grad=True)  |  Time needed: 0:00:09.395271  \n",
      "Run: 48\t| Iteration: 400 \t| Log-Likelihood:-3.1872602585198515 \t|  theta: tensor([[0.0501, 3.0048]], requires_grad=True)  |  Time needed: 0:00:09.501576  \n",
      "Run: 48\t| Iteration: 500 \t| Log-Likelihood:-3.187239590251445 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.605121  \n",
      "Run: 48\t| Iteration: 600 \t| Log-Likelihood:-3.1872378677291926 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.412676  \n",
      "Run: 48\t| Iteration: 700 \t| Log-Likelihood:-3.1872377310906703 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.382964  \n",
      "Run: 48\t| Iteration: 800 \t| Log-Likelihood:-3.187237760910914 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.418542  \n",
      "Run: 48\t| Iteration: 900 \t| Log-Likelihood:-3.187237756225673 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.447200  \n",
      "Run: 49\t| Iteration: 0 \t| Log-Likelihood:-3.3551445784548912 \t|  theta: tensor([[0.3273, 1.2908]], requires_grad=True)  |  Time needed: 0:00:00.095417  \n",
      "Run: 49\t| Iteration: 100 \t| Log-Likelihood:-3.1905200068258392 \t|  theta: tensor([[0.4276, 1.0586]], requires_grad=True)  |  Time needed: 0:00:09.440496  \n",
      "Run: 49\t| Iteration: 200 \t| Log-Likelihood:-3.1904627542639825 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.322563  \n",
      "Run: 49\t| Iteration: 300 \t| Log-Likelihood:-3.190462732774848 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.301463  \n",
      "Run: 49\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.348976  \n",
      "Run: 49\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.325067  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 49\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.399108  \n",
      "Run: 49\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.311354  \n",
      "Run: 49\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.319274  \n",
      "Run: 49\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.285066  \n",
      "Run: 50\t| Iteration: 0 \t| Log-Likelihood:-3.420025601328078 \t|  theta: tensor([[0.1086, 2.4101]], requires_grad=True)  |  Time needed: 0:00:00.097035  \n",
      "Run: 50\t| Iteration: 100 \t| Log-Likelihood:-3.206889904306711 \t|  theta: tensor([[0.0502, 2.8232]], requires_grad=True)  |  Time needed: 0:00:09.672126  \n",
      "Run: 50\t| Iteration: 200 \t| Log-Likelihood:-3.1888542481722078 \t|  theta: tensor([[0.0501, 2.9486]], requires_grad=True)  |  Time needed: 0:00:09.502635  \n",
      "Run: 50\t| Iteration: 300 \t| Log-Likelihood:-3.187369423613517 \t|  theta: tensor([[0.0501, 2.9845]], requires_grad=True)  |  Time needed: 0:00:09.483968  \n",
      "Run: 50\t| Iteration: 400 \t| Log-Likelihood:-3.1872484276008644 \t|  theta: tensor([[0.0501, 2.9948]], requires_grad=True)  |  Time needed: 0:00:09.472922  \n",
      "Run: 50\t| Iteration: 500 \t| Log-Likelihood:-3.1872385866358375 \t|  theta: tensor([[0.0501, 2.9977]], requires_grad=True)  |  Time needed: 0:00:09.497294  \n",
      "Run: 50\t| Iteration: 600 \t| Log-Likelihood:-3.1872378121422336 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.512952  \n",
      "Run: 50\t| Iteration: 700 \t| Log-Likelihood:-3.1872377284245417 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.518399  \n",
      "Run: 50\t| Iteration: 800 \t| Log-Likelihood:-3.187237734268096 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.476515  \n",
      "Run: 50\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.431905  \n",
      "Run: 51\t| Iteration: 0 \t| Log-Likelihood:-3.6160866922377166 \t|  theta: tensor([[0.1288, 0.9911]], requires_grad=True)  |  Time needed: 0:00:00.096735  \n",
      "Run: 51\t| Iteration: 100 \t| Log-Likelihood:-3.1905273700708365 \t|  theta: tensor([[0.4272, 1.0585]], requires_grad=True)  |  Time needed: 0:00:09.578582  \n",
      "Run: 51\t| Iteration: 200 \t| Log-Likelihood:-3.190462731175582 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.450602  \n",
      "Run: 51\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029785506 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.466028  \n",
      "Run: 51\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.432856  \n",
      "Run: 51\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.547645  \n",
      "Run: 51\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.482695  \n",
      "Run: 51\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.437922  \n",
      "Run: 51\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.443319  \n",
      "Run: 51\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.477563  \n",
      "Run: 52\t| Iteration: 0 \t| Log-Likelihood:-3.3028188767891655 \t|  theta: tensor([[0.2105, 3.0571]], requires_grad=True)  |  Time needed: 0:00:00.093500  \n",
      "Run: 52\t| Iteration: 100 \t| Log-Likelihood:-3.1874135819426206 \t|  theta: tensor([[0.0501, 3.0155]], requires_grad=True)  |  Time needed: 0:00:09.391190  \n",
      "Run: 52\t| Iteration: 200 \t| Log-Likelihood:-3.187252065322764 \t|  theta: tensor([[0.0501, 3.0036]], requires_grad=True)  |  Time needed: 0:00:09.455106  \n",
      "Run: 52\t| Iteration: 300 \t| Log-Likelihood:-3.1872389167466033 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.576205  \n",
      "Run: 52\t| Iteration: 400 \t| Log-Likelihood:-3.187237854422692 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.444175  \n",
      "Run: 52\t| Iteration: 500 \t| Log-Likelihood:-3.1872377788006956 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.467101  \n",
      "Run: 52\t| Iteration: 600 \t| Log-Likelihood:-3.187237760512351 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.507955  \n",
      "Run: 52\t| Iteration: 700 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.421097  \n",
      "Run: 52\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.393132  \n",
      "Run: 52\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.417043  \n",
      "Run: 53\t| Iteration: 0 \t| Log-Likelihood:-3.7542595835707226 \t|  theta: tensor([[0.4647, 2.5829]], requires_grad=True)  |  Time needed: 0:00:00.098380  \n",
      "Run: 53\t| Iteration: 100 \t| Log-Likelihood:-3.1967586203589393 \t|  theta: tensor([[0.0502, 2.8767]], requires_grad=True)  |  Time needed: 0:00:09.352215  \n",
      "Run: 53\t| Iteration: 200 \t| Log-Likelihood:-3.1880168653042644 \t|  theta: tensor([[0.0501, 2.9640]], requires_grad=True)  |  Time needed: 0:00:09.418000  \n",
      "Run: 53\t| Iteration: 300 \t| Log-Likelihood:-3.1873011750856715 \t|  theta: tensor([[0.0501, 2.9889]], requires_grad=True)  |  Time needed: 0:00:09.347364  \n",
      "Run: 53\t| Iteration: 400 \t| Log-Likelihood:-3.187242931902378 \t|  theta: tensor([[0.0501, 2.9960]], requires_grad=True)  |  Time needed: 0:00:09.320137  \n",
      "Run: 53\t| Iteration: 500 \t| Log-Likelihood:-3.1872381357830597 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.531957  \n",
      "Run: 53\t| Iteration: 600 \t| Log-Likelihood:-3.1872377903555797 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.559289  \n",
      "Run: 53\t| Iteration: 700 \t| Log-Likelihood:-3.187237729120667 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.376887  \n",
      "Run: 53\t| Iteration: 800 \t| Log-Likelihood:-3.187237734062632 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.355180  \n",
      "Run: 53\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.334609  \n",
      "Run: 54\t| Iteration: 0 \t| Log-Likelihood:-5.799021982562776 \t|  theta: tensor([[0.1305, 0.5040]], requires_grad=True)  |  Time needed: 0:00:00.096632  \n",
      "Run: 54\t| Iteration: 100 \t| Log-Likelihood:-3.190483624541308 \t|  theta: tensor([[0.4297, 1.0577]], requires_grad=True)  |  Time needed: 0:00:09.320541  \n",
      "Run: 54\t| Iteration: 200 \t| Log-Likelihood:-3.1904627216470107 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.305987  \n",
      "Run: 54\t| Iteration: 300 \t| Log-Likelihood:-3.19046267314168 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.308420  \n",
      "Run: 54\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.325392  \n",
      "Run: 54\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.355812  \n",
      "Run: 54\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.262943  \n",
      "Run: 54\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.285528  \n",
      "Run: 54\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.312960  \n",
      "Run: 54\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.349210  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 55\t| Iteration: 0 \t| Log-Likelihood:-3.2137186897639234 \t|  theta: tensor([[0.5367, 1.0181]], requires_grad=True)  |  Time needed: 0:00:00.094235  \n",
      "Run: 55\t| Iteration: 100 \t| Log-Likelihood:-3.190483272424068 \t|  theta: tensor([[0.4362, 1.0562]], requires_grad=True)  |  Time needed: 0:00:09.472397  \n",
      "Run: 55\t| Iteration: 200 \t| Log-Likelihood:-3.190462721562771 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.439330  \n",
      "Run: 55\t| Iteration: 300 \t| Log-Likelihood:-3.190462702943956 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.431896  \n",
      "Run: 55\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.425542  \n",
      "Run: 55\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.407138  \n",
      "Run: 55\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.473247  \n",
      "Run: 55\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.020357  \n",
      "Run: 55\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.990371  \n",
      "Run: 55\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.429574  \n",
      "Run: 56\t| Iteration: 0 \t| Log-Likelihood:-5.3930504217127595 \t|  theta: tensor([[0.5869, 0.4412]], requires_grad=True)  |  Time needed: 0:00:00.094431  \n",
      "Run: 56\t| Iteration: 100 \t| Log-Likelihood:-3.1905703941126 \t|  theta: tensor([[0.4403, 1.0550]], requires_grad=True)  |  Time needed: 0:00:10.074229  \n",
      "Run: 56\t| Iteration: 200 \t| Log-Likelihood:-3.190462800617736 \t|  theta: tensor([[0.4332, 1.0569]], requires_grad=True)  |  Time needed: 0:00:09.519804  \n",
      "Run: 56\t| Iteration: 300 \t| Log-Likelihood:-3.190462703013295 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.497723  \n",
      "Run: 56\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.513058  \n",
      "Run: 56\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.519277  \n",
      "Run: 56\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.482072  \n",
      "Run: 56\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.505208  \n",
      "Run: 56\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.442049  \n",
      "Run: 56\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.440087  \n",
      "Run: 57\t| Iteration: 0 \t| Log-Likelihood:-5.43018832245459 \t|  theta: tensor([[0.4449, 4.6809]], requires_grad=True)  |  Time needed: 0:00:00.101589  \n",
      "Run: 57\t| Iteration: 100 \t| Log-Likelihood:-3.3333455306281534 \t|  theta: tensor([[0.0501, 3.4764]], requires_grad=True)  |  Time needed: 0:00:09.446612  \n",
      "Run: 57\t| Iteration: 200 \t| Log-Likelihood:-3.199033462473751 \t|  theta: tensor([[0.0501, 3.1347]], requires_grad=True)  |  Time needed: 0:00:09.355500  \n",
      "Run: 57\t| Iteration: 300 \t| Log-Likelihood:-3.188195089653463 \t|  theta: tensor([[0.0501, 3.0376]], requires_grad=True)  |  Time needed: 0:00:09.446387  \n",
      "Run: 57\t| Iteration: 400 \t| Log-Likelihood:-3.187315570412193 \t|  theta: tensor([[0.0501, 3.0099]], requires_grad=True)  |  Time needed: 0:00:09.432428  \n",
      "Run: 57\t| Iteration: 500 \t| Log-Likelihood:-3.1872440566797193 \t|  theta: tensor([[0.0501, 3.0020]], requires_grad=True)  |  Time needed: 0:00:09.392753  \n",
      "Run: 57\t| Iteration: 600 \t| Log-Likelihood:-3.1872382442627534 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.401540  \n",
      "Run: 57\t| Iteration: 700 \t| Log-Likelihood:-3.187237779355317 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.364852  \n",
      "Run: 57\t| Iteration: 800 \t| Log-Likelihood:-3.187237770769577 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.400219  \n",
      "Run: 57\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564653074 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.389284  \n",
      "Run: 58\t| Iteration: 0 \t| Log-Likelihood:-3.2913578470735523 \t|  theta: tensor([[0.3583, 1.2317]], requires_grad=True)  |  Time needed: 0:00:00.096259  \n",
      "Run: 58\t| Iteration: 100 \t| Log-Likelihood:-3.1904902694670056 \t|  theta: tensor([[0.4292, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.338051  \n",
      "Run: 58\t| Iteration: 200 \t| Log-Likelihood:-3.1904627276389794 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.308408  \n",
      "Run: 58\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029494343 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.392577  \n",
      "Run: 58\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.363956  \n",
      "Run: 58\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.373579  \n",
      "Run: 58\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.372552  \n",
      "Run: 58\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.380020  \n",
      "Run: 58\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.350318  \n",
      "Run: 58\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.460589  \n",
      "Run: 59\t| Iteration: 0 \t| Log-Likelihood:-3.2108312916164534 \t|  theta: tensor([[0.0359, 3.0863]], requires_grad=True)  |  Time needed: 0:00:00.096689  \n",
      "Run: 59\t| Iteration: 100 \t| Log-Likelihood:-3.187634974600635 \t|  theta: tensor([[0.0501, 3.0238]], requires_grad=True)  |  Time needed: 0:00:09.312624  \n",
      "Run: 59\t| Iteration: 200 \t| Log-Likelihood:-3.1872700752630188 \t|  theta: tensor([[0.0501, 3.0060]], requires_grad=True)  |  Time needed: 0:00:09.292603  \n",
      "Run: 59\t| Iteration: 300 \t| Log-Likelihood:-3.1872403873735307 \t|  theta: tensor([[0.0501, 3.0009]], requires_grad=True)  |  Time needed: 0:00:09.386487  \n",
      "Run: 59\t| Iteration: 400 \t| Log-Likelihood:-3.18723794760855 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.316886  \n",
      "Run: 59\t| Iteration: 500 \t| Log-Likelihood:-3.1872377399647775 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.303914  \n",
      "Run: 59\t| Iteration: 600 \t| Log-Likelihood:-3.1872377612770126 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.374647  \n",
      "Run: 59\t| Iteration: 700 \t| Log-Likelihood:-3.187237756276779 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.283917  \n",
      "Run: 59\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.277278  \n",
      "Run: 59\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.317136  \n",
      "Run: 60\t| Iteration: 0 \t| Log-Likelihood:-3.4536717258090053 \t|  theta: tensor([[0.4166, 0.8340]], requires_grad=True)  |  Time needed: 0:00:00.099141  \n",
      "Run: 60\t| Iteration: 100 \t| Log-Likelihood:-3.1904643122856395 \t|  theta: tensor([[0.4338, 1.0567]], requires_grad=True)  |  Time needed: 0:00:09.442957  \n",
      "Run: 60\t| Iteration: 200 \t| Log-Likelihood:-3.190462704369726 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.476616  \n",
      "Run: 60\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029288197 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.496087  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 60\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.479714  \n",
      "Run: 60\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.660035  \n",
      "Run: 60\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.721042  \n",
      "Run: 60\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.453669  \n",
      "Run: 60\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.488062  \n",
      "Run: 60\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.504621  \n",
      "Run: 61\t| Iteration: 0 \t| Log-Likelihood:-3.891098910957085 \t|  theta: tensor([[0.5768, 2.8892]], requires_grad=True)  |  Time needed: 0:00:00.089760  \n",
      "Run: 61\t| Iteration: 100 \t| Log-Likelihood:-3.187872159252853 \t|  theta: tensor([[0.0501, 2.9674]], requires_grad=True)  |  Time needed: 0:00:09.440399  \n",
      "Run: 61\t| Iteration: 200 \t| Log-Likelihood:-3.187289400427576 \t|  theta: tensor([[0.0501, 2.9899]], requires_grad=True)  |  Time needed: 0:00:09.448992  \n",
      "Run: 61\t| Iteration: 300 \t| Log-Likelihood:-3.1872419597777224 \t|  theta: tensor([[0.0501, 2.9963]], requires_grad=True)  |  Time needed: 0:00:09.477267  \n",
      "Run: 61\t| Iteration: 400 \t| Log-Likelihood:-3.18723807287064 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.463360  \n",
      "Run: 61\t| Iteration: 500 \t| Log-Likelihood:-3.1872377877239138 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.494545  \n",
      "Run: 61\t| Iteration: 600 \t| Log-Likelihood:-3.1872377286476987 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.455165  \n",
      "Run: 61\t| Iteration: 700 \t| Log-Likelihood:-3.1872377340164393 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.673482  \n",
      "Run: 61\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.299309  \n",
      "Run: 61\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.271195  \n",
      "Run: 62\t| Iteration: 0 \t| Log-Likelihood:-3.203028781903524 \t|  theta: tensor([[0.5142, 1.0429]], requires_grad=True)  |  Time needed: 0:00:00.097520  \n",
      "Run: 62\t| Iteration: 100 \t| Log-Likelihood:-3.1904742639328134 \t|  theta: tensor([[0.4354, 1.0564]], requires_grad=True)  |  Time needed: 0:00:09.086441  \n",
      "Run: 62\t| Iteration: 200 \t| Log-Likelihood:-3.1904626835986876 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137067  \n",
      "Run: 62\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029369723 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.101681  \n",
      "Run: 62\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.218677  \n",
      "Run: 62\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.258681  \n",
      "Run: 62\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.161433  \n",
      "Run: 62\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.064298  \n",
      "Run: 62\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.170313  \n",
      "Run: 62\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.167031  \n",
      "Run: 63\t| Iteration: 0 \t| Log-Likelihood:-3.3001000623633936 \t|  theta: tensor([[0.4459, 0.9070]], requires_grad=True)  |  Time needed: 0:00:00.096631  \n",
      "Run: 63\t| Iteration: 100 \t| Log-Likelihood:-3.190466144165341 \t|  theta: tensor([[0.4342, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.092761  \n",
      "Run: 63\t| Iteration: 200 \t| Log-Likelihood:-3.1904627060309574 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082240  \n",
      "Run: 63\t| Iteration: 300 \t| Log-Likelihood:-3.190462673128239 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.073893  \n",
      "Run: 63\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097553  \n",
      "Run: 63\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142600  \n",
      "Run: 63\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.095845  \n",
      "Run: 63\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.088330  \n",
      "Run: 63\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.098482  \n",
      "Run: 63\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150278  \n",
      "Run: 64\t| Iteration: 0 \t| Log-Likelihood:-3.206988080308131 \t|  theta: tensor([[0.0803, 3.1287]], requires_grad=True)  |  Time needed: 0:00:00.095201  \n",
      "Run: 64\t| Iteration: 100 \t| Log-Likelihood:-3.1881132637127814 \t|  theta: tensor([[0.0501, 3.0359]], requires_grad=True)  |  Time needed: 0:00:09.664088  \n",
      "Run: 64\t| Iteration: 200 \t| Log-Likelihood:-3.18730889776533 \t|  theta: tensor([[0.0501, 3.0094]], requires_grad=True)  |  Time needed: 0:00:09.123697  \n",
      "Run: 64\t| Iteration: 300 \t| Log-Likelihood:-3.187243548966603 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.113612  \n",
      "Run: 64\t| Iteration: 400 \t| Log-Likelihood:-3.187238194010433 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.138182  \n",
      "Run: 64\t| Iteration: 500 \t| Log-Likelihood:-3.1872377758149737 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.125627  \n",
      "Run: 64\t| Iteration: 600 \t| Log-Likelihood:-3.187237770446435 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.106065  \n",
      "Run: 64\t| Iteration: 700 \t| Log-Likelihood:-3.1872377564457466 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.107461  \n",
      "Run: 64\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.116969  \n",
      "Run: 64\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.094328  \n",
      "Run: 65\t| Iteration: 0 \t| Log-Likelihood:-3.592097194874182 \t|  theta: tensor([[0.4044, 3.2593]], requires_grad=True)  |  Time needed: 0:00:00.095137  \n",
      "Run: 65\t| Iteration: 100 \t| Log-Likelihood:-3.190751610805843 \t|  theta: tensor([[0.0501, 3.0730]], requires_grad=True)  |  Time needed: 0:00:09.109055  \n",
      "Run: 65\t| Iteration: 200 \t| Log-Likelihood:-3.1875232876047725 \t|  theta: tensor([[0.0501, 3.0200]], requires_grad=True)  |  Time needed: 0:00:09.148058  \n",
      "Run: 65\t| Iteration: 300 \t| Log-Likelihood:-3.1872609738282085 \t|  theta: tensor([[0.0501, 3.0049]], requires_grad=True)  |  Time needed: 0:00:09.102894  \n",
      "Run: 65\t| Iteration: 400 \t| Log-Likelihood:-3.1872396572601556 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.122597  \n",
      "Run: 65\t| Iteration: 500 \t| Log-Likelihood:-3.1872378728556887 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.149276  \n",
      "Run: 65\t| Iteration: 600 \t| Log-Likelihood:-3.1872377313833344 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.188406  \n",
      "Run: 65\t| Iteration: 700 \t| Log-Likelihood:-3.187237760935221 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.600192  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 65\t| Iteration: 800 \t| Log-Likelihood:-3.1872377562288623 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.102536  \n",
      "Run: 65\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.104602  \n",
      "Run: 66\t| Iteration: 0 \t| Log-Likelihood:-3.5914456153285808 \t|  theta: tensor([[0.3420, 3.4564]], requires_grad=True)  |  Time needed: 0:00:00.089550  \n",
      "Run: 66\t| Iteration: 100 \t| Log-Likelihood:-3.1980674671879235 \t|  theta: tensor([[0.0501, 3.1290]], requires_grad=True)  |  Time needed: 0:00:09.305559  \n",
      "Run: 66\t| Iteration: 200 \t| Log-Likelihood:-3.1881168325924394 \t|  theta: tensor([[0.0501, 3.0360]], requires_grad=True)  |  Time needed: 0:00:09.347357  \n",
      "Run: 66\t| Iteration: 300 \t| Log-Likelihood:-3.187309180750834 \t|  theta: tensor([[0.0501, 3.0094]], requires_grad=True)  |  Time needed: 0:00:09.306356  \n",
      "Run: 66\t| Iteration: 400 \t| Log-Likelihood:-3.1872435680101074 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.328262  \n",
      "Run: 66\t| Iteration: 500 \t| Log-Likelihood:-3.187238195303661 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.357640  \n",
      "Run: 66\t| Iteration: 600 \t| Log-Likelihood:-3.1872377760362767 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.290572  \n",
      "Run: 66\t| Iteration: 700 \t| Log-Likelihood:-3.1872377704885992 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.324996  \n",
      "Run: 66\t| Iteration: 800 \t| Log-Likelihood:-3.1872377564457466 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.325193  \n",
      "Run: 66\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.331416  \n",
      "Run: 67\t| Iteration: 0 \t| Log-Likelihood:-3.697298960907382 \t|  theta: tensor([[0.4173, 0.7532]], requires_grad=True)  |  Time needed: 0:00:00.088271  \n",
      "Run: 67\t| Iteration: 100 \t| Log-Likelihood:-3.190466055673701 \t|  theta: tensor([[0.4342, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.115593  \n",
      "Run: 67\t| Iteration: 200 \t| Log-Likelihood:-3.190462676159524 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.101962  \n",
      "Run: 67\t| Iteration: 300 \t| Log-Likelihood:-3.190462673128239 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135353  \n",
      "Run: 67\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144473  \n",
      "Run: 67\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093479  \n",
      "Run: 67\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103069  \n",
      "Run: 67\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.580170  \n",
      "Run: 67\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.211001  \n",
      "Run: 67\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110269  \n",
      "Run: 68\t| Iteration: 0 \t| Log-Likelihood:-3.9452476023194754 \t|  theta: tensor([[0.5467, 2.5265]], requires_grad=True)  |  Time needed: 0:00:00.092683  \n",
      "Run: 68\t| Iteration: 100 \t| Log-Likelihood:-3.1997964651468873 \t|  theta: tensor([[0.0502, 2.8585]], requires_grad=True)  |  Time needed: 0:00:09.105902  \n",
      "Run: 68\t| Iteration: 200 \t| Log-Likelihood:-3.1882670838169007 \t|  theta: tensor([[0.0501, 2.9587]], requires_grad=True)  |  Time needed: 0:00:09.096912  \n",
      "Run: 68\t| Iteration: 300 \t| Log-Likelihood:-3.187321580794133 \t|  theta: tensor([[0.0501, 2.9874]], requires_grad=True)  |  Time needed: 0:00:09.142013  \n",
      "Run: 68\t| Iteration: 400 \t| Log-Likelihood:-3.1872445615233866 \t|  theta: tensor([[0.0501, 2.9956]], requires_grad=True)  |  Time needed: 0:00:09.118948  \n",
      "Run: 68\t| Iteration: 500 \t| Log-Likelihood:-3.187238310492239 \t|  theta: tensor([[0.0501, 2.9979]], requires_grad=True)  |  Time needed: 0:00:09.118158  \n",
      "Run: 68\t| Iteration: 600 \t| Log-Likelihood:-3.1872377975499853 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.136875  \n",
      "Run: 68\t| Iteration: 700 \t| Log-Likelihood:-3.1872377300606587 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.131856  \n",
      "Run: 68\t| Iteration: 800 \t| Log-Likelihood:-3.1872377341335514 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113043  \n",
      "Run: 68\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.126053  \n",
      "Run: 69\t| Iteration: 0 \t| Log-Likelihood:-6.062711287630502 \t|  theta: tensor([[0.5480, 4.8703]], requires_grad=True)  |  Time needed: 0:00:00.092539  \n",
      "Run: 69\t| Iteration: 100 \t| Log-Likelihood:-3.3681700076138137 \t|  theta: tensor([[0.0501, 3.5302]], requires_grad=True)  |  Time needed: 0:00:09.183535  \n",
      "Run: 69\t| Iteration: 200 \t| Log-Likelihood:-3.201838638982273 \t|  theta: tensor([[0.0501, 3.1499]], requires_grad=True)  |  Time needed: 0:00:09.134530  \n",
      "Run: 69\t| Iteration: 300 \t| Log-Likelihood:-3.1884223785405084 \t|  theta: tensor([[0.0501, 3.0419]], requires_grad=True)  |  Time needed: 0:00:09.203095  \n",
      "Run: 69\t| Iteration: 400 \t| Log-Likelihood:-3.187334074507966 \t|  theta: tensor([[0.0501, 3.0112]], requires_grad=True)  |  Time needed: 0:00:09.120267  \n",
      "Run: 69\t| Iteration: 500 \t| Log-Likelihood:-3.1872455613402155 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.126459  \n",
      "Run: 69\t| Iteration: 600 \t| Log-Likelihood:-3.1872383864196716 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.186678  \n",
      "Run: 69\t| Iteration: 700 \t| Log-Likelihood:-3.1872377930866165 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.214394  \n",
      "Run: 69\t| Iteration: 800 \t| Log-Likelihood:-3.187237771561061 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.141245  \n",
      "Run: 69\t| Iteration: 900 \t| Log-Likelihood:-3.187237756527817 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.134481  \n",
      "Run: 70\t| Iteration: 0 \t| Log-Likelihood:-3.5429975947763204 \t|  theta: tensor([[0.3347, 3.3852]], requires_grad=True)  |  Time needed: 0:00:00.092931  \n",
      "Run: 70\t| Iteration: 100 \t| Log-Likelihood:-3.194962466249629 \t|  theta: tensor([[0.0501, 3.1088]], requires_grad=True)  |  Time needed: 0:00:09.100854  \n",
      "Run: 70\t| Iteration: 200 \t| Log-Likelihood:-3.1878650771073627 \t|  theta: tensor([[0.0501, 3.0302]], requires_grad=True)  |  Time needed: 0:00:09.110421  \n",
      "Run: 70\t| Iteration: 300 \t| Log-Likelihood:-3.18728874137539 \t|  theta: tensor([[0.0501, 3.0078]], requires_grad=True)  |  Time needed: 0:00:09.155625  \n",
      "Run: 70\t| Iteration: 400 \t| Log-Likelihood:-3.1872418800026487 \t|  theta: tensor([[0.0501, 3.0014]], requires_grad=True)  |  Time needed: 0:00:09.227278  \n",
      "Run: 70\t| Iteration: 500 \t| Log-Likelihood:-3.187238097194741 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.102179  \n",
      "Run: 70\t| Iteration: 600 \t| Log-Likelihood:-3.187237757547981 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.156348  \n",
      "Run: 70\t| Iteration: 700 \t| Log-Likelihood:-3.1872377658831654 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.094992  \n",
      "Run: 70\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563683525 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.096354  \n",
      "Run: 70\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.127154  \n",
      "Run: 71\t| Iteration: 0 \t| Log-Likelihood:-4.777336806932941 \t|  theta: tensor([[0.4120, 4.3759]], requires_grad=True)  |  Time needed: 0:00:00.094564  \n",
      "Run: 71\t| Iteration: 100 \t| Log-Likelihood:-3.285172896866822 \t|  theta: tensor([[0.0501, 3.3899]], requires_grad=True)  |  Time needed: 0:00:09.292875  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 71\t| Iteration: 200 \t| Log-Likelihood:-3.1951512865517295 \t|  theta: tensor([[0.0501, 3.1101]], requires_grad=True)  |  Time needed: 0:00:09.297958  \n",
      "Run: 71\t| Iteration: 300 \t| Log-Likelihood:-3.1878803210551094 \t|  theta: tensor([[0.0501, 3.0306]], requires_grad=True)  |  Time needed: 0:00:09.744651  \n",
      "Run: 71\t| Iteration: 400 \t| Log-Likelihood:-3.1872899962737504 \t|  theta: tensor([[0.0501, 3.0079]], requires_grad=True)  |  Time needed: 0:00:09.309296  \n",
      "Run: 71\t| Iteration: 500 \t| Log-Likelihood:-3.1872419840252486 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.291357  \n",
      "Run: 71\t| Iteration: 600 \t| Log-Likelihood:-3.1872381055543753 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.325382  \n",
      "Run: 71\t| Iteration: 700 \t| Log-Likelihood:-3.1872377582386053 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.369404  \n",
      "Run: 71\t| Iteration: 800 \t| Log-Likelihood:-3.1872377659373776 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.308971  \n",
      "Run: 71\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563738805 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.316636  \n",
      "Run: 72\t| Iteration: 0 \t| Log-Likelihood:-4.893231425896747 \t|  theta: tensor([[0.3779, 4.4680]], requires_grad=True)  |  Time needed: 0:00:00.091570  \n",
      "Run: 72\t| Iteration: 100 \t| Log-Likelihood:-3.298701701591137 \t|  theta: tensor([[0.0501, 3.4160]], requires_grad=True)  |  Time needed: 0:00:09.096115  \n",
      "Run: 72\t| Iteration: 200 \t| Log-Likelihood:-3.196241819760272 \t|  theta: tensor([[0.0501, 3.1175]], requires_grad=True)  |  Time needed: 0:00:09.145149  \n",
      "Run: 72\t| Iteration: 300 \t| Log-Likelihood:-3.1879688238381494 \t|  theta: tensor([[0.0501, 3.0327]], requires_grad=True)  |  Time needed: 0:00:09.323996  \n",
      "Run: 72\t| Iteration: 400 \t| Log-Likelihood:-3.187297167917164 \t|  theta: tensor([[0.0501, 3.0085]], requires_grad=True)  |  Time needed: 0:00:09.106039  \n",
      "Run: 72\t| Iteration: 500 \t| Log-Likelihood:-3.187242598452042 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.114353  \n",
      "Run: 72\t| Iteration: 600 \t| Log-Likelihood:-3.1872381643011782 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.155126  \n",
      "Run: 72\t| Iteration: 700 \t| Log-Likelihood:-3.1872377658818714 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.100389  \n",
      "Run: 72\t| Iteration: 800 \t| Log-Likelihood:-3.187237766218004 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.098540  \n",
      "Run: 72\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564025847 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.186993  \n",
      "Run: 73\t| Iteration: 0 \t| Log-Likelihood:-3.569997618952162 \t|  theta: tensor([[0.3295, 2.5353]], requires_grad=True)  |  Time needed: 0:00:00.097542  \n",
      "Run: 73\t| Iteration: 100 \t| Log-Likelihood:-3.1991237925030735 \t|  theta: tensor([[0.0502, 2.8623]], requires_grad=True)  |  Time needed: 0:00:09.085681  \n",
      "Run: 73\t| Iteration: 200 \t| Log-Likelihood:-3.1882115811470237 \t|  theta: tensor([[0.0501, 2.9598]], requires_grad=True)  |  Time needed: 0:00:09.199887  \n",
      "Run: 73\t| Iteration: 300 \t| Log-Likelihood:-3.187317066205681 \t|  theta: tensor([[0.0501, 2.9877]], requires_grad=True)  |  Time needed: 0:00:09.195293  \n",
      "Run: 73\t| Iteration: 400 \t| Log-Likelihood:-3.1872442135896275 \t|  theta: tensor([[0.0501, 2.9957]], requires_grad=True)  |  Time needed: 0:00:09.121993  \n",
      "Run: 73\t| Iteration: 500 \t| Log-Likelihood:-3.1872382857238586 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.152611  \n",
      "Run: 73\t| Iteration: 600 \t| Log-Likelihood:-3.1872377951829143 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.196240  \n",
      "Run: 73\t| Iteration: 700 \t| Log-Likelihood:-3.1872377298572268 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.131980  \n",
      "Run: 73\t| Iteration: 800 \t| Log-Likelihood:-3.187237734120019 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.109789  \n",
      "Run: 73\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.166586  \n",
      "Run: 74\t| Iteration: 0 \t| Log-Likelihood:-3.471054647756698 \t|  theta: tensor([[0.3517, 2.9728]], requires_grad=True)  |  Time needed: 0:00:00.091848  \n",
      "Run: 74\t| Iteration: 100 \t| Log-Likelihood:-3.1872734530572973 \t|  theta: tensor([[0.0501, 2.9914]], requires_grad=True)  |  Time needed: 0:00:09.115383  \n",
      "Run: 74\t| Iteration: 200 \t| Log-Likelihood:-3.1872406174163865 \t|  theta: tensor([[0.0501, 2.9967]], requires_grad=True)  |  Time needed: 0:00:09.155599  \n",
      "Run: 74\t| Iteration: 300 \t| Log-Likelihood:-3.1872379889060882 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.162459  \n",
      "Run: 74\t| Iteration: 400 \t| Log-Likelihood:-3.187237786549128 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.149500  \n",
      "Run: 74\t| Iteration: 500 \t| Log-Likelihood:-3.18723773164813 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.177861  \n",
      "Run: 74\t| Iteration: 600 \t| Log-Likelihood:-3.1872377339420526 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113595  \n",
      "Run: 74\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.109046  \n",
      "Run: 74\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.146917  \n",
      "Run: 74\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.610061  \n",
      "Run: 75\t| Iteration: 0 \t| Log-Likelihood:-4.163616898500805 \t|  theta: tensor([[0.5422, 2.0457]], requires_grad=True)  |  Time needed: 0:00:00.093165  \n",
      "Run: 75\t| Iteration: 100 \t| Log-Likelihood:-3.281521712461058 \t|  theta: tensor([[0.0509, 2.6113]], requires_grad=True)  |  Time needed: 0:00:09.095209  \n",
      "Run: 75\t| Iteration: 200 \t| Log-Likelihood:-3.195289191729693 \t|  theta: tensor([[0.0501, 2.8865]], requires_grad=True)  |  Time needed: 0:00:09.148323  \n",
      "Run: 75\t| Iteration: 300 \t| Log-Likelihood:-3.187896096710577 \t|  theta: tensor([[0.0501, 2.9668]], requires_grad=True)  |  Time needed: 0:00:09.126899  \n",
      "Run: 75\t| Iteration: 400 \t| Log-Likelihood:-3.1872913094656012 \t|  theta: tensor([[0.0501, 2.9897]], requires_grad=True)  |  Time needed: 0:00:09.097468  \n",
      "Run: 75\t| Iteration: 500 \t| Log-Likelihood:-3.1872421043855224 \t|  theta: tensor([[0.0501, 2.9963]], requires_grad=True)  |  Time needed: 0:00:09.255700  \n",
      "Run: 75\t| Iteration: 600 \t| Log-Likelihood:-3.187238084427778 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.164672  \n",
      "Run: 75\t| Iteration: 700 \t| Log-Likelihood:-3.1872377887380554 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.096343  \n",
      "Run: 75\t| Iteration: 800 \t| Log-Likelihood:-3.1872377287387494 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.114379  \n",
      "Run: 75\t| Iteration: 900 \t| Log-Likelihood:-3.187237734027563 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.111982  \n",
      "Run: 76\t| Iteration: 0 \t| Log-Likelihood:-5.497926233461738 \t|  theta: tensor([[0.5073, 0.4329]], requires_grad=True)  |  Time needed: 0:00:00.088830  \n",
      "Run: 76\t| Iteration: 100 \t| Log-Likelihood:-3.190516078085742 \t|  theta: tensor([[0.4381, 1.0556]], requires_grad=True)  |  Time needed: 0:00:09.299463  \n",
      "Run: 76\t| Iteration: 200 \t| Log-Likelihood:-3.1904627512273667 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.321863  \n",
      "Run: 76\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029700667 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.305589  \n",
      "Run: 76\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.297622  \n",
      "Run: 76\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.363614  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 76\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.306151  \n",
      "Run: 76\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.283049  \n",
      "Run: 76\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.375460  \n",
      "Run: 76\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.315219  \n",
      "Run: 77\t| Iteration: 0 \t| Log-Likelihood:-3.2125990277832415 \t|  theta: tensor([[0.3609, 1.0169]], requires_grad=True)  |  Time needed: 0:00:00.091401  \n",
      "Run: 77\t| Iteration: 100 \t| Log-Likelihood:-3.1904680701218835 \t|  theta: tensor([[0.4313, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.119849  \n",
      "Run: 77\t| Iteration: 200 \t| Log-Likelihood:-3.1904627077560916 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097499  \n",
      "Run: 77\t| Iteration: 300 \t| Log-Likelihood:-3.190462673129442 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.087976  \n",
      "Run: 77\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097599  \n",
      "Run: 77\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.204876  \n",
      "Run: 77\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129659  \n",
      "Run: 77\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.100484  \n",
      "Run: 77\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144219  \n",
      "Run: 77\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.534425  \n",
      "Run: 78\t| Iteration: 0 \t| Log-Likelihood:-3.9331469092540803 \t|  theta: tensor([[0.3939, 1.8914]], requires_grad=True)  |  Time needed: 0:00:00.096870  \n",
      "Run: 78\t| Iteration: 100 \t| Log-Likelihood:-3.483733985208066 \t|  theta: tensor([[0.0589, 2.2874]], requires_grad=True)  |  Time needed: 0:00:09.135343  \n",
      "Run: 78\t| Iteration: 200 \t| Log-Likelihood:-3.2175487980214816 \t|  theta: tensor([[0.0503, 2.7804]], requires_grad=True)  |  Time needed: 0:00:09.342157  \n",
      "Run: 78\t| Iteration: 300 \t| Log-Likelihood:-3.189744252302629 \t|  theta: tensor([[0.0501, 2.9362]], requires_grad=True)  |  Time needed: 0:00:09.840513  \n",
      "Run: 78\t| Iteration: 400 \t| Log-Likelihood:-3.1874420369489025 \t|  theta: tensor([[0.0501, 2.9810]], requires_grad=True)  |  Time needed: 0:00:09.852213  \n",
      "Run: 78\t| Iteration: 500 \t| Log-Likelihood:-3.1872543923419956 \t|  theta: tensor([[0.0501, 2.9938]], requires_grad=True)  |  Time needed: 0:00:09.836089  \n",
      "Run: 78\t| Iteration: 600 \t| Log-Likelihood:-3.1872390685515555 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.720502  \n",
      "Run: 78\t| Iteration: 700 \t| Log-Likelihood:-3.1872378362874776 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.138247  \n",
      "Run: 78\t| Iteration: 800 \t| Log-Likelihood:-3.187237727884054 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.279283  \n",
      "Run: 78\t| Iteration: 900 \t| Log-Likelihood:-3.1872377345536314 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.114620  \n",
      "Run: 79\t| Iteration: 0 \t| Log-Likelihood:-3.6569563998485397 \t|  theta: tensor([[0.1583, 1.5643]], requires_grad=True)  |  Time needed: 0:00:00.092936  \n",
      "Run: 79\t| Iteration: 100 \t| Log-Likelihood:-3.191236706149832 \t|  theta: tensor([[0.4138, 1.0638]], requires_grad=True)  |  Time needed: 0:00:09.139084  \n",
      "Run: 79\t| Iteration: 200 \t| Log-Likelihood:-3.190463349453307 \t|  theta: tensor([[0.4324, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.174901  \n",
      "Run: 79\t| Iteration: 300 \t| Log-Likelihood:-3.1904627035345925 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.153664  \n",
      "Run: 79\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.155713  \n",
      "Run: 79\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.187882  \n",
      "Run: 79\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.149057  \n",
      "Run: 79\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142487  \n",
      "Run: 79\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113609  \n",
      "Run: 79\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.126091  \n",
      "Run: 80\t| Iteration: 0 \t| Log-Likelihood:-3.387189990949091 \t|  theta: tensor([[0.1828, 2.5688]], requires_grad=True)  |  Time needed: 0:00:00.096618  \n",
      "Run: 80\t| Iteration: 100 \t| Log-Likelihood:-3.1972885113087575 \t|  theta: tensor([[0.0502, 2.8733]], requires_grad=True)  |  Time needed: 0:00:09.116065  \n",
      "Run: 80\t| Iteration: 200 \t| Log-Likelihood:-3.1880604147600056 \t|  theta: tensor([[0.0501, 2.9630]], requires_grad=True)  |  Time needed: 0:00:09.162770  \n",
      "Run: 80\t| Iteration: 300 \t| Log-Likelihood:-3.1873047420087133 \t|  theta: tensor([[0.0501, 2.9886]], requires_grad=True)  |  Time needed: 0:00:09.108835  \n",
      "Run: 80\t| Iteration: 400 \t| Log-Likelihood:-3.187243199454027 \t|  theta: tensor([[0.0501, 2.9960]], requires_grad=True)  |  Time needed: 0:00:09.188059  \n",
      "Run: 80\t| Iteration: 500 \t| Log-Likelihood:-3.1872381538171957 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.155480  \n",
      "Run: 80\t| Iteration: 600 \t| Log-Likelihood:-3.1872377921182142 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.091872  \n",
      "Run: 80\t| Iteration: 700 \t| Log-Likelihood:-3.1872377292813705 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.096370  \n",
      "Run: 80\t| Iteration: 800 \t| Log-Likelihood:-3.187237734074889 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.252215  \n",
      "Run: 80\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.098254  \n",
      "Run: 81\t| Iteration: 0 \t| Log-Likelihood:-3.691989682275381 \t|  theta: tensor([[0.1037, 1.5268]], requires_grad=True)  |  Time needed: 0:00:00.088502  \n",
      "Run: 81\t| Iteration: 100 \t| Log-Likelihood:-3.1911205689925075 \t|  theta: tensor([[0.4152, 1.0631]], requires_grad=True)  |  Time needed: 0:00:09.286724  \n",
      "Run: 81\t| Iteration: 200 \t| Log-Likelihood:-3.1904632801393396 \t|  theta: tensor([[0.4324, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.278548  \n",
      "Run: 81\t| Iteration: 300 \t| Log-Likelihood:-3.190462673644886 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.306503  \n",
      "Run: 81\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.283096  \n",
      "Run: 81\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.308022  \n",
      "Run: 81\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.280468  \n",
      "Run: 81\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.325162  \n",
      "Run: 81\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.317842  \n",
      "Run: 81\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.253214  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 82\t| Iteration: 0 \t| Log-Likelihood:-3.692626813390757 \t|  theta: tensor([[0.2002, 0.8270]], requires_grad=True)  |  Time needed: 0:00:00.089512  \n",
      "Run: 82\t| Iteration: 100 \t| Log-Likelihood:-3.190491442641631 \t|  theta: tensor([[0.4291, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.282208  \n",
      "Run: 82\t| Iteration: 200 \t| Log-Likelihood:-3.1904626989399034 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113420  \n",
      "Run: 82\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327526622 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.174622  \n",
      "Run: 82\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.098556  \n",
      "Run: 82\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137297  \n",
      "Run: 82\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127160  \n",
      "Run: 82\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.086948  \n",
      "Run: 82\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102466  \n",
      "Run: 82\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.094584  \n",
      "Run: 83\t| Iteration: 0 \t| Log-Likelihood:-3.775373214734392 \t|  theta: tensor([[0.0944, 1.3752]], requires_grad=True)  |  Time needed: 0:00:00.095454  \n",
      "Run: 83\t| Iteration: 100 \t| Log-Likelihood:-3.1907279690651364 \t|  theta: tensor([[0.4215, 1.0605]], requires_grad=True)  |  Time needed: 0:00:09.132215  \n",
      "Run: 83\t| Iteration: 200 \t| Log-Likelihood:-3.190462938919803 \t|  theta: tensor([[0.4326, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.080913  \n",
      "Run: 83\t| Iteration: 300 \t| Log-Likelihood:-3.1904627329424238 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125442  \n",
      "Run: 83\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.157334  \n",
      "Run: 83\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.121262  \n",
      "Run: 83\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.184200  \n",
      "Run: 83\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119026  \n",
      "Run: 83\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105105  \n",
      "Run: 83\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117178  \n",
      "Run: 84\t| Iteration: 0 \t| Log-Likelihood:-5.470023463103926 \t|  theta: tensor([[0.3017, 4.7933]], requires_grad=True)  |  Time needed: 0:00:00.097585  \n",
      "Run: 84\t| Iteration: 100 \t| Log-Likelihood:-3.3535659944390686 \t|  theta: tensor([[0.0501, 3.5083]], requires_grad=True)  |  Time needed: 0:00:09.167699  \n",
      "Run: 84\t| Iteration: 200 \t| Log-Likelihood:-3.2006623601467026 \t|  theta: tensor([[0.0501, 3.1437]], requires_grad=True)  |  Time needed: 0:00:09.127867  \n",
      "Run: 84\t| Iteration: 300 \t| Log-Likelihood:-3.188327069177769 \t|  theta: tensor([[0.0501, 3.0402]], requires_grad=True)  |  Time needed: 0:00:09.141307  \n",
      "Run: 84\t| Iteration: 400 \t| Log-Likelihood:-3.1873263037734874 \t|  theta: tensor([[0.0501, 3.0106]], requires_grad=True)  |  Time needed: 0:00:09.135552  \n",
      "Run: 84\t| Iteration: 500 \t| Log-Likelihood:-3.1872449632301993 \t|  theta: tensor([[0.0501, 3.0022]], requires_grad=True)  |  Time needed: 0:00:09.112790  \n",
      "Run: 84\t| Iteration: 600 \t| Log-Likelihood:-3.187238326579296 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.196143  \n",
      "Run: 84\t| Iteration: 700 \t| Log-Likelihood:-3.1872377888898114 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.175206  \n",
      "Run: 84\t| Iteration: 800 \t| Log-Likelihood:-3.1872377712487623 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.112348  \n",
      "Run: 84\t| Iteration: 900 \t| Log-Likelihood:-3.1872377565063426 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.122353  \n",
      "Run: 85\t| Iteration: 0 \t| Log-Likelihood:-3.233959652282768 \t|  theta: tensor([[0.3343, 1.1541]], requires_grad=True)  |  Time needed: 0:00:00.095935  \n",
      "Run: 85\t| Iteration: 100 \t| Log-Likelihood:-3.190486593986181 \t|  theta: tensor([[0.4295, 1.0580]], requires_grad=True)  |  Time needed: 0:00:09.097353  \n",
      "Run: 85\t| Iteration: 200 \t| Log-Likelihood:-3.190462754174837 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108086  \n",
      "Run: 85\t| Iteration: 300 \t| Log-Likelihood:-3.190462702946068 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.217311  \n",
      "Run: 85\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.245941  \n",
      "Run: 85\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117493  \n",
      "Run: 85\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.586640  \n",
      "Run: 85\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.186952  \n",
      "Run: 85\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.173877  \n",
      "Run: 85\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.148207  \n",
      "Run: 86\t| Iteration: 0 \t| Log-Likelihood:-4.160551324999238 \t|  theta: tensor([[0.1270, 0.8248]], requires_grad=True)  |  Time needed: 0:00:00.093993  \n",
      "Run: 86\t| Iteration: 100 \t| Log-Likelihood:-3.1905059548230255 \t|  theta: tensor([[0.4282, 1.0582]], requires_grad=True)  |  Time needed: 0:00:09.296449  \n",
      "Run: 86\t| Iteration: 200 \t| Log-Likelihood:-3.1904627119594524 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.299409  \n",
      "Run: 86\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731594474 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.318530  \n",
      "Run: 86\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.298036  \n",
      "Run: 86\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.306919  \n",
      "Run: 86\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.472441  \n",
      "Run: 86\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.282948  \n",
      "Run: 86\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.303793  \n",
      "Run: 86\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.321326  \n",
      "Run: 87\t| Iteration: 0 \t| Log-Likelihood:-3.2345626371073695 \t|  theta: tensor([[0.1377, 2.9773]], requires_grad=True)  |  Time needed: 0:00:00.089618  \n",
      "Run: 87\t| Iteration: 100 \t| Log-Likelihood:-3.1872620954821085 \t|  theta: tensor([[0.0501, 2.9927]], requires_grad=True)  |  Time needed: 0:00:09.096792  \n",
      "Run: 87\t| Iteration: 200 \t| Log-Likelihood:-3.1872397009560123 \t|  theta: tensor([[0.0501, 2.9971]], requires_grad=True)  |  Time needed: 0:00:09.257430  \n",
      "Run: 87\t| Iteration: 300 \t| Log-Likelihood:-3.187237932478166 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.179897  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 87\t| Iteration: 400 \t| Log-Likelihood:-3.187237724570214 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.103636  \n",
      "Run: 87\t| Iteration: 500 \t| Log-Likelihood:-3.1872377311819737 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.121014  \n",
      "Run: 87\t| Iteration: 600 \t| Log-Likelihood:-3.1872377376088985 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108247  \n",
      "Run: 87\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.195713  \n",
      "Run: 87\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.116549  \n",
      "Run: 87\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113438  \n",
      "Run: 88\t| Iteration: 0 \t| Log-Likelihood:-4.633608804418249 \t|  theta: tensor([[0.0421, 4.4996]], requires_grad=True)  |  Time needed: 0:00:00.098796  \n",
      "Run: 88\t| Iteration: 100 \t| Log-Likelihood:-3.3035413535111333 \t|  theta: tensor([[0.0501, 3.4249]], requires_grad=True)  |  Time needed: 0:00:09.118265  \n",
      "Run: 88\t| Iteration: 200 \t| Log-Likelihood:-3.196631853749839 \t|  theta: tensor([[0.0501, 3.1201]], requires_grad=True)  |  Time needed: 0:00:09.138346  \n",
      "Run: 88\t| Iteration: 300 \t| Log-Likelihood:-3.188000401768347 \t|  theta: tensor([[0.0501, 3.0334]], requires_grad=True)  |  Time needed: 0:00:09.171564  \n",
      "Run: 88\t| Iteration: 400 \t| Log-Likelihood:-3.1872997750449024 \t|  theta: tensor([[0.0501, 3.0087]], requires_grad=True)  |  Time needed: 0:00:09.124293  \n",
      "Run: 88\t| Iteration: 500 \t| Log-Likelihood:-3.1872427583383423 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.175712  \n",
      "Run: 88\t| Iteration: 600 \t| Log-Likelihood:-3.1872381812411854 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.259862  \n",
      "Run: 88\t| Iteration: 700 \t| Log-Likelihood:-3.187237767175745 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.223443  \n",
      "Run: 88\t| Iteration: 800 \t| Log-Likelihood:-3.187237766315089 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.126630  \n",
      "Run: 88\t| Iteration: 900 \t| Log-Likelihood:-3.187237756408538 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.166542  \n",
      "Run: 89\t| Iteration: 0 \t| Log-Likelihood:-3.2694711015886497 \t|  theta: tensor([[0.2547, 1.1397]], requires_grad=True)  |  Time needed: 0:00:00.095973  \n",
      "Run: 89\t| Iteration: 100 \t| Log-Likelihood:-3.1905148535766097 \t|  theta: tensor([[0.4278, 1.0584]], requires_grad=True)  |  Time needed: 0:00:09.137205  \n",
      "Run: 89\t| Iteration: 200 \t| Log-Likelihood:-3.1904627496917253 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.610333  \n",
      "Run: 89\t| Iteration: 300 \t| Log-Likelihood:-3.190462702968558 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.166860  \n",
      "Run: 89\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136689  \n",
      "Run: 89\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.168913  \n",
      "Run: 89\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156621  \n",
      "Run: 89\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104177  \n",
      "Run: 89\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.580129  \n",
      "Run: 89\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.151283  \n",
      "Run: 90\t| Iteration: 0 \t| Log-Likelihood:-3.2094573645040256 \t|  theta: tensor([[0.1012, 3.0469]], requires_grad=True)  |  Time needed: 0:00:00.090757  \n",
      "Run: 90\t| Iteration: 100 \t| Log-Likelihood:-3.187357658222979 \t|  theta: tensor([[0.0501, 3.0126]], requires_grad=True)  |  Time needed: 0:00:09.111318  \n",
      "Run: 90\t| Iteration: 200 \t| Log-Likelihood:-3.1872474872794334 \t|  theta: tensor([[0.0501, 3.0028]], requires_grad=True)  |  Time needed: 0:00:09.137038  \n",
      "Run: 90\t| Iteration: 300 \t| Log-Likelihood:-3.187238560862542 \t|  theta: tensor([[0.0501, 3.0000]], requires_grad=True)  |  Time needed: 0:00:09.123164  \n",
      "Run: 90\t| Iteration: 400 \t| Log-Likelihood:-3.1872378133263704 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.108249  \n",
      "Run: 90\t| Iteration: 500 \t| Log-Likelihood:-3.1872377763497375 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.136276  \n",
      "Run: 90\t| Iteration: 600 \t| Log-Likelihood:-3.187237760321356 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.111429  \n",
      "Run: 90\t| Iteration: 700 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.099313  \n",
      "Run: 90\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.252262  \n",
      "Run: 90\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.241329  \n",
      "Run: 91\t| Iteration: 0 \t| Log-Likelihood:-5.097398704573925 \t|  theta: tensor([[0.2057, 4.6746]], requires_grad=True)  |  Time needed: 0:00:00.092465  \n",
      "Run: 91\t| Iteration: 100 \t| Log-Likelihood:-3.332257545406934 \t|  theta: tensor([[0.0501, 3.4746]], requires_grad=True)  |  Time needed: 0:00:09.313168  \n",
      "Run: 91\t| Iteration: 200 \t| Log-Likelihood:-3.1989457360648803 \t|  theta: tensor([[0.0501, 3.1342]], requires_grad=True)  |  Time needed: 0:00:09.322621  \n",
      "Run: 91\t| Iteration: 300 \t| Log-Likelihood:-3.188187962142668 \t|  theta: tensor([[0.0501, 3.0374]], requires_grad=True)  |  Time needed: 0:00:09.293060  \n",
      "Run: 91\t| Iteration: 400 \t| Log-Likelihood:-3.187314969529151 \t|  theta: tensor([[0.0501, 3.0099]], requires_grad=True)  |  Time needed: 0:00:09.272760  \n",
      "Run: 91\t| Iteration: 500 \t| Log-Likelihood:-3.187244000950507 \t|  theta: tensor([[0.0501, 3.0020]], requires_grad=True)  |  Time needed: 0:00:09.295445  \n",
      "Run: 91\t| Iteration: 600 \t| Log-Likelihood:-3.1872382418360905 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.293987  \n",
      "Run: 91\t| Iteration: 700 \t| Log-Likelihood:-3.187237779124661 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.286332  \n",
      "Run: 91\t| Iteration: 800 \t| Log-Likelihood:-3.1872377707475383 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.388827  \n",
      "Run: 91\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564653074 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.277874  \n",
      "Run: 92\t| Iteration: 0 \t| Log-Likelihood:-3.9631353085019922 \t|  theta: tensor([[0.4337, 1.8186]], requires_grad=True)  |  Time needed: 0:00:00.088592  \n",
      "Run: 92\t| Iteration: 100 \t| Log-Likelihood:-3.220830989221611 \t|  theta: tensor([[0.3437, 1.1334]], requires_grad=True)  |  Time needed: 0:00:09.118306  \n",
      "Run: 92\t| Iteration: 200 \t| Log-Likelihood:-3.1904809153928673 \t|  theta: tensor([[0.4299, 1.0578]], requires_grad=True)  |  Time needed: 0:00:09.134900  \n",
      "Run: 92\t| Iteration: 300 \t| Log-Likelihood:-3.1904627491129567 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128745  \n",
      "Run: 92\t| Iteration: 400 \t| Log-Likelihood:-3.1904627327443165 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.192087  \n",
      "Run: 92\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.124494  \n",
      "Run: 92\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117930  \n",
      "Run: 92\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099526  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 92\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.575086  \n",
      "Run: 92\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.115402  \n",
      "Run: 93\t| Iteration: 0 \t| Log-Likelihood:-4.145555407888312 \t|  theta: tensor([[0.4429, 3.9112]], requires_grad=True)  |  Time needed: 0:00:00.093180  \n",
      "Run: 93\t| Iteration: 100 \t| Log-Likelihood:-3.2302456489897735 \t|  theta: tensor([[0.0501, 3.2581]], requires_grad=True)  |  Time needed: 0:00:09.132656  \n",
      "Run: 93\t| Iteration: 200 \t| Log-Likelihood:-3.190719335399629 \t|  theta: tensor([[0.0501, 3.0727]], requires_grad=True)  |  Time needed: 0:00:09.095205  \n",
      "Run: 93\t| Iteration: 300 \t| Log-Likelihood:-3.187520672850904 \t|  theta: tensor([[0.0501, 3.0199]], requires_grad=True)  |  Time needed: 0:00:09.118321  \n",
      "Run: 93\t| Iteration: 400 \t| Log-Likelihood:-3.1872607583129424 \t|  theta: tensor([[0.0501, 3.0049]], requires_grad=True)  |  Time needed: 0:00:09.104823  \n",
      "Run: 93\t| Iteration: 500 \t| Log-Likelihood:-3.187239637009796 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.076167  \n",
      "Run: 93\t| Iteration: 600 \t| Log-Likelihood:-3.187237871235151 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.144216  \n",
      "Run: 93\t| Iteration: 700 \t| Log-Likelihood:-3.1872377312993616 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.131870  \n",
      "Run: 93\t| Iteration: 800 \t| Log-Likelihood:-3.1872377609230327 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113335  \n",
      "Run: 93\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562288623 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.165159  \n",
      "Run: 94\t| Iteration: 0 \t| Log-Likelihood:-5.5959295829906575 \t|  theta: tensor([[0.1595, 4.9108]], requires_grad=True)  |  Time needed: 0:00:00.093329  \n",
      "Run: 94\t| Iteration: 100 \t| Log-Likelihood:-3.3761587765185257 \t|  theta: tensor([[0.0501, 3.5418]], requires_grad=True)  |  Time needed: 0:00:09.108381  \n",
      "Run: 94\t| Iteration: 200 \t| Log-Likelihood:-3.2024821406542396 \t|  theta: tensor([[0.0501, 3.1532]], requires_grad=True)  |  Time needed: 0:00:09.104783  \n",
      "Run: 94\t| Iteration: 300 \t| Log-Likelihood:-3.1884744441863178 \t|  theta: tensor([[0.0501, 3.0429]], requires_grad=True)  |  Time needed: 0:00:09.080121  \n",
      "Run: 94\t| Iteration: 400 \t| Log-Likelihood:-3.187338295071828 \t|  theta: tensor([[0.0501, 3.0114]], requires_grad=True)  |  Time needed: 0:00:09.241154  \n",
      "Run: 94\t| Iteration: 500 \t| Log-Likelihood:-3.187245916581238 \t|  theta: tensor([[0.0501, 3.0025]], requires_grad=True)  |  Time needed: 0:00:09.184297  \n",
      "Run: 94\t| Iteration: 600 \t| Log-Likelihood:-3.1872384137634913 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.115268  \n",
      "Run: 94\t| Iteration: 700 \t| Log-Likelihood:-3.1872377990642566 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.659786  \n",
      "Run: 94\t| Iteration: 800 \t| Log-Likelihood:-3.1872377717341824 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.426467  \n",
      "Run: 94\t| Iteration: 900 \t| Log-Likelihood:-3.187237756542487 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.126321  \n",
      "Run: 95\t| Iteration: 0 \t| Log-Likelihood:-3.5885021093280107 \t|  theta: tensor([[0.1339, 2.1828]], requires_grad=True)  |  Time needed: 0:00:00.091578  \n",
      "Run: 95\t| Iteration: 100 \t| Log-Likelihood:-3.231200154029054 \t|  theta: tensor([[0.0504, 2.7355]], requires_grad=True)  |  Time needed: 0:00:09.202710  \n",
      "Run: 95\t| Iteration: 200 \t| Log-Likelihood:-3.1908969426792377 \t|  theta: tensor([[0.0501, 2.9232]], requires_grad=True)  |  Time needed: 0:00:09.152490  \n",
      "Run: 95\t| Iteration: 300 \t| Log-Likelihood:-3.1875362052774494 \t|  theta: tensor([[0.0501, 2.9773]], requires_grad=True)  |  Time needed: 0:00:09.107723  \n",
      "Run: 95\t| Iteration: 400 \t| Log-Likelihood:-3.187262026788532 \t|  theta: tensor([[0.0501, 2.9927]], requires_grad=True)  |  Time needed: 0:00:09.145188  \n",
      "Run: 95\t| Iteration: 500 \t| Log-Likelihood:-3.1872396935430354 \t|  theta: tensor([[0.0501, 2.9971]], requires_grad=True)  |  Time needed: 0:00:09.109398  \n",
      "Run: 95\t| Iteration: 600 \t| Log-Likelihood:-3.187237931571936 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.199296  \n",
      "Run: 95\t| Iteration: 700 \t| Log-Likelihood:-3.187237724570214 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.117129  \n",
      "Run: 95\t| Iteration: 800 \t| Log-Likelihood:-3.1872377311819737 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.109472  \n",
      "Run: 95\t| Iteration: 900 \t| Log-Likelihood:-3.1872377376088985 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.098663  \n",
      "Run: 96\t| Iteration: 0 \t| Log-Likelihood:-3.6973724955460145 \t|  theta: tensor([[0.3564, 3.5848]], requires_grad=True)  |  Time needed: 0:00:00.094513  \n",
      "Run: 96\t| Iteration: 100 \t| Log-Likelihood:-3.2049891175497236 \t|  theta: tensor([[0.0501, 3.1654]], requires_grad=True)  |  Time needed: 0:00:09.291268  \n",
      "Run: 96\t| Iteration: 200 \t| Log-Likelihood:-3.1886774617250673 \t|  theta: tensor([[0.0501, 3.0463]], requires_grad=True)  |  Time needed: 0:00:09.316003  \n",
      "Run: 96\t| Iteration: 300 \t| Log-Likelihood:-3.18735479276574 \t|  theta: tensor([[0.0501, 3.0124]], requires_grad=True)  |  Time needed: 0:00:09.292937  \n",
      "Run: 96\t| Iteration: 400 \t| Log-Likelihood:-3.1872472437767474 \t|  theta: tensor([[0.0501, 3.0027]], requires_grad=True)  |  Time needed: 0:00:09.836370  \n",
      "Run: 96\t| Iteration: 500 \t| Log-Likelihood:-3.187238537805912 \t|  theta: tensor([[0.0501, 3.0000]], requires_grad=True)  |  Time needed: 0:00:09.386230  \n",
      "Run: 96\t| Iteration: 600 \t| Log-Likelihood:-3.1872378117097258 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.296925  \n",
      "Run: 96\t| Iteration: 700 \t| Log-Likelihood:-3.187237772488387 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.311748  \n",
      "Run: 96\t| Iteration: 800 \t| Log-Likelihood:-3.1872377603134905 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.282387  \n",
      "Run: 96\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.295659  \n",
      "Run: 97\t| Iteration: 0 \t| Log-Likelihood:-3.2537323316746543 \t|  theta: tensor([[0.1347, 3.1836]], requires_grad=True)  |  Time needed: 0:00:00.087716  \n",
      "Run: 97\t| Iteration: 100 \t| Log-Likelihood:-3.189007399266542 \t|  theta: tensor([[0.0501, 3.0515]], requires_grad=True)  |  Time needed: 0:00:09.088349  \n",
      "Run: 97\t| Iteration: 200 \t| Log-Likelihood:-3.187381606188242 \t|  theta: tensor([[0.0501, 3.0139]], requires_grad=True)  |  Time needed: 0:00:09.110355  \n",
      "Run: 97\t| Iteration: 300 \t| Log-Likelihood:-3.187249442268057 \t|  theta: tensor([[0.0501, 3.0032]], requires_grad=True)  |  Time needed: 0:00:09.181103  \n",
      "Run: 97\t| Iteration: 400 \t| Log-Likelihood:-3.1872386790705036 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.119596  \n",
      "Run: 97\t| Iteration: 500 \t| Log-Likelihood:-3.1872378297769064 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.159029  \n",
      "Run: 97\t| Iteration: 600 \t| Log-Likelihood:-3.1872377773816547 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.121759  \n",
      "Run: 97\t| Iteration: 700 \t| Log-Likelihood:-3.1872377603784074 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.343658  \n",
      "Run: 97\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.198364  \n",
      "Run: 97\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108782  \n",
      "Run: 98\t| Iteration: 0 \t| Log-Likelihood:-4.075871480147191 \t|  theta: tensor([[0.1825, 0.7307]], requires_grad=True)  |  Time needed: 0:00:00.092049  \n",
      "Run: 98\t| Iteration: 100 \t| Log-Likelihood:-3.1904882140312427 \t|  theta: tensor([[0.4293, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.112040  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 98\t| Iteration: 200 \t| Log-Likelihood:-3.1904627258016665 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093388  \n",
      "Run: 98\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029480683 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.207289  \n",
      "Run: 98\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.159079  \n",
      "Run: 98\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.122483  \n",
      "Run: 98\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119552  \n",
      "Run: 98\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110131  \n",
      "Run: 98\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.155716  \n",
      "Run: 98\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.124725  \n",
      "Run: 99\t| Iteration: 0 \t| Log-Likelihood:-3.8756515810379937 \t|  theta: tensor([[0.2565, 3.9040]], requires_grad=True)  |  Time needed: 0:00:00.092181  \n",
      "Run: 99\t| Iteration: 100 \t| Log-Likelihood:-3.2295640786001383 \t|  theta: tensor([[0.0501, 3.2560]], requires_grad=True)  |  Time needed: 0:00:09.162469  \n",
      "Run: 99\t| Iteration: 200 \t| Log-Likelihood:-3.190664301263267 \t|  theta: tensor([[0.0501, 3.0721]], requires_grad=True)  |  Time needed: 0:00:09.112563  \n",
      "Run: 99\t| Iteration: 300 \t| Log-Likelihood:-3.187516155642639 \t|  theta: tensor([[0.0501, 3.0197]], requires_grad=True)  |  Time needed: 0:00:09.148754  \n",
      "Run: 99\t| Iteration: 400 \t| Log-Likelihood:-3.187260385699508 \t|  theta: tensor([[0.0501, 3.0048]], requires_grad=True)  |  Time needed: 0:00:09.104999  \n",
      "Run: 99\t| Iteration: 500 \t| Log-Likelihood:-3.187239602495583 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.116214  \n",
      "Run: 99\t| Iteration: 600 \t| Log-Likelihood:-3.187237869039144 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.165732  \n",
      "Run: 99\t| Iteration: 700 \t| Log-Likelihood:-3.1872377310906703 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.229614  \n",
      "Run: 99\t| Iteration: 800 \t| Log-Likelihood:-3.187237760910914 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.205872  \n",
      "Run: 99\t| Iteration: 900 \t| Log-Likelihood:-3.187237756225673 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.195909  \n",
      "Run: 100\t| Iteration: 0 \t| Log-Likelihood:-3.605848676402666 \t|  theta: tensor([[0.2599, 0.8213]], requires_grad=True)  |  Time needed: 0:00:00.100438  \n",
      "Run: 100\t| Iteration: 100 \t| Log-Likelihood:-3.1904777076791255 \t|  theta: tensor([[0.4302, 1.0577]], requires_grad=True)  |  Time needed: 0:00:09.138936  \n",
      "Run: 100\t| Iteration: 200 \t| Log-Likelihood:-3.1904626866162262 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103963  \n",
      "Run: 100\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327421737 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.180425  \n",
      "Run: 100\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.166647  \n",
      "Run: 100\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093772  \n",
      "Run: 100\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135466  \n",
      "Run: 100\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.095056  \n",
      "Run: 100\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102124  \n",
      "Run: 100\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.114707  \n",
      "Run: 101\t| Iteration: 0 \t| Log-Likelihood:-5.0068984351991475 \t|  theta: tensor([[0.1346, 4.6622]], requires_grad=True)  |  Time needed: 0:00:00.092332  \n",
      "Run: 101\t| Iteration: 100 \t| Log-Likelihood:-3.3301246894691574 \t|  theta: tensor([[0.0501, 3.4711]], requires_grad=True)  |  Time needed: 0:00:09.287742  \n",
      "Run: 101\t| Iteration: 200 \t| Log-Likelihood:-3.198773867989394 \t|  theta: tensor([[0.0501, 3.1332]], requires_grad=True)  |  Time needed: 0:00:09.762890  \n",
      "Run: 101\t| Iteration: 300 \t| Log-Likelihood:-3.188174114852532 \t|  theta: tensor([[0.0501, 3.0371]], requires_grad=True)  |  Time needed: 0:00:09.281389  \n",
      "Run: 101\t| Iteration: 400 \t| Log-Likelihood:-3.187313903590789 \t|  theta: tensor([[0.0501, 3.0098]], requires_grad=True)  |  Time needed: 0:00:09.304467  \n",
      "Run: 101\t| Iteration: 500 \t| Log-Likelihood:-3.1872439088420554 \t|  theta: tensor([[0.0501, 3.0020]], requires_grad=True)  |  Time needed: 0:00:09.367007  \n",
      "Run: 101\t| Iteration: 600 \t| Log-Likelihood:-3.1872382295291506 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.292731  \n",
      "Run: 101\t| Iteration: 700 \t| Log-Likelihood:-3.1872377785126957 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.352207  \n",
      "Run: 101\t| Iteration: 800 \t| Log-Likelihood:-3.1872377707036734 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.286805  \n",
      "Run: 101\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564653074 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.305645  \n",
      "Run: 102\t| Iteration: 0 \t| Log-Likelihood:-5.894117566784604 \t|  theta: tensor([[0.3628, 4.9369]], requires_grad=True)  |  Time needed: 0:00:00.090036  \n",
      "Run: 102\t| Iteration: 100 \t| Log-Likelihood:-3.3813559690579824 \t|  theta: tensor([[0.0501, 3.5492]], requires_grad=True)  |  Time needed: 0:00:09.082564  \n",
      "Run: 102\t| Iteration: 200 \t| Log-Likelihood:-3.2029008084489403 \t|  theta: tensor([[0.0501, 3.1553]], requires_grad=True)  |  Time needed: 0:00:09.126890  \n",
      "Run: 102\t| Iteration: 300 \t| Log-Likelihood:-3.188508381446503 \t|  theta: tensor([[0.0501, 3.0435]], requires_grad=True)  |  Time needed: 0:00:09.085209  \n",
      "Run: 102\t| Iteration: 400 \t| Log-Likelihood:-3.187341020871372 \t|  theta: tensor([[0.0501, 3.0116]], requires_grad=True)  |  Time needed: 0:00:09.084213  \n",
      "Run: 102\t| Iteration: 500 \t| Log-Likelihood:-3.187246152144397 \t|  theta: tensor([[0.0501, 3.0025]], requires_grad=True)  |  Time needed: 0:00:09.129746  \n",
      "Run: 102\t| Iteration: 600 \t| Log-Likelihood:-3.1872384360368766 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.099145  \n",
      "Run: 102\t| Iteration: 700 \t| Log-Likelihood:-3.1872378005628463 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.115436  \n",
      "Run: 102\t| Iteration: 800 \t| Log-Likelihood:-3.1872377718346674 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.100249  \n",
      "Run: 102\t| Iteration: 900 \t| Log-Likelihood:-3.187237756549928 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.117913  \n",
      "Run: 103\t| Iteration: 0 \t| Log-Likelihood:-3.8664242633801904 \t|  theta: tensor([[0.0576, 4.0273]], requires_grad=True)  |  Time needed: 0:00:00.093925  \n",
      "Run: 103\t| Iteration: 100 \t| Log-Likelihood:-3.2418747167097752 \t|  theta: tensor([[0.0501, 3.2910]], requires_grad=True)  |  Time needed: 0:00:09.106832  \n",
      "Run: 103\t| Iteration: 200 \t| Log-Likelihood:-3.1916583259308924 \t|  theta: tensor([[0.0501, 3.0820]], requires_grad=True)  |  Time needed: 0:00:09.124508  \n",
      "Run: 103\t| Iteration: 300 \t| Log-Likelihood:-3.187596951390001 \t|  theta: tensor([[0.0501, 3.0226]], requires_grad=True)  |  Time needed: 0:00:09.112255  \n",
      "Run: 103\t| Iteration: 400 \t| Log-Likelihood:-3.187266975669284 \t|  theta: tensor([[0.0501, 3.0056]], requires_grad=True)  |  Time needed: 0:00:09.100750  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 103\t| Iteration: 500 \t| Log-Likelihood:-3.187240116958921 \t|  theta: tensor([[0.0501, 3.0008]], requires_grad=True)  |  Time needed: 0:00:09.252764  \n",
      "Run: 103\t| Iteration: 600 \t| Log-Likelihood:-3.187237923504832 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.432026  \n",
      "Run: 103\t| Iteration: 700 \t| Log-Likelihood:-3.18723773832041 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.085846  \n",
      "Run: 103\t| Iteration: 800 \t| Log-Likelihood:-3.187237761166744 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.083878  \n",
      "Run: 103\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562607603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.127451  \n",
      "Run: 104\t| Iteration: 0 \t| Log-Likelihood:-3.9273552430481304 \t|  theta: tensor([[0.4831, 2.3298]], requires_grad=True)  |  Time needed: 0:00:00.091661  \n",
      "Run: 104\t| Iteration: 100 \t| Log-Likelihood:-3.2151292011359063 \t|  theta: tensor([[0.0502, 2.7894]], requires_grad=True)  |  Time needed: 0:00:09.083029  \n",
      "Run: 104\t| Iteration: 200 \t| Log-Likelihood:-3.189541381772019 \t|  theta: tensor([[0.0501, 2.9388]], requires_grad=True)  |  Time needed: 0:00:09.217550  \n",
      "Run: 104\t| Iteration: 300 \t| Log-Likelihood:-3.1874255115640406 \t|  theta: tensor([[0.0501, 2.9817]], requires_grad=True)  |  Time needed: 0:00:09.137224  \n",
      "Run: 104\t| Iteration: 400 \t| Log-Likelihood:-3.187253018577677 \t|  theta: tensor([[0.0501, 2.9940]], requires_grad=True)  |  Time needed: 0:00:09.084721  \n",
      "Run: 104\t| Iteration: 500 \t| Log-Likelihood:-3.187238967836271 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.278590  \n",
      "Run: 104\t| Iteration: 600 \t| Log-Likelihood:-3.187237831329155 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.116794  \n",
      "Run: 104\t| Iteration: 700 \t| Log-Likelihood:-3.1872377271504546 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.087272  \n",
      "Run: 104\t| Iteration: 800 \t| Log-Likelihood:-3.187237734493052 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.117844  \n",
      "Run: 104\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.213763  \n",
      "Run: 105\t| Iteration: 0 \t| Log-Likelihood:-3.79647470538932 \t|  theta: tensor([[0.3671, 1.6637]], requires_grad=True)  |  Time needed: 0:00:00.090574  \n",
      "Run: 105\t| Iteration: 100 \t| Log-Likelihood:-3.191390704848838 \t|  theta: tensor([[0.4122, 1.0650]], requires_grad=True)  |  Time needed: 0:00:09.083653  \n",
      "Run: 105\t| Iteration: 200 \t| Log-Likelihood:-3.1904635339122382 \t|  theta: tensor([[0.4323, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.112767  \n",
      "Run: 105\t| Iteration: 300 \t| Log-Likelihood:-3.1904627036479805 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110393  \n",
      "Run: 105\t| Iteration: 400 \t| Log-Likelihood:-3.190462732730266 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.316909  \n",
      "Run: 105\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127655  \n",
      "Run: 105\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.243589  \n",
      "Run: 105\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.091583  \n",
      "Run: 105\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108327  \n",
      "Run: 105\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.096660  \n",
      "Run: 106\t| Iteration: 0 \t| Log-Likelihood:-3.334832206381266 \t|  theta: tensor([[0.2660, 0.9512]], requires_grad=True)  |  Time needed: 0:00:00.095992  \n",
      "Run: 106\t| Iteration: 100 \t| Log-Likelihood:-3.1904853105068307 \t|  theta: tensor([[0.4296, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.346717  \n",
      "Run: 106\t| Iteration: 200 \t| Log-Likelihood:-3.1904627232148934 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.346790  \n",
      "Run: 106\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731429215 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.324804  \n",
      "Run: 106\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.328247  \n",
      "Run: 106\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.352446  \n",
      "Run: 106\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.391916  \n",
      "Run: 106\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.318357  \n",
      "Run: 106\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.335008  \n",
      "Run: 106\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.402699  \n",
      "Run: 107\t| Iteration: 0 \t| Log-Likelihood:-3.8811969489051243 \t|  theta: tensor([[0.5720, 3.1176]], requires_grad=True)  |  Time needed: 0:00:00.088817  \n",
      "Run: 107\t| Iteration: 100 \t| Log-Likelihood:-3.1879682056678473 \t|  theta: tensor([[0.0501, 3.0327]], requires_grad=True)  |  Time needed: 0:00:09.477899  \n",
      "Run: 107\t| Iteration: 200 \t| Log-Likelihood:-3.187297127287643 \t|  theta: tensor([[0.0501, 3.0085]], requires_grad=True)  |  Time needed: 0:00:09.316439  \n",
      "Run: 107\t| Iteration: 300 \t| Log-Likelihood:-3.1872425976242935 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.156298  \n",
      "Run: 107\t| Iteration: 400 \t| Log-Likelihood:-3.1872381643011782 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.187088  \n",
      "Run: 107\t| Iteration: 500 \t| Log-Likelihood:-3.1872377658818714 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.128485  \n",
      "Run: 107\t| Iteration: 600 \t| Log-Likelihood:-3.187237766218004 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.152486  \n",
      "Run: 107\t| Iteration: 700 \t| Log-Likelihood:-3.1872377564025847 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.143547  \n",
      "Run: 107\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.167612  \n",
      "Run: 107\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.267264  \n",
      "Run: 108\t| Iteration: 0 \t| Log-Likelihood:-3.790798466014525 \t|  theta: tensor([[0.1365, 3.9312]], requires_grad=True)  |  Time needed: 0:00:00.093969  \n",
      "Run: 108\t| Iteration: 100 \t| Log-Likelihood:-3.2321493708633344 \t|  theta: tensor([[0.0501, 3.2637]], requires_grad=True)  |  Time needed: 0:00:09.409430  \n",
      "Run: 108\t| Iteration: 200 \t| Log-Likelihood:-3.190873158543124 \t|  theta: tensor([[0.0501, 3.0743]], requires_grad=True)  |  Time needed: 0:00:09.193038  \n",
      "Run: 108\t| Iteration: 300 \t| Log-Likelihood:-3.1875331691343782 \t|  theta: tensor([[0.0501, 3.0204]], requires_grad=True)  |  Time needed: 0:00:09.164586  \n",
      "Run: 108\t| Iteration: 400 \t| Log-Likelihood:-3.1872617976484543 \t|  theta: tensor([[0.0501, 3.0050]], requires_grad=True)  |  Time needed: 0:00:09.176518  \n",
      "Run: 108\t| Iteration: 500 \t| Log-Likelihood:-3.187239665048316 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.159783  \n",
      "Run: 108\t| Iteration: 600 \t| Log-Likelihood:-3.187237877768749 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.178625  \n",
      "Run: 108\t| Iteration: 700 \t| Log-Likelihood:-3.187237731807449 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.177305  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 108\t| Iteration: 800 \t| Log-Likelihood:-3.187237760972214 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.145883  \n",
      "Run: 108\t| Iteration: 900 \t| Log-Likelihood:-3.187237756235455 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.171142  \n",
      "Run: 109\t| Iteration: 0 \t| Log-Likelihood:-3.7618787915220886 \t|  theta: tensor([[0.2903, 1.6912]], requires_grad=True)  |  Time needed: 0:00:00.091152  \n",
      "Run: 109\t| Iteration: 100 \t| Log-Likelihood:-3.192517030091609 \t|  theta: tensor([[0.4028, 1.0700]], requires_grad=True)  |  Time needed: 0:00:09.164641  \n",
      "Run: 109\t| Iteration: 200 \t| Log-Likelihood:-3.1904644559297686 \t|  theta: tensor([[0.4320, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.241556  \n",
      "Run: 109\t| Iteration: 300 \t| Log-Likelihood:-3.1904626746803495 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.202217  \n",
      "Run: 109\t| Iteration: 400 \t| Log-Likelihood:-3.190462702929426 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.214971  \n",
      "Run: 109\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.248634  \n",
      "Run: 109\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.165000  \n",
      "Run: 109\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.193747  \n",
      "Run: 109\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.165570  \n",
      "Run: 109\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.296213  \n",
      "Run: 110\t| Iteration: 0 \t| Log-Likelihood:-3.193655187081825 \t|  theta: tensor([[0.0382, 2.9388]], requires_grad=True)  |  Time needed: 0:00:00.091473  \n",
      "Run: 110\t| Iteration: 100 \t| Log-Likelihood:-3.187425697287915 \t|  theta: tensor([[0.0501, 2.9817]], requires_grad=True)  |  Time needed: 0:00:09.141801  \n",
      "Run: 110\t| Iteration: 200 \t| Log-Likelihood:-3.1872530347672634 \t|  theta: tensor([[0.0501, 2.9940]], requires_grad=True)  |  Time needed: 0:00:09.149127  \n",
      "Run: 110\t| Iteration: 300 \t| Log-Likelihood:-3.187238969094954 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.161746  \n",
      "Run: 110\t| Iteration: 400 \t| Log-Likelihood:-3.187237831329155 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.178809  \n",
      "Run: 110\t| Iteration: 500 \t| Log-Likelihood:-3.1872377271504546 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.151906  \n",
      "Run: 110\t| Iteration: 600 \t| Log-Likelihood:-3.187237734493052 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.152253  \n",
      "Run: 110\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.559153  \n",
      "Run: 110\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.274741  \n",
      "Run: 110\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.147631  \n",
      "Run: 111\t| Iteration: 0 \t| Log-Likelihood:-3.1906161830148605 \t|  theta: tensor([[0.0551, 3.0675]], requires_grad=True)  |  Time needed: 0:00:00.096451  \n",
      "Run: 111\t| Iteration: 100 \t| Log-Likelihood:-3.1874825724590727 \t|  theta: tensor([[0.0501, 3.0184]], requires_grad=True)  |  Time needed: 0:00:09.355685  \n",
      "Run: 111\t| Iteration: 200 \t| Log-Likelihood:-3.1872576480420793 \t|  theta: tensor([[0.0501, 3.0045]], requires_grad=True)  |  Time needed: 0:00:09.328588  \n",
      "Run: 111\t| Iteration: 300 \t| Log-Likelihood:-3.187239361562932 \t|  theta: tensor([[0.0501, 3.0005]], requires_grad=True)  |  Time needed: 0:00:09.449599  \n",
      "Run: 111\t| Iteration: 400 \t| Log-Likelihood:-3.1872378433610646 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.317541  \n",
      "Run: 111\t| Iteration: 500 \t| Log-Likelihood:-3.1872377259541445 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.311337  \n",
      "Run: 111\t| Iteration: 600 \t| Log-Likelihood:-3.187237760793628 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.394426  \n",
      "Run: 111\t| Iteration: 700 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.458348  \n",
      "Run: 111\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.353257  \n",
      "Run: 111\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.337049  \n",
      "Run: 112\t| Iteration: 0 \t| Log-Likelihood:-3.7865965743369694 \t|  theta: tensor([[0.3021, 2.0985]], requires_grad=True)  |  Time needed: 0:00:00.092803  \n",
      "Run: 112\t| Iteration: 100 \t| Log-Likelihood:-3.251298754398843 \t|  theta: tensor([[0.0505, 2.6804]], requires_grad=True)  |  Time needed: 0:00:09.176045  \n",
      "Run: 112\t| Iteration: 200 \t| Log-Likelihood:-3.1926216785036376 \t|  theta: tensor([[0.0501, 2.9070]], requires_grad=True)  |  Time needed: 0:00:09.102642  \n",
      "Run: 112\t| Iteration: 300 \t| Log-Likelihood:-3.1876773377593426 \t|  theta: tensor([[0.0501, 2.9726]], requires_grad=True)  |  Time needed: 0:00:09.125272  \n",
      "Run: 112\t| Iteration: 400 \t| Log-Likelihood:-3.1872735153079255 \t|  theta: tensor([[0.0501, 2.9914]], requires_grad=True)  |  Time needed: 0:00:09.095416  \n",
      "Run: 112\t| Iteration: 500 \t| Log-Likelihood:-3.1872406231948966 \t|  theta: tensor([[0.0501, 2.9967]], requires_grad=True)  |  Time needed: 0:00:09.098752  \n",
      "Run: 112\t| Iteration: 600 \t| Log-Likelihood:-3.1872379889060882 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.142655  \n",
      "Run: 112\t| Iteration: 700 \t| Log-Likelihood:-3.187237786549128 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.189264  \n",
      "Run: 112\t| Iteration: 800 \t| Log-Likelihood:-3.18723773164813 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.090994  \n",
      "Run: 112\t| Iteration: 900 \t| Log-Likelihood:-3.1872377339420526 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.110764  \n",
      "Run: 113\t| Iteration: 0 \t| Log-Likelihood:-3.5592234160197425 \t|  theta: tensor([[0.0430, 2.2337]], requires_grad=True)  |  Time needed: 0:00:00.094433  \n",
      "Run: 113\t| Iteration: 100 \t| Log-Likelihood:-3.223513071108675 \t|  theta: tensor([[0.0503, 2.7598]], requires_grad=True)  |  Time needed: 0:00:09.110690  \n",
      "Run: 113\t| Iteration: 200 \t| Log-Likelihood:-3.1902460570238746 \t|  theta: tensor([[0.0501, 2.9302]], requires_grad=True)  |  Time needed: 0:00:09.138080  \n",
      "Run: 113\t| Iteration: 300 \t| Log-Likelihood:-3.187483040320523 \t|  theta: tensor([[0.0501, 2.9793]], requires_grad=True)  |  Time needed: 0:00:09.476392  \n",
      "Run: 113\t| Iteration: 400 \t| Log-Likelihood:-3.187257702064657 \t|  theta: tensor([[0.0501, 2.9933]], requires_grad=True)  |  Time needed: 0:00:09.165706  \n",
      "Run: 113\t| Iteration: 500 \t| Log-Likelihood:-3.1872393737616296 \t|  theta: tensor([[0.0501, 2.9973]], requires_grad=True)  |  Time needed: 0:00:09.106671  \n",
      "Run: 113\t| Iteration: 600 \t| Log-Likelihood:-3.1872378513540944 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.209953  \n",
      "Run: 113\t| Iteration: 700 \t| Log-Likelihood:-3.1872377259529077 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.781052  \n",
      "Run: 113\t| Iteration: 800 \t| Log-Likelihood:-3.187237730990951 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.807987  \n",
      "Run: 113\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.837637  \n",
      "Run: 114\t| Iteration: 0 \t| Log-Likelihood:-3.264107615865565 \t|  theta: tensor([[0.1716, 2.9604]], requires_grad=True)  |  Time needed: 0:00:00.092220  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 114\t| Iteration: 100 \t| Log-Likelihood:-3.187314894972917 \t|  theta: tensor([[0.0501, 2.9879]], requires_grad=True)  |  Time needed: 0:00:09.100731  \n",
      "Run: 114\t| Iteration: 200 \t| Log-Likelihood:-3.1872440481591022 \t|  theta: tensor([[0.0501, 2.9957]], requires_grad=True)  |  Time needed: 0:00:09.147957  \n",
      "Run: 114\t| Iteration: 300 \t| Log-Likelihood:-3.1872382753495594 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.550939  \n",
      "Run: 114\t| Iteration: 400 \t| Log-Likelihood:-3.1872377940232948 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.270976  \n",
      "Run: 114\t| Iteration: 500 \t| Log-Likelihood:-3.187237729768656 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.143643  \n",
      "Run: 114\t| Iteration: 600 \t| Log-Likelihood:-3.1872377341133595 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.150078  \n",
      "Run: 114\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.161323  \n",
      "Run: 114\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.082950  \n",
      "Run: 114\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.213909  \n",
      "Run: 115\t| Iteration: 0 \t| Log-Likelihood:-3.546751882883555 \t|  theta: tensor([[0.3393, 2.6087]], requires_grad=True)  |  Time needed: 0:00:00.091753  \n",
      "Run: 115\t| Iteration: 100 \t| Log-Likelihood:-3.1955064236873283 \t|  theta: tensor([[0.0501, 2.8850]], requires_grad=True)  |  Time needed: 0:00:09.163683  \n",
      "Run: 115\t| Iteration: 200 \t| Log-Likelihood:-3.1879139235528657 \t|  theta: tensor([[0.0501, 2.9663]], requires_grad=True)  |  Time needed: 0:00:09.167643  \n",
      "Run: 115\t| Iteration: 300 \t| Log-Likelihood:-3.187292807990142 \t|  theta: tensor([[0.0501, 2.9896]], requires_grad=True)  |  Time needed: 0:00:09.164520  \n",
      "Run: 115\t| Iteration: 400 \t| Log-Likelihood:-3.1872422233420354 \t|  theta: tensor([[0.0501, 2.9962]], requires_grad=True)  |  Time needed: 0:00:09.107925  \n",
      "Run: 115\t| Iteration: 500 \t| Log-Likelihood:-3.187238091085829 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.088384  \n",
      "Run: 115\t| Iteration: 600 \t| Log-Likelihood:-3.187237789575403 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.122411  \n",
      "Run: 115\t| Iteration: 700 \t| Log-Likelihood:-3.18723772879423 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.141307  \n",
      "Run: 115\t| Iteration: 800 \t| Log-Likelihood:-3.18723773403323 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.109094  \n",
      "Run: 115\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.124320  \n",
      "Run: 116\t| Iteration: 0 \t| Log-Likelihood:-3.6915145896480985 \t|  theta: tensor([[0.1610, 1.6269]], requires_grad=True)  |  Time needed: 0:00:00.097812  \n",
      "Run: 116\t| Iteration: 100 \t| Log-Likelihood:-3.191938074497336 \t|  theta: tensor([[0.4070, 1.0673]], requires_grad=True)  |  Time needed: 0:00:09.287343  \n",
      "Run: 116\t| Iteration: 200 \t| Log-Likelihood:-3.1904639950129474 \t|  theta: tensor([[0.4321, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.312172  \n",
      "Run: 116\t| Iteration: 300 \t| Log-Likelihood:-3.1904627040647213 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.287085  \n",
      "Run: 116\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731260706 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.285294  \n",
      "Run: 116\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.314314  \n",
      "Run: 116\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.284182  \n",
      "Run: 116\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.285171  \n",
      "Run: 116\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.284092  \n",
      "Run: 116\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.313400  \n",
      "Run: 117\t| Iteration: 0 \t| Log-Likelihood:-4.376843364452982 \t|  theta: tensor([[0.5388, 3.9504]], requires_grad=True)  |  Time needed: 0:00:00.089779  \n",
      "Run: 117\t| Iteration: 100 \t| Log-Likelihood:-3.2340125793733625 \t|  theta: tensor([[0.0501, 3.2692]], requires_grad=True)  |  Time needed: 0:00:09.097999  \n",
      "Run: 117\t| Iteration: 200 \t| Log-Likelihood:-3.191023600858753 \t|  theta: tensor([[0.0501, 3.0758]], requires_grad=True)  |  Time needed: 0:00:09.136930  \n",
      "Run: 117\t| Iteration: 300 \t| Log-Likelihood:-3.1875453325073133 \t|  theta: tensor([[0.0501, 3.0208]], requires_grad=True)  |  Time needed: 0:00:09.152794  \n",
      "Run: 117\t| Iteration: 400 \t| Log-Likelihood:-3.1872627521542216 \t|  theta: tensor([[0.0501, 3.0051]], requires_grad=True)  |  Time needed: 0:00:09.097424  \n",
      "Run: 117\t| Iteration: 500 \t| Log-Likelihood:-3.1872397549092066 \t|  theta: tensor([[0.0501, 3.0007]], requires_grad=True)  |  Time needed: 0:00:09.141918  \n",
      "Run: 117\t| Iteration: 600 \t| Log-Likelihood:-3.1872378886246486 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.086323  \n",
      "Run: 117\t| Iteration: 700 \t| Log-Likelihood:-3.1872377323693906 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.307770  \n",
      "Run: 117\t| Iteration: 800 \t| Log-Likelihood:-3.187237761009845 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.231586  \n",
      "Run: 117\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562388574 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.460773  \n",
      "Run: 118\t| Iteration: 0 \t| Log-Likelihood:-3.368177331870975 \t|  theta: tensor([[0.1987, 3.3506]], requires_grad=True)  |  Time needed: 0:00:00.092007  \n",
      "Run: 118\t| Iteration: 100 \t| Log-Likelihood:-3.1936435597045887 \t|  theta: tensor([[0.0501, 3.0990]], requires_grad=True)  |  Time needed: 0:00:09.124604  \n",
      "Run: 118\t| Iteration: 200 \t| Log-Likelihood:-3.1877580227713715 \t|  theta: tensor([[0.0501, 3.0274]], requires_grad=True)  |  Time needed: 0:00:09.155027  \n",
      "Run: 118\t| Iteration: 300 \t| Log-Likelihood:-3.1872800714398526 \t|  theta: tensor([[0.0501, 3.0070]], requires_grad=True)  |  Time needed: 0:00:09.108041  \n",
      "Run: 118\t| Iteration: 400 \t| Log-Likelihood:-3.1872411894593666 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.153746  \n",
      "Run: 118\t| Iteration: 500 \t| Log-Likelihood:-3.187238029169022 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.289013  \n",
      "Run: 118\t| Iteration: 600 \t| Log-Likelihood:-3.187237749114665 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.164924  \n",
      "Run: 118\t| Iteration: 700 \t| Log-Likelihood:-3.187237765488728 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.114639  \n",
      "Run: 118\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563266774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.177766  \n",
      "Run: 118\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.118917  \n",
      "Run: 119\t| Iteration: 0 \t| Log-Likelihood:-3.671427644376539 \t|  theta: tensor([[0.1137, 2.0234]], requires_grad=True)  |  Time needed: 0:00:00.095762  \n",
      "Run: 119\t| Iteration: 100 \t| Log-Likelihood:-3.266487495666408 \t|  theta: tensor([[0.0507, 2.6441]], requires_grad=True)  |  Time needed: 0:00:09.139952  \n",
      "Run: 119\t| Iteration: 200 \t| Log-Likelihood:-3.1939499346640736 \t|  theta: tensor([[0.0501, 2.8963]], requires_grad=True)  |  Time needed: 0:00:09.138254  \n",
      "Run: 119\t| Iteration: 300 \t| Log-Likelihood:-3.187786163043704 \t|  theta: tensor([[0.0501, 2.9696]], requires_grad=True)  |  Time needed: 0:00:09.185125  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 119\t| Iteration: 400 \t| Log-Likelihood:-3.187282397482981 \t|  theta: tensor([[0.0501, 2.9905]], requires_grad=True)  |  Time needed: 0:00:09.095865  \n",
      "Run: 119\t| Iteration: 500 \t| Log-Likelihood:-3.187241360974906 \t|  theta: tensor([[0.0501, 2.9965]], requires_grad=True)  |  Time needed: 0:00:09.150391  \n",
      "Run: 119\t| Iteration: 600 \t| Log-Likelihood:-3.1872380337506208 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.111417  \n",
      "Run: 119\t| Iteration: 700 \t| Log-Likelihood:-3.1872377876907443 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.148476  \n",
      "Run: 119\t| Iteration: 800 \t| Log-Likelihood:-3.187237732076667 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.120055  \n",
      "Run: 119\t| Iteration: 900 \t| Log-Likelihood:-3.1872377339847713 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.143200  \n",
      "Run: 120\t| Iteration: 0 \t| Log-Likelihood:-3.649760070698405 \t|  theta: tensor([[0.1480, 1.5438]], requires_grad=True)  |  Time needed: 0:00:00.093491  \n",
      "Run: 120\t| Iteration: 100 \t| Log-Likelihood:-3.191133292912902 \t|  theta: tensor([[0.4150, 1.0632]], requires_grad=True)  |  Time needed: 0:00:09.265612  \n",
      "Run: 120\t| Iteration: 200 \t| Log-Likelihood:-3.1904632908639545 \t|  theta: tensor([[0.4324, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.116931  \n",
      "Run: 120\t| Iteration: 300 \t| Log-Likelihood:-3.190462733258389 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.100632  \n",
      "Run: 120\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102713  \n",
      "Run: 120\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125432  \n",
      "Run: 120\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099900  \n",
      "Run: 120\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113931  \n",
      "Run: 120\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.122412  \n",
      "Run: 120\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.106892  \n",
      "Run: 121\t| Iteration: 0 \t| Log-Likelihood:-3.5248446705479446 \t|  theta: tensor([[0.1580, 2.3056]], requires_grad=True)  |  Time needed: 0:00:00.090327  \n",
      "Run: 121\t| Iteration: 100 \t| Log-Likelihood:-3.2161270247808527 \t|  theta: tensor([[0.0503, 2.7857]], requires_grad=True)  |  Time needed: 0:00:09.354850  \n",
      "Run: 121\t| Iteration: 200 \t| Log-Likelihood:-3.1896249144213673 \t|  theta: tensor([[0.0501, 2.9377]], requires_grad=True)  |  Time needed: 0:00:09.473502  \n",
      "Run: 121\t| Iteration: 300 \t| Log-Likelihood:-3.1874323357318746 \t|  theta: tensor([[0.0501, 2.9814]], requires_grad=True)  |  Time needed: 0:00:09.285547  \n",
      "Run: 121\t| Iteration: 400 \t| Log-Likelihood:-3.187253563426114 \t|  theta: tensor([[0.0501, 2.9939]], requires_grad=True)  |  Time needed: 0:00:09.474558  \n",
      "Run: 121\t| Iteration: 500 \t| Log-Likelihood:-3.187239010679688 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.586575  \n",
      "Run: 121\t| Iteration: 600 \t| Log-Likelihood:-3.1872378309857305 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.296798  \n",
      "Run: 121\t| Iteration: 700 \t| Log-Likelihood:-3.1872377274958903 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.293272  \n",
      "Run: 121\t| Iteration: 800 \t| Log-Likelihood:-3.1872377345230225 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.291296  \n",
      "Run: 121\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.284803  \n",
      "Run: 122\t| Iteration: 0 \t| Log-Likelihood:-6.414403860696062 \t|  theta: tensor([[0.1488, 0.3949]], requires_grad=True)  |  Time needed: 0:00:00.091539  \n",
      "Run: 122\t| Iteration: 100 \t| Log-Likelihood:-3.190476968464733 \t|  theta: tensor([[0.4302, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.256530  \n",
      "Run: 122\t| Iteration: 200 \t| Log-Likelihood:-3.1904626858683516 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137688  \n",
      "Run: 122\t| Iteration: 300 \t| Log-Likelihood:-3.190462673137243 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137184  \n",
      "Run: 122\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.160535  \n",
      "Run: 122\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156766  \n",
      "Run: 122\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.106678  \n",
      "Run: 122\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136321  \n",
      "Run: 122\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104486  \n",
      "Run: 122\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123508  \n",
      "Run: 123\t| Iteration: 0 \t| Log-Likelihood:-5.25987161549384 \t|  theta: tensor([[0.5260, 4.5233]], requires_grad=True)  |  Time needed: 0:00:00.092552  \n",
      "Run: 123\t| Iteration: 100 \t| Log-Likelihood:-3.3072404276661733 \t|  theta: tensor([[0.0501, 3.4316]], requires_grad=True)  |  Time needed: 0:00:09.118415  \n",
      "Run: 123\t| Iteration: 200 \t| Log-Likelihood:-3.196930043767322 \t|  theta: tensor([[0.0501, 3.1220]], requires_grad=True)  |  Time needed: 0:00:09.131983  \n",
      "Run: 123\t| Iteration: 300 \t| Log-Likelihood:-3.1880246442583164 \t|  theta: tensor([[0.0501, 3.0340]], requires_grad=True)  |  Time needed: 0:00:09.156804  \n",
      "Run: 123\t| Iteration: 400 \t| Log-Likelihood:-3.1873017173736806 \t|  theta: tensor([[0.0501, 3.0089]], requires_grad=True)  |  Time needed: 0:00:09.139469  \n",
      "Run: 123\t| Iteration: 500 \t| Log-Likelihood:-3.187242929417535 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.109358  \n",
      "Run: 123\t| Iteration: 600 \t| Log-Likelihood:-3.1872381387299087 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.154247  \n",
      "Run: 123\t| Iteration: 700 \t| Log-Likelihood:-3.1872377682851636 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.174154  \n",
      "Run: 123\t| Iteration: 800 \t| Log-Likelihood:-3.1872377663940323 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.157409  \n",
      "Run: 123\t| Iteration: 900 \t| Log-Likelihood:-3.187237756420657 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.081259  \n",
      "Run: 124\t| Iteration: 0 \t| Log-Likelihood:-3.2422666015525956 \t|  theta: tensor([[0.0462, 3.2912]], requires_grad=True)  |  Time needed: 0:00:00.092299  \n",
      "Run: 124\t| Iteration: 100 \t| Log-Likelihood:-3.1916663256063065 \t|  theta: tensor([[0.0501, 3.0821]], requires_grad=True)  |  Time needed: 0:00:09.102338  \n",
      "Run: 124\t| Iteration: 200 \t| Log-Likelihood:-3.187597593892379 \t|  theta: tensor([[0.0501, 3.0226]], requires_grad=True)  |  Time needed: 0:00:09.193226  \n",
      "Run: 124\t| Iteration: 300 \t| Log-Likelihood:-3.1872670367406117 \t|  theta: tensor([[0.0501, 3.0056]], requires_grad=True)  |  Time needed: 0:00:09.096771  \n",
      "Run: 124\t| Iteration: 400 \t| Log-Likelihood:-3.1872401216032378 \t|  theta: tensor([[0.0501, 3.0008]], requires_grad=True)  |  Time needed: 0:00:09.130740  \n",
      "Run: 124\t| Iteration: 500 \t| Log-Likelihood:-3.187237923504832 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.107149  \n",
      "Run: 124\t| Iteration: 600 \t| Log-Likelihood:-3.18723773832041 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.111637  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 124\t| Iteration: 700 \t| Log-Likelihood:-3.187237761166744 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.123349  \n",
      "Run: 124\t| Iteration: 800 \t| Log-Likelihood:-3.1872377562607603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.075862  \n",
      "Run: 124\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.223213  \n",
      "Run: 125\t| Iteration: 0 \t| Log-Likelihood:-3.66325630455062 \t|  theta: tensor([[0.4417, 3.2884]], requires_grad=True)  |  Time needed: 0:00:00.098611  \n",
      "Run: 125\t| Iteration: 100 \t| Log-Likelihood:-3.191579344444419 \t|  theta: tensor([[0.0501, 3.0813]], requires_grad=True)  |  Time needed: 0:00:09.440579  \n",
      "Run: 125\t| Iteration: 200 \t| Log-Likelihood:-3.18759049240671 \t|  theta: tensor([[0.0501, 3.0224]], requires_grad=True)  |  Time needed: 0:00:09.229235  \n",
      "Run: 125\t| Iteration: 300 \t| Log-Likelihood:-3.1872664499789383 \t|  theta: tensor([[0.0501, 3.0056]], requires_grad=True)  |  Time needed: 0:00:09.173422  \n",
      "Run: 125\t| Iteration: 400 \t| Log-Likelihood:-3.1872400727893084 \t|  theta: tensor([[0.0501, 3.0008]], requires_grad=True)  |  Time needed: 0:00:09.198832  \n",
      "Run: 125\t| Iteration: 500 \t| Log-Likelihood:-3.1872379198794727 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.091235  \n",
      "Run: 125\t| Iteration: 600 \t| Log-Likelihood:-3.1872377381323407 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.094357  \n",
      "Run: 125\t| Iteration: 700 \t| Log-Likelihood:-3.187237761153279 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.269202  \n",
      "Run: 125\t| Iteration: 800 \t| Log-Likelihood:-3.1872377562607603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.092430  \n",
      "Run: 125\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.074336  \n",
      "Run: 126\t| Iteration: 0 \t| Log-Likelihood:-3.8880149053213047 \t|  theta: tensor([[0.4615, 0.7003]], requires_grad=True)  |  Time needed: 0:00:00.089914  \n",
      "Run: 126\t| Iteration: 100 \t| Log-Likelihood:-3.190477730310252 \t|  theta: tensor([[0.4357, 1.0562]], requires_grad=True)  |  Time needed: 0:00:09.294320  \n",
      "Run: 126\t| Iteration: 200 \t| Log-Likelihood:-3.1904626866343566 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309382  \n",
      "Run: 126\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731372114 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.296301  \n",
      "Run: 126\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.292278  \n",
      "Run: 126\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.325320  \n",
      "Run: 126\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.277646  \n",
      "Run: 126\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.306810  \n",
      "Run: 126\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.270521  \n",
      "Run: 126\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.280182  \n",
      "Run: 127\t| Iteration: 0 \t| Log-Likelihood:-3.270106120639361 \t|  theta: tensor([[0.1764, 2.9351]], requires_grad=True)  |  Time needed: 0:00:00.086998  \n",
      "Run: 127\t| Iteration: 100 \t| Log-Likelihood:-3.187449801185916 \t|  theta: tensor([[0.0501, 2.9807]], requires_grad=True)  |  Time needed: 0:00:09.455444  \n",
      "Run: 127\t| Iteration: 200 \t| Log-Likelihood:-3.1872550059289635 \t|  theta: tensor([[0.0501, 2.9937]], requires_grad=True)  |  Time needed: 0:00:09.115017  \n",
      "Run: 127\t| Iteration: 300 \t| Log-Likelihood:-3.1872391715382933 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.227046  \n",
      "Run: 127\t| Iteration: 400 \t| Log-Likelihood:-3.187237836847023 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.197055  \n",
      "Run: 127\t| Iteration: 500 \t| Log-Likelihood:-3.18723772817174 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.145425  \n",
      "Run: 127\t| Iteration: 600 \t| Log-Likelihood:-3.187237730859588 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.139557  \n",
      "Run: 127\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.148839  \n",
      "Run: 127\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.123738  \n",
      "Run: 127\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.096997  \n",
      "Run: 128\t| Iteration: 0 \t| Log-Likelihood:-6.595271714362122 \t|  theta: tensor([[0.2244, 0.3477]], requires_grad=True)  |  Time needed: 0:00:00.097137  \n",
      "Run: 128\t| Iteration: 100 \t| Log-Likelihood:-3.190466950224363 \t|  theta: tensor([[0.4315, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.126334  \n",
      "Run: 128\t| Iteration: 200 \t| Log-Likelihood:-3.1904627364467353 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.147848  \n",
      "Run: 128\t| Iteration: 300 \t| Log-Likelihood:-3.190462702930722 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156117  \n",
      "Run: 128\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.126374  \n",
      "Run: 128\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142756  \n",
      "Run: 128\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.469655  \n",
      "Run: 128\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.268631  \n",
      "Run: 128\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.165856  \n",
      "Run: 128\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.181770  \n",
      "Run: 129\t| Iteration: 0 \t| Log-Likelihood:-6.411056538271267 \t|  theta: tensor([[0.2118, 0.3710]], requires_grad=True)  |  Time needed: 0:00:00.091426  \n",
      "Run: 129\t| Iteration: 100 \t| Log-Likelihood:-3.1904687900162925 \t|  theta: tensor([[0.4312, 1.0573]], requires_grad=True)  |  Time needed: 0:00:09.209837  \n",
      "Run: 129\t| Iteration: 200 \t| Log-Likelihood:-3.1904627083149713 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105426  \n",
      "Run: 129\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731300794 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.344688  \n",
      "Run: 129\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144276  \n",
      "Run: 129\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.121914  \n",
      "Run: 129\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136172  \n",
      "Run: 129\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142181  \n",
      "Run: 129\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123290  \n",
      "Run: 129\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.160160  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 130\t| Iteration: 0 \t| Log-Likelihood:-5.203336873639233 \t|  theta: tensor([[0.5516, 4.4648]], requires_grad=True)  |  Time needed: 0:00:00.091817  \n",
      "Run: 130\t| Iteration: 100 \t| Log-Likelihood:-3.2982180197288917 \t|  theta: tensor([[0.0501, 3.4151]], requires_grad=True)  |  Time needed: 0:00:09.169035  \n",
      "Run: 130\t| Iteration: 200 \t| Log-Likelihood:-3.196202791512236 \t|  theta: tensor([[0.0501, 3.1173]], requires_grad=True)  |  Time needed: 0:00:09.157066  \n",
      "Run: 130\t| Iteration: 300 \t| Log-Likelihood:-3.1879656055093717 \t|  theta: tensor([[0.0501, 3.0326]], requires_grad=True)  |  Time needed: 0:00:09.098120  \n",
      "Run: 130\t| Iteration: 400 \t| Log-Likelihood:-3.1872969119334704 \t|  theta: tensor([[0.0501, 3.0085]], requires_grad=True)  |  Time needed: 0:00:09.153912  \n",
      "Run: 130\t| Iteration: 500 \t| Log-Likelihood:-3.1872425777795854 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.101121  \n",
      "Run: 130\t| Iteration: 600 \t| Log-Likelihood:-3.187238158218671 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.106472  \n",
      "Run: 130\t| Iteration: 700 \t| Log-Likelihood:-3.1872377656127364 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.069268  \n",
      "Run: 130\t| Iteration: 800 \t| Log-Likelihood:-3.187237766198799 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.079036  \n",
      "Run: 130\t| Iteration: 900 \t| Log-Likelihood:-3.187237756396702 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.222275  \n",
      "Run: 131\t| Iteration: 0 \t| Log-Likelihood:-3.9257948088934316 \t|  theta: tensor([[0.4681, 2.2853]], requires_grad=True)  |  Time needed: 0:00:00.089590  \n",
      "Run: 131\t| Iteration: 100 \t| Log-Likelihood:-3.2201107083309313 \t|  theta: tensor([[0.0503, 2.7713]], requires_grad=True)  |  Time needed: 0:00:09.268208  \n",
      "Run: 131\t| Iteration: 200 \t| Log-Likelihood:-3.189959405127484 \t|  theta: tensor([[0.0501, 2.9336]], requires_grad=True)  |  Time needed: 0:00:09.279667  \n",
      "Run: 131\t| Iteration: 300 \t| Log-Likelihood:-3.1874596537489435 \t|  theta: tensor([[0.0501, 2.9802]], requires_grad=True)  |  Time needed: 0:00:09.276273  \n",
      "Run: 131\t| Iteration: 400 \t| Log-Likelihood:-3.187255785630011 \t|  theta: tensor([[0.0501, 2.9936]], requires_grad=True)  |  Time needed: 0:00:09.422235  \n",
      "Run: 131\t| Iteration: 500 \t| Log-Likelihood:-3.1872392346114964 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.308210  \n",
      "Run: 131\t| Iteration: 600 \t| Log-Likelihood:-3.1872378423833885 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.328631  \n",
      "Run: 131\t| Iteration: 700 \t| Log-Likelihood:-3.187237724886483 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.362718  \n",
      "Run: 131\t| Iteration: 800 \t| Log-Likelihood:-3.1872377309022415 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.300079  \n",
      "Run: 131\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.318372  \n",
      "Run: 132\t| Iteration: 0 \t| Log-Likelihood:-3.9426704204910727 \t|  theta: tensor([[0.4602, 2.2298]], requires_grad=True)  |  Time needed: 0:00:00.089727  \n",
      "Run: 132\t| Iteration: 100 \t| Log-Likelihood:-3.227667909905066 \t|  theta: tensor([[0.0503, 2.7464]], requires_grad=True)  |  Time needed: 0:00:09.075852  \n",
      "Run: 132\t| Iteration: 200 \t| Log-Likelihood:-3.1905972909066302 \t|  theta: tensor([[0.0501, 2.9263]], requires_grad=True)  |  Time needed: 0:00:09.544384  \n",
      "Run: 132\t| Iteration: 300 \t| Log-Likelihood:-3.187511730837719 \t|  theta: tensor([[0.0501, 2.9782]], requires_grad=True)  |  Time needed: 0:00:09.140078  \n",
      "Run: 132\t| Iteration: 400 \t| Log-Likelihood:-3.187260032069055 \t|  theta: tensor([[0.0501, 2.9930]], requires_grad=True)  |  Time needed: 0:00:09.102062  \n",
      "Run: 132\t| Iteration: 500 \t| Log-Likelihood:-3.1872395456543647 \t|  theta: tensor([[0.0501, 2.9972]], requires_grad=True)  |  Time needed: 0:00:09.238404  \n",
      "Run: 132\t| Iteration: 600 \t| Log-Likelihood:-3.187237862838917 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.094448  \n",
      "Run: 132\t| Iteration: 700 \t| Log-Likelihood:-3.1872377271983945 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.146570  \n",
      "Run: 132\t| Iteration: 800 \t| Log-Likelihood:-3.1872377310961695 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.094705  \n",
      "Run: 132\t| Iteration: 900 \t| Log-Likelihood:-3.187237737599123 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.123932  \n",
      "Run: 133\t| Iteration: 0 \t| Log-Likelihood:-3.7327706674976544 \t|  theta: tensor([[0.1172, 1.0297]], requires_grad=True)  |  Time needed: 0:00:00.091139  \n",
      "Run: 133\t| Iteration: 100 \t| Log-Likelihood:-3.1905369140962443 \t|  theta: tensor([[0.4268, 1.0586]], requires_grad=True)  |  Time needed: 0:00:09.080774  \n",
      "Run: 133\t| Iteration: 200 \t| Log-Likelihood:-3.190462739657786 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.134480  \n",
      "Run: 133\t| Iteration: 300 \t| Log-Likelihood:-3.190462732787995 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.094153  \n",
      "Run: 133\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105548  \n",
      "Run: 133\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.192970  \n",
      "Run: 133\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135075  \n",
      "Run: 133\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097162  \n",
      "Run: 133\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.147858  \n",
      "Run: 133\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.115241  \n",
      "Run: 134\t| Iteration: 0 \t| Log-Likelihood:-3.663749302934459 \t|  theta: tensor([[0.4686, 2.8935]], requires_grad=True)  |  Time needed: 0:00:00.092602  \n",
      "Run: 134\t| Iteration: 100 \t| Log-Likelihood:-3.187821603884695 \t|  theta: tensor([[0.0501, 2.9686]], requires_grad=True)  |  Time needed: 0:00:09.170034  \n",
      "Run: 134\t| Iteration: 200 \t| Log-Likelihood:-3.187285291164821 \t|  theta: tensor([[0.0501, 2.9903]], requires_grad=True)  |  Time needed: 0:00:09.247900  \n",
      "Run: 134\t| Iteration: 300 \t| Log-Likelihood:-3.187241583830536 \t|  theta: tensor([[0.0501, 2.9964]], requires_grad=True)  |  Time needed: 0:00:09.195946  \n",
      "Run: 134\t| Iteration: 400 \t| Log-Likelihood:-3.1872380520554837 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:10.031072  \n",
      "Run: 134\t| Iteration: 500 \t| Log-Likelihood:-3.1872377892337096 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.184204  \n",
      "Run: 134\t| Iteration: 600 \t| Log-Likelihood:-3.1872377284709117 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.111734  \n",
      "Run: 134\t| Iteration: 700 \t| Log-Likelihood:-3.1872377340002864 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.219138  \n",
      "Run: 134\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.155623  \n",
      "Run: 134\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.103382  \n",
      "Run: 135\t| Iteration: 0 \t| Log-Likelihood:-4.235297408557214 \t|  theta: tensor([[0.2394, 1.0014]], requires_grad=True)  |  Time needed: 0:00:00.093523  \n",
      "Run: 135\t| Iteration: 100 \t| Log-Likelihood:-3.1904982145986773 \t|  theta: tensor([[0.4287, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.140108  \n",
      "Run: 135\t| Iteration: 200 \t| Log-Likelihood:-3.190462705044613 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.078602  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 135\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029554304 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082286  \n",
      "Run: 135\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.134756  \n",
      "Run: 135\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.253643  \n",
      "Run: 135\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.131630  \n",
      "Run: 135\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.066075  \n",
      "Run: 135\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.533417  \n",
      "Run: 135\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.187738  \n",
      "Run: 136\t| Iteration: 0 \t| Log-Likelihood:-4.218941852763487 \t|  theta: tensor([[0.5076, 3.8710]], requires_grad=True)  |  Time needed: 0:00:00.093705  \n",
      "Run: 136\t| Iteration: 100 \t| Log-Likelihood:-3.2265440243401144 \t|  theta: tensor([[0.0501, 3.2467]], requires_grad=True)  |  Time needed: 0:00:09.649684  \n",
      "Run: 136\t| Iteration: 200 \t| Log-Likelihood:-3.1904203369575255 \t|  theta: tensor([[0.0501, 3.0694]], requires_grad=True)  |  Time needed: 0:00:09.267020  \n",
      "Run: 136\t| Iteration: 300 \t| Log-Likelihood:-3.1874964000111707 \t|  theta: tensor([[0.0501, 3.0190]], requires_grad=True)  |  Time needed: 0:00:09.272849  \n",
      "Run: 136\t| Iteration: 400 \t| Log-Likelihood:-3.187258792916174 \t|  theta: tensor([[0.0501, 3.0046]], requires_grad=True)  |  Time needed: 0:00:09.268870  \n",
      "Run: 136\t| Iteration: 500 \t| Log-Likelihood:-3.1872394645742506 \t|  theta: tensor([[0.0501, 3.0005]], requires_grad=True)  |  Time needed: 0:00:09.315266  \n",
      "Run: 136\t| Iteration: 600 \t| Log-Likelihood:-3.187237854854227 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.298601  \n",
      "Run: 136\t| Iteration: 700 \t| Log-Likelihood:-3.1872377265483305 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.301628  \n",
      "Run: 136\t| Iteration: 800 \t| Log-Likelihood:-3.1872377608396922 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.405319  \n",
      "Run: 136\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562165286 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.364394  \n",
      "Run: 137\t| Iteration: 0 \t| Log-Likelihood:-4.17053876806173 \t|  theta: tensor([[0.3077, 0.6610]], requires_grad=True)  |  Time needed: 0:00:00.091630  \n",
      "Run: 137\t| Iteration: 100 \t| Log-Likelihood:-3.1904647965310686 \t|  theta: tensor([[0.4319, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.115843  \n",
      "Run: 137\t| Iteration: 200 \t| Log-Likelihood:-3.1904626749419367 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.089225  \n",
      "Run: 137\t| Iteration: 300 \t| Log-Likelihood:-3.190462702929609 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.068235  \n",
      "Run: 137\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.224943  \n",
      "Run: 137\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.088315  \n",
      "Run: 137\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.084189  \n",
      "Run: 137\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099537  \n",
      "Run: 137\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.075045  \n",
      "Run: 137\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117135  \n",
      "Run: 138\t| Iteration: 0 \t| Log-Likelihood:-3.201235961358108 \t|  theta: tensor([[0.0828, 3.0759]], requires_grad=True)  |  Time needed: 0:00:00.096330  \n",
      "Run: 138\t| Iteration: 100 \t| Log-Likelihood:-3.1875456268585163 \t|  theta: tensor([[0.0501, 3.0208]], requires_grad=True)  |  Time needed: 0:00:09.130740  \n",
      "Run: 138\t| Iteration: 200 \t| Log-Likelihood:-3.1872627785239938 \t|  theta: tensor([[0.0501, 3.0051]], requires_grad=True)  |  Time needed: 0:00:09.149902  \n",
      "Run: 138\t| Iteration: 300 \t| Log-Likelihood:-3.1872397565210395 \t|  theta: tensor([[0.0501, 3.0007]], requires_grad=True)  |  Time needed: 0:00:09.084973  \n",
      "Run: 138\t| Iteration: 400 \t| Log-Likelihood:-3.1872378886246486 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.144211  \n",
      "Run: 138\t| Iteration: 500 \t| Log-Likelihood:-3.1872377323693906 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.111842  \n",
      "Run: 138\t| Iteration: 600 \t| Log-Likelihood:-3.187237761009845 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.118931  \n",
      "Run: 138\t| Iteration: 700 \t| Log-Likelihood:-3.1872377562388574 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.155669  \n",
      "Run: 138\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.180706  \n",
      "Run: 138\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.156809  \n",
      "Run: 139\t| Iteration: 0 \t| Log-Likelihood:-3.5551474493692545 \t|  theta: tensor([[0.5718, 0.7943]], requires_grad=True)  |  Time needed: 0:00:00.092975  \n",
      "Run: 139\t| Iteration: 100 \t| Log-Likelihood:-3.190520321035905 \t|  theta: tensor([[0.4383, 1.0556]], requires_grad=True)  |  Time needed: 0:00:09.127846  \n",
      "Run: 139\t| Iteration: 200 \t| Log-Likelihood:-3.19046275507062 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.111665  \n",
      "Run: 139\t| Iteration: 300 \t| Log-Likelihood:-3.190462702973115 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128377  \n",
      "Run: 139\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.703982  \n",
      "Run: 139\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.176131  \n",
      "Run: 139\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.130326  \n",
      "Run: 139\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.160047  \n",
      "Run: 139\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119564  \n",
      "Run: 139\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.112102  \n",
      "Run: 140\t| Iteration: 0 \t| Log-Likelihood:-3.734727332568279 \t|  theta: tensor([[0.1245, 1.7446]], requires_grad=True)  |  Time needed: 0:00:00.097209  \n",
      "Run: 140\t| Iteration: 100 \t| Log-Likelihood:-3.221939102349611 \t|  theta: tensor([[0.3420, 1.1348]], requires_grad=True)  |  Time needed: 0:00:09.096695  \n",
      "Run: 140\t| Iteration: 200 \t| Log-Likelihood:-3.1904816285663875 \t|  theta: tensor([[0.4299, 1.0578]], requires_grad=True)  |  Time needed: 0:00:09.105722  \n",
      "Run: 140\t| Iteration: 300 \t| Log-Likelihood:-3.190462719962931 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.085572  \n",
      "Run: 140\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731404915 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105853  \n",
      "Run: 140\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.092107  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 140\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156898  \n",
      "Run: 140\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.241863  \n",
      "Run: 140\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.213575  \n",
      "Run: 140\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.088418  \n",
      "Run: 141\t| Iteration: 0 \t| Log-Likelihood:-3.4066376735170234 \t|  theta: tensor([[0.1337, 2.4594]], requires_grad=True)  |  Time needed: 0:00:00.089749  \n",
      "Run: 141\t| Iteration: 100 \t| Log-Likelihood:-3.2034788795960547 \t|  theta: tensor([[0.0502, 2.8392]], requires_grad=True)  |  Time needed: 0:00:09.372189  \n",
      "Run: 141\t| Iteration: 200 \t| Log-Likelihood:-3.1885713933235227 \t|  theta: tensor([[0.0501, 2.9532]], requires_grad=True)  |  Time needed: 0:00:09.313128  \n",
      "Run: 141\t| Iteration: 300 \t| Log-Likelihood:-3.1873463772600674 \t|  theta: tensor([[0.0501, 2.9858]], requires_grad=True)  |  Time needed: 0:00:09.321530  \n",
      "Run: 141\t| Iteration: 400 \t| Log-Likelihood:-3.1872465644623684 \t|  theta: tensor([[0.0501, 2.9952]], requires_grad=True)  |  Time needed: 0:00:09.323760  \n",
      "Run: 141\t| Iteration: 500 \t| Log-Likelihood:-3.187238453015784 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.311045  \n",
      "Run: 141\t| Iteration: 600 \t| Log-Likelihood:-3.1872378034362168 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.298010  \n",
      "Run: 141\t| Iteration: 700 \t| Log-Likelihood:-3.1872377273865427 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.335284  \n",
      "Run: 141\t| Iteration: 800 \t| Log-Likelihood:-3.1872377342130447 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.325655  \n",
      "Run: 141\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.343749  \n",
      "Run: 142\t| Iteration: 0 \t| Log-Likelihood:-3.2136284258890075 \t|  theta: tensor([[0.4667, 0.9855]], requires_grad=True)  |  Time needed: 0:00:00.088790  \n",
      "Run: 142\t| Iteration: 100 \t| Log-Likelihood:-3.1904668036055788 \t|  theta: tensor([[0.4344, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.154890  \n",
      "Run: 142\t| Iteration: 200 \t| Log-Likelihood:-3.1904627066185967 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.091220  \n",
      "Run: 142\t| Iteration: 300 \t| Log-Likelihood:-3.190462702930985 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.126908  \n",
      "Run: 142\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.091480  \n",
      "Run: 142\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.083927  \n",
      "Run: 142\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125384  \n",
      "Run: 142\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082338  \n",
      "Run: 142\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102525  \n",
      "Run: 142\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.084828  \n",
      "Run: 143\t| Iteration: 0 \t| Log-Likelihood:-8.38849331132492 \t|  theta: tensor([[0.2709, 0.1142]], requires_grad=True)  |  Time needed: 0:00:00.090883  \n",
      "Run: 143\t| Iteration: 100 \t| Log-Likelihood:-3.1904628948756772 \t|  theta: tensor([[0.4331, 1.0568]], requires_grad=True)  |  Time needed: 0:00:09.136378  \n",
      "Run: 143\t| Iteration: 200 \t| Log-Likelihood:-3.1904627327958504 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125317  \n",
      "Run: 143\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.235385  \n",
      "Run: 143\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.145014  \n",
      "Run: 143\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108681  \n",
      "Run: 143\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.134276  \n",
      "Run: 143\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104215  \n",
      "Run: 143\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082881  \n",
      "Run: 143\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.227127  \n",
      "Run: 144\t| Iteration: 0 \t| Log-Likelihood:-3.762021011376717 \t|  theta: tensor([[0.3776, 1.6166]], requires_grad=True)  |  Time needed: 0:00:00.098939  \n",
      "Run: 144\t| Iteration: 100 \t| Log-Likelihood:-3.19096022971531 \t|  theta: tensor([[0.4176, 1.0625]], requires_grad=True)  |  Time needed: 0:00:09.371869  \n",
      "Run: 144\t| Iteration: 200 \t| Log-Likelihood:-3.1904631386818942 \t|  theta: tensor([[0.4325, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.104211  \n",
      "Run: 144\t| Iteration: 300 \t| Log-Likelihood:-3.190462703321823 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150155  \n",
      "Run: 144\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.076106  \n",
      "Run: 144\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.224440  \n",
      "Run: 144\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.146988  \n",
      "Run: 144\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.205389  \n",
      "Run: 144\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102169  \n",
      "Run: 144\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.140807  \n",
      "Run: 145\t| Iteration: 0 \t| Log-Likelihood:-4.024688700151431 \t|  theta: tensor([[0.4592, 1.9901]], requires_grad=True)  |  Time needed: 0:00:00.095755  \n",
      "Run: 145\t| Iteration: 100 \t| Log-Likelihood:-3.311622629528016 \t|  theta: tensor([[0.0514, 2.5521]], requires_grad=True)  |  Time needed: 0:00:09.099492  \n",
      "Run: 145\t| Iteration: 200 \t| Log-Likelihood:-3.198055818191404 \t|  theta: tensor([[0.0502, 2.8686]], requires_grad=True)  |  Time needed: 0:00:09.305456  \n",
      "Run: 145\t| Iteration: 300 \t| Log-Likelihood:-3.188123613336066 \t|  theta: tensor([[0.0501, 2.9616]], requires_grad=True)  |  Time needed: 0:00:09.226079  \n",
      "Run: 145\t| Iteration: 400 \t| Log-Likelihood:-3.1873098621749922 \t|  theta: tensor([[0.0501, 2.9883]], requires_grad=True)  |  Time needed: 0:00:09.097811  \n",
      "Run: 145\t| Iteration: 500 \t| Log-Likelihood:-3.1872435943621333 \t|  theta: tensor([[0.0501, 2.9958]], requires_grad=True)  |  Time needed: 0:00:09.084171  \n",
      "Run: 145\t| Iteration: 600 \t| Log-Likelihood:-3.187238244404091 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.116265  \n",
      "Run: 145\t| Iteration: 700 \t| Log-Likelihood:-3.1872377949563577 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.079068  \n",
      "Run: 145\t| Iteration: 800 \t| Log-Likelihood:-3.1872377295309295 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.130353  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 145\t| Iteration: 900 \t| Log-Likelihood:-3.1872377340938054 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.133482  \n",
      "Run: 146\t| Iteration: 0 \t| Log-Likelihood:-4.44542253566353 \t|  theta: tensor([[0.3763, 4.2090]], requires_grad=True)  |  Time needed: 0:00:00.088811  \n",
      "Run: 146\t| Iteration: 100 \t| Log-Likelihood:-3.2628761547137852 \t|  theta: tensor([[0.0501, 3.3425]], requires_grad=True)  |  Time needed: 0:00:09.278891  \n",
      "Run: 146\t| Iteration: 200 \t| Log-Likelihood:-3.193353076173606 \t|  theta: tensor([[0.0501, 3.0967]], requires_grad=True)  |  Time needed: 0:00:09.414153  \n",
      "Run: 146\t| Iteration: 300 \t| Log-Likelihood:-3.1877344189350163 \t|  theta: tensor([[0.0501, 3.0268]], requires_grad=True)  |  Time needed: 0:00:09.296944  \n",
      "Run: 146\t| Iteration: 400 \t| Log-Likelihood:-3.187278127969987 \t|  theta: tensor([[0.0501, 3.0068]], requires_grad=True)  |  Time needed: 0:00:09.276676  \n",
      "Run: 146\t| Iteration: 500 \t| Log-Likelihood:-3.1872410287290505 \t|  theta: tensor([[0.0501, 3.0011]], requires_grad=True)  |  Time needed: 0:00:09.277783  \n",
      "Run: 146\t| Iteration: 600 \t| Log-Likelihood:-3.1872380128292033 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.799472  \n",
      "Run: 146\t| Iteration: 700 \t| Log-Likelihood:-3.1872377481038123 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.320890  \n",
      "Run: 146\t| Iteration: 800 \t| Log-Likelihood:-3.187237765407941 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.279902  \n",
      "Run: 146\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563169674 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.298549  \n",
      "Run: 147\t| Iteration: 0 \t| Log-Likelihood:-3.1960738810248683 \t|  theta: tensor([[0.0793, 2.9754]], requires_grad=True)  |  Time needed: 0:00:00.092188  \n",
      "Run: 147\t| Iteration: 100 \t| Log-Likelihood:-3.18726647542139 \t|  theta: tensor([[0.0501, 2.9922]], requires_grad=True)  |  Time needed: 0:00:09.110083  \n",
      "Run: 147\t| Iteration: 200 \t| Log-Likelihood:-3.1872400850419162 \t|  theta: tensor([[0.0501, 2.9970]], requires_grad=True)  |  Time needed: 0:00:09.235162  \n",
      "Run: 147\t| Iteration: 300 \t| Log-Likelihood:-3.1872379534006723 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.131349  \n",
      "Run: 147\t| Iteration: 400 \t| Log-Likelihood:-3.187237726954977 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.093581  \n",
      "Run: 147\t| Iteration: 500 \t| Log-Likelihood:-3.1872377313505376 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.138788  \n",
      "Run: 147\t| Iteration: 600 \t| Log-Likelihood:-3.1872377339088978 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.164536  \n",
      "Run: 147\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.091281  \n",
      "Run: 147\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.446832  \n",
      "Run: 147\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.098081  \n",
      "Run: 148\t| Iteration: 0 \t| Log-Likelihood:-4.404527535426769 \t|  theta: tensor([[0.2219, 4.3035]], requires_grad=True)  |  Time needed: 0:00:00.093962  \n",
      "Run: 148\t| Iteration: 100 \t| Log-Likelihood:-3.2751437658941502 \t|  theta: tensor([[0.0501, 3.3693]], requires_grad=True)  |  Time needed: 0:00:09.115560  \n",
      "Run: 148\t| Iteration: 200 \t| Log-Likelihood:-3.1943425160528673 \t|  theta: tensor([[0.0501, 3.1043]], requires_grad=True)  |  Time needed: 0:00:09.154372  \n",
      "Run: 148\t| Iteration: 300 \t| Log-Likelihood:-3.1878147319069536 \t|  theta: tensor([[0.0501, 3.0289]], requires_grad=True)  |  Time needed: 0:00:09.109213  \n",
      "Run: 148\t| Iteration: 400 \t| Log-Likelihood:-3.1872846393673773 \t|  theta: tensor([[0.0501, 3.0074]], requires_grad=True)  |  Time needed: 0:00:09.130668  \n",
      "Run: 148\t| Iteration: 500 \t| Log-Likelihood:-3.1872415293234253 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.186631  \n",
      "Run: 148\t| Iteration: 600 \t| Log-Likelihood:-3.1872380669023803 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.180365  \n",
      "Run: 148\t| Iteration: 700 \t| Log-Likelihood:-3.1872377552878977 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.212847  \n",
      "Run: 148\t| Iteration: 800 \t| Log-Likelihood:-3.1872377656898445 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.117926  \n",
      "Run: 148\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563469474 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.084164  \n",
      "Run: 149\t| Iteration: 0 \t| Log-Likelihood:-3.8765846939464024 \t|  theta: tensor([[0.4036, 3.7154]], requires_grad=True)  |  Time needed: 0:00:00.094599  \n",
      "Run: 149\t| Iteration: 100 \t| Log-Likelihood:-3.213774592661418 \t|  theta: tensor([[0.0501, 3.2025]], requires_grad=True)  |  Time needed: 0:00:09.080368  \n",
      "Run: 149\t| Iteration: 200 \t| Log-Likelihood:-3.189388256180918 \t|  theta: tensor([[0.0501, 3.0569]], requires_grad=True)  |  Time needed: 0:00:09.109348  \n",
      "Run: 149\t| Iteration: 300 \t| Log-Likelihood:-3.1874125672555538 \t|  theta: tensor([[0.0501, 3.0154]], requires_grad=True)  |  Time needed: 0:00:09.079753  \n",
      "Run: 149\t| Iteration: 400 \t| Log-Likelihood:-3.187251980015941 \t|  theta: tensor([[0.0501, 3.0036]], requires_grad=True)  |  Time needed: 0:00:09.085591  \n",
      "Run: 149\t| Iteration: 500 \t| Log-Likelihood:-3.1872389090412803 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.321225  \n",
      "Run: 149\t| Iteration: 600 \t| Log-Likelihood:-3.1872378539602475 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.127241  \n",
      "Run: 149\t| Iteration: 700 \t| Log-Likelihood:-3.1872377787676025 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.104499  \n",
      "Run: 149\t| Iteration: 800 \t| Log-Likelihood:-3.187237760512351 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.169626  \n",
      "Run: 149\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.264204  \n",
      "Run: 150\t| Iteration: 0 \t| Log-Likelihood:-7.023103341049455 \t|  theta: tensor([[0.4739, 0.2708]], requires_grad=True)  |  Time needed: 0:00:00.090496  \n",
      "Run: 150\t| Iteration: 100 \t| Log-Likelihood:-3.1905114925476936 \t|  theta: tensor([[0.4379, 1.0556]], requires_grad=True)  |  Time needed: 0:00:09.070570  \n",
      "Run: 150\t| Iteration: 200 \t| Log-Likelihood:-3.1904627469712383 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.563788  \n",
      "Run: 150\t| Iteration: 300 \t| Log-Likelihood:-3.190462702966187 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.197002  \n",
      "Run: 150\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116128  \n",
      "Run: 150\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108327  \n",
      "Run: 150\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.107398  \n",
      "Run: 150\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099655  \n",
      "Run: 150\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.122111  \n",
      "Run: 150\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.085337  \n",
      "Run: 151\t| Iteration: 0 \t| Log-Likelihood:-4.2652328391929055 \t|  theta: tensor([[0.2380, 0.9786]], requires_grad=True)  |  Time needed: 0:00:00.089885  \n",
      "Run: 151\t| Iteration: 100 \t| Log-Likelihood:-3.1904959685877414 \t|  theta: tensor([[0.4288, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.373662  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 151\t| Iteration: 200 \t| Log-Likelihood:-3.1904627328398165 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.310079  \n",
      "Run: 151\t| Iteration: 300 \t| Log-Likelihood:-3.190462732755622 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309295  \n",
      "Run: 151\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.284595  \n",
      "Run: 151\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.314422  \n",
      "Run: 151\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.275451  \n",
      "Run: 151\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.286404  \n",
      "Run: 151\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.303912  \n",
      "Run: 151\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.282017  \n",
      "Run: 152\t| Iteration: 0 \t| Log-Likelihood:-3.5166124090168878 \t|  theta: tensor([[0.1283, 1.0985]], requires_grad=True)  |  Time needed: 0:00:00.091986  \n",
      "Run: 152\t| Iteration: 100 \t| Log-Likelihood:-3.19055012785902 \t|  theta: tensor([[0.4263, 1.0588]], requires_grad=True)  |  Time needed: 0:00:09.108340  \n",
      "Run: 152\t| Iteration: 200 \t| Log-Likelihood:-3.190462811041708 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.114315  \n",
      "Run: 152\t| Iteration: 300 \t| Log-Likelihood:-3.190462702995768 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.083021  \n",
      "Run: 152\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.202758  \n",
      "Run: 152\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.141099  \n",
      "Run: 152\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.112662  \n",
      "Run: 152\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102546  \n",
      "Run: 152\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.177993  \n",
      "Run: 152\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.083455  \n",
      "Run: 153\t| Iteration: 0 \t| Log-Likelihood:-3.781449449020248 \t|  theta: tensor([[0.2472, 1.9489]], requires_grad=True)  |  Time needed: 0:00:00.096927  \n",
      "Run: 153\t| Iteration: 100 \t| Log-Likelihood:-3.316924947468972 \t|  theta: tensor([[0.0515, 2.5424]], requires_grad=True)  |  Time needed: 0:00:09.266490  \n",
      "Run: 153\t| Iteration: 200 \t| Log-Likelihood:-3.1985559309913794 \t|  theta: tensor([[0.0502, 2.8656]], requires_grad=True)  |  Time needed: 0:00:09.118335  \n",
      "Run: 153\t| Iteration: 300 \t| Log-Likelihood:-3.1881648148113944 \t|  theta: tensor([[0.0501, 2.9608]], requires_grad=True)  |  Time needed: 0:00:09.107386  \n",
      "Run: 153\t| Iteration: 400 \t| Log-Likelihood:-3.187313246500633 \t|  theta: tensor([[0.0501, 2.9880]], requires_grad=True)  |  Time needed: 0:00:09.101150  \n",
      "Run: 153\t| Iteration: 500 \t| Log-Likelihood:-3.187243862749761 \t|  theta: tensor([[0.0501, 2.9958]], requires_grad=True)  |  Time needed: 0:00:09.109193  \n",
      "Run: 153\t| Iteration: 600 \t| Log-Likelihood:-3.187238263835015 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.219855  \n",
      "Run: 153\t| Iteration: 700 \t| Log-Likelihood:-3.187237793031188 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.230302  \n",
      "Run: 153\t| Iteration: 800 \t| Log-Likelihood:-3.1872377296812178 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.607068  \n",
      "Run: 153\t| Iteration: 900 \t| Log-Likelihood:-3.1872377341067706 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.148636  \n",
      "Run: 154\t| Iteration: 0 \t| Log-Likelihood:-3.686192780804567 \t|  theta: tensor([[0.4732, 2.8156]], requires_grad=True)  |  Time needed: 0:00:00.092034  \n",
      "Run: 154\t| Iteration: 100 \t| Log-Likelihood:-3.1890138106235764 \t|  theta: tensor([[0.0501, 2.9461]], requires_grad=True)  |  Time needed: 0:00:09.851643  \n",
      "Run: 154\t| Iteration: 200 \t| Log-Likelihood:-3.1873824757538993 \t|  theta: tensor([[0.0501, 2.9838]], requires_grad=True)  |  Time needed: 0:00:09.995984  \n",
      "Run: 154\t| Iteration: 300 \t| Log-Likelihood:-3.1872495101055085 \t|  theta: tensor([[0.0501, 2.9946]], requires_grad=True)  |  Time needed: 0:00:10.085841  \n",
      "Run: 154\t| Iteration: 400 \t| Log-Likelihood:-3.1872387225541416 \t|  theta: tensor([[0.0501, 2.9977]], requires_grad=True)  |  Time needed: 0:00:10.010361  \n",
      "Run: 154\t| Iteration: 500 \t| Log-Likelihood:-3.1872378156067476 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.104144  \n",
      "Run: 154\t| Iteration: 600 \t| Log-Likelihood:-3.1872377252566224 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.113238  \n",
      "Run: 154\t| Iteration: 700 \t| Log-Likelihood:-3.1872377343011133 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.103313  \n",
      "Run: 154\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.097084  \n",
      "Run: 154\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.152494  \n",
      "Run: 155\t| Iteration: 0 \t| Log-Likelihood:-3.8275251963534718 \t|  theta: tensor([[0.3280, 1.7625]], requires_grad=True)  |  Time needed: 0:00:00.091765  \n",
      "Run: 155\t| Iteration: 100 \t| Log-Likelihood:-3.1984846302449377 \t|  theta: tensor([[0.3787, 1.0891]], requires_grad=True)  |  Time needed: 0:00:09.145422  \n",
      "Run: 155\t| Iteration: 200 \t| Log-Likelihood:-3.190468663027536 \t|  theta: tensor([[0.4312, 1.0575]], requires_grad=True)  |  Time needed: 0:00:09.079629  \n",
      "Run: 155\t| Iteration: 300 \t| Log-Likelihood:-3.1904627380812767 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110914  \n",
      "Run: 155\t| Iteration: 400 \t| Log-Likelihood:-3.190462702932167 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.149859  \n",
      "Run: 155\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.095689  \n",
      "Run: 155\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.090307  \n",
      "Run: 155\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.118121  \n",
      "Run: 155\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.090534  \n",
      "Run: 155\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.090179  \n",
      "Run: 156\t| Iteration: 0 \t| Log-Likelihood:-3.7323797759675266 \t|  theta: tensor([[0.0919, 1.5794]], requires_grad=True)  |  Time needed: 0:00:00.093072  \n",
      "Run: 156\t| Iteration: 100 \t| Log-Likelihood:-3.1915425415779297 \t|  theta: tensor([[0.4105, 1.0654]], requires_grad=True)  |  Time needed: 0:00:09.287192  \n",
      "Run: 156\t| Iteration: 200 \t| Log-Likelihood:-3.1904636082963913 \t|  theta: tensor([[0.4323, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.295392  \n",
      "Run: 156\t| Iteration: 300 \t| Log-Likelihood:-3.1904626739699222 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.351606  \n",
      "Run: 156\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731257903 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.429425  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 156\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.322061  \n",
      "Run: 156\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.295396  \n",
      "Run: 156\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.393766  \n",
      "Run: 156\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.391732  \n",
      "Run: 156\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.304387  \n",
      "Run: 157\t| Iteration: 0 \t| Log-Likelihood:-3.978632762898034 \t|  theta: tensor([[0.0581, 4.1090]], requires_grad=True)  |  Time needed: 0:00:00.087847  \n",
      "Run: 157\t| Iteration: 100 \t| Log-Likelihood:-3.250894196739111 \t|  theta: tensor([[0.0501, 3.3141]], requires_grad=True)  |  Time needed: 0:00:09.078339  \n",
      "Run: 157\t| Iteration: 200 \t| Log-Likelihood:-3.19238637297011 \t|  theta: tensor([[0.0501, 3.0886]], requires_grad=True)  |  Time needed: 0:00:09.095153  \n",
      "Run: 157\t| Iteration: 300 \t| Log-Likelihood:-3.187656043787173 \t|  theta: tensor([[0.0501, 3.0245]], requires_grad=True)  |  Time needed: 0:00:09.534512  \n",
      "Run: 157\t| Iteration: 400 \t| Log-Likelihood:-3.187271762479961 \t|  theta: tensor([[0.0501, 3.0062]], requires_grad=True)  |  Time needed: 0:00:09.110969  \n",
      "Run: 157\t| Iteration: 500 \t| Log-Likelihood:-3.187240533919934 \t|  theta: tensor([[0.0501, 3.0010]], requires_grad=True)  |  Time needed: 0:00:09.102490  \n",
      "Run: 157\t| Iteration: 600 \t| Log-Likelihood:-3.1872379622624973 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.189442  \n",
      "Run: 157\t| Iteration: 700 \t| Log-Likelihood:-3.1872377408684893 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.207336  \n",
      "Run: 157\t| Iteration: 800 \t| Log-Likelihood:-3.1872377650879806 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.073788  \n",
      "Run: 157\t| Iteration: 900 \t| Log-Likelihood:-3.187237756285213 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.112037  \n",
      "Run: 158\t| Iteration: 0 \t| Log-Likelihood:-3.370838475387709 \t|  theta: tensor([[0.0626, 2.4535]], requires_grad=True)  |  Time needed: 0:00:00.095873  \n",
      "Run: 158\t| Iteration: 100 \t| Log-Likelihood:-3.2037847201978304 \t|  theta: tensor([[0.0502, 2.8377]], requires_grad=True)  |  Time needed: 0:00:09.100005  \n",
      "Run: 158\t| Iteration: 200 \t| Log-Likelihood:-3.1885967270767774 \t|  theta: tensor([[0.0501, 2.9528]], requires_grad=True)  |  Time needed: 0:00:09.117041  \n",
      "Run: 158\t| Iteration: 300 \t| Log-Likelihood:-3.1873484165783794 \t|  theta: tensor([[0.0501, 2.9857]], requires_grad=True)  |  Time needed: 0:00:09.151886  \n",
      "Run: 158\t| Iteration: 400 \t| Log-Likelihood:-3.1872467291068824 \t|  theta: tensor([[0.0501, 2.9951]], requires_grad=True)  |  Time needed: 0:00:09.139313  \n",
      "Run: 158\t| Iteration: 500 \t| Log-Likelihood:-3.187238462439696 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.177044  \n",
      "Run: 158\t| Iteration: 600 \t| Log-Likelihood:-3.187237804533553 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.147030  \n",
      "Run: 158\t| Iteration: 700 \t| Log-Likelihood:-3.1872377274647694 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.117960  \n",
      "Run: 158\t| Iteration: 800 \t| Log-Likelihood:-3.1872377342130447 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.103617  \n",
      "Run: 158\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.184529  \n",
      "Run: 159\t| Iteration: 0 \t| Log-Likelihood:-4.303387266121972 \t|  theta: tensor([[0.1638, 4.2765]], requires_grad=True)  |  Time needed: 0:00:00.091219  \n",
      "Run: 159\t| Iteration: 100 \t| Log-Likelihood:-3.2715390771072963 \t|  theta: tensor([[0.0501, 3.3616]], requires_grad=True)  |  Time needed: 0:00:09.107187  \n",
      "Run: 159\t| Iteration: 200 \t| Log-Likelihood:-3.194051815927958 \t|  theta: tensor([[0.0501, 3.1021]], requires_grad=True)  |  Time needed: 0:00:09.101945  \n",
      "Run: 159\t| Iteration: 300 \t| Log-Likelihood:-3.187791128592373 \t|  theta: tensor([[0.0501, 3.0283]], requires_grad=True)  |  Time needed: 0:00:09.121640  \n",
      "Run: 159\t| Iteration: 400 \t| Log-Likelihood:-3.1872827626394806 \t|  theta: tensor([[0.0501, 3.0073]], requires_grad=True)  |  Time needed: 0:00:09.092949  \n",
      "Run: 159\t| Iteration: 500 \t| Log-Likelihood:-3.1872414219586593 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.097847  \n",
      "Run: 159\t| Iteration: 600 \t| Log-Likelihood:-3.187238050096716 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.114329  \n",
      "Run: 159\t| Iteration: 700 \t| Log-Likelihood:-3.1872377505567155 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.089476  \n",
      "Run: 159\t| Iteration: 800 \t| Log-Likelihood:-3.187237765621672 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.087594  \n",
      "Run: 159\t| Iteration: 900 \t| Log-Likelihood:-3.187237756341774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.480363  \n",
      "Run: 160\t| Iteration: 0 \t| Log-Likelihood:-3.4802925166509273 \t|  theta: tensor([[0.0708, 2.2949]], requires_grad=True)  |  Time needed: 0:00:00.092215  \n",
      "Run: 160\t| Iteration: 100 \t| Log-Likelihood:-3.2168222349122817 \t|  theta: tensor([[0.0503, 2.7831]], requires_grad=True)  |  Time needed: 0:00:09.086095  \n",
      "Run: 160\t| Iteration: 200 \t| Log-Likelihood:-3.1896832306309655 \t|  theta: tensor([[0.0501, 2.9370]], requires_grad=True)  |  Time needed: 0:00:09.274855  \n",
      "Run: 160\t| Iteration: 300 \t| Log-Likelihood:-3.187437054340899 \t|  theta: tensor([[0.0501, 2.9812]], requires_grad=True)  |  Time needed: 0:00:09.268179  \n",
      "Run: 160\t| Iteration: 400 \t| Log-Likelihood:-3.187253938086324 \t|  theta: tensor([[0.0501, 2.9938]], requires_grad=True)  |  Time needed: 0:00:09.200533  \n",
      "Run: 160\t| Iteration: 500 \t| Log-Likelihood:-3.187239038764846 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.084764  \n",
      "Run: 160\t| Iteration: 600 \t| Log-Likelihood:-3.187237833558587 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.115707  \n",
      "Run: 160\t| Iteration: 700 \t| Log-Likelihood:-3.1872377276712656 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.102277  \n",
      "Run: 160\t| Iteration: 800 \t| Log-Likelihood:-3.1872377345331544 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.110452  \n",
      "Run: 160\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.624258  \n",
      "Run: 161\t| Iteration: 0 \t| Log-Likelihood:-3.7794947680100006 \t|  theta: tensor([[0.4817, 3.3908]], requires_grad=True)  |  Time needed: 0:00:00.088659  \n",
      "Run: 161\t| Iteration: 100 \t| Log-Likelihood:-3.1951905614920406 \t|  theta: tensor([[0.0501, 3.1104]], requires_grad=True)  |  Time needed: 0:00:09.285038  \n",
      "Run: 161\t| Iteration: 200 \t| Log-Likelihood:-3.1878835124665823 \t|  theta: tensor([[0.0501, 3.0307]], requires_grad=True)  |  Time needed: 0:00:09.390716  \n",
      "Run: 161\t| Iteration: 300 \t| Log-Likelihood:-3.1872902588503687 \t|  theta: tensor([[0.0501, 3.0079]], requires_grad=True)  |  Time needed: 0:00:09.285645  \n",
      "Run: 161\t| Iteration: 400 \t| Log-Likelihood:-3.187242006562642 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.263019  \n",
      "Run: 161\t| Iteration: 500 \t| Log-Likelihood:-3.1872381071054683 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.362404  \n",
      "Run: 161\t| Iteration: 600 \t| Log-Likelihood:-3.187237758365095 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.351111  \n",
      "Run: 161\t| Iteration: 700 \t| Log-Likelihood:-3.1872377659373776 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.277971  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 161\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563738805 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.291025  \n",
      "Run: 161\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.324935  \n",
      "Run: 162\t| Iteration: 0 \t| Log-Likelihood:-3.210907828567554 \t|  theta: tensor([[0.4616, 0.9895]], requires_grad=True)  |  Time needed: 0:00:00.088615  \n",
      "Run: 162\t| Iteration: 100 \t| Log-Likelihood:-3.190465860667567 \t|  theta: tensor([[0.4342, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.127609  \n",
      "Run: 162\t| Iteration: 200 \t| Log-Likelihood:-3.190462705810933 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.204032  \n",
      "Run: 162\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029304944 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.078930  \n",
      "Run: 162\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.080428  \n",
      "Run: 162\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.098696  \n",
      "Run: 162\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.096469  \n",
      "Run: 162\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.075309  \n",
      "Run: 162\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.149461  \n",
      "Run: 162\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103501  \n",
      "Run: 163\t| Iteration: 0 \t| Log-Likelihood:-4.437750828714459 \t|  theta: tensor([[0.0488, 4.3950]], requires_grad=True)  |  Time needed: 0:00:00.094607  \n",
      "Run: 163\t| Iteration: 100 \t| Log-Likelihood:-3.2878956703473823 \t|  theta: tensor([[0.0501, 3.3953]], requires_grad=True)  |  Time needed: 0:00:09.108372  \n",
      "Run: 163\t| Iteration: 200 \t| Log-Likelihood:-3.195370752765233 \t|  theta: tensor([[0.0501, 3.1116]], requires_grad=True)  |  Time needed: 0:00:09.150223  \n",
      "Run: 163\t| Iteration: 300 \t| Log-Likelihood:-3.187898111457952 \t|  theta: tensor([[0.0501, 3.0310]], requires_grad=True)  |  Time needed: 0:00:09.097509  \n",
      "Run: 163\t| Iteration: 400 \t| Log-Likelihood:-3.1872914644289896 \t|  theta: tensor([[0.0501, 3.0080]], requires_grad=True)  |  Time needed: 0:00:09.097506  \n",
      "Run: 163\t| Iteration: 500 \t| Log-Likelihood:-3.1872421102652955 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.162265  \n",
      "Run: 163\t| Iteration: 600 \t| Log-Likelihood:-3.1872381188626586 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.266438  \n",
      "Run: 163\t| Iteration: 700 \t| Log-Likelihood:-3.1872377590017926 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.106748  \n",
      "Run: 163\t| Iteration: 800 \t| Log-Likelihood:-3.1872377659922275 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.244608  \n",
      "Run: 163\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563794796 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.109804  \n",
      "Run: 164\t| Iteration: 0 \t| Log-Likelihood:-3.5465423423187303 \t|  theta: tensor([[0.1137, 3.7165]], requires_grad=True)  |  Time needed: 0:00:00.099876  \n",
      "Run: 164\t| Iteration: 100 \t| Log-Likelihood:-3.2138586878836817 \t|  theta: tensor([[0.0501, 3.2028]], requires_grad=True)  |  Time needed: 0:00:09.226419  \n",
      "Run: 164\t| Iteration: 200 \t| Log-Likelihood:-3.1893950311228374 \t|  theta: tensor([[0.0501, 3.0570]], requires_grad=True)  |  Time needed: 0:00:09.123666  \n",
      "Run: 164\t| Iteration: 300 \t| Log-Likelihood:-3.1874130743037243 \t|  theta: tensor([[0.0501, 3.0154]], requires_grad=True)  |  Time needed: 0:00:09.193575  \n",
      "Run: 164\t| Iteration: 400 \t| Log-Likelihood:-3.1872520254811643 \t|  theta: tensor([[0.0501, 3.0036]], requires_grad=True)  |  Time needed: 0:00:09.133824  \n",
      "Run: 164\t| Iteration: 500 \t| Log-Likelihood:-3.187238913499139 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.568606  \n",
      "Run: 164\t| Iteration: 600 \t| Log-Likelihood:-3.187237854306974 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.159536  \n",
      "Run: 164\t| Iteration: 700 \t| Log-Likelihood:-3.1872377787676025 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.112755  \n",
      "Run: 164\t| Iteration: 800 \t| Log-Likelihood:-3.187237760512351 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.134838  \n",
      "Run: 164\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.121477  \n",
      "Run: 165\t| Iteration: 0 \t| Log-Likelihood:-3.839808201620671 \t|  theta: tensor([[0.1960, 3.9279]], requires_grad=True)  |  Time needed: 0:00:00.091094  \n",
      "Run: 165\t| Iteration: 100 \t| Log-Likelihood:-3.231829476844699 \t|  theta: tensor([[0.0501, 3.2628]], requires_grad=True)  |  Time needed: 0:00:09.109164  \n",
      "Run: 165\t| Iteration: 200 \t| Log-Likelihood:-3.1908472190348305 \t|  theta: tensor([[0.0501, 3.0740]], requires_grad=True)  |  Time needed: 0:00:09.283775  \n",
      "Run: 165\t| Iteration: 300 \t| Log-Likelihood:-3.1875310521272104 \t|  theta: tensor([[0.0501, 3.0203]], requires_grad=True)  |  Time needed: 0:00:09.085763  \n",
      "Run: 165\t| Iteration: 400 \t| Log-Likelihood:-3.1872616188861427 \t|  theta: tensor([[0.0501, 3.0050]], requires_grad=True)  |  Time needed: 0:00:09.140598  \n",
      "Run: 165\t| Iteration: 500 \t| Log-Likelihood:-3.1872396529647467 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.122653  \n",
      "Run: 165\t| Iteration: 600 \t| Log-Likelihood:-3.1872378771691166 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.165107  \n",
      "Run: 165\t| Iteration: 700 \t| Log-Likelihood:-3.187237731722059 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.084007  \n",
      "Run: 165\t| Iteration: 800 \t| Log-Likelihood:-3.1872377609598126 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.101860  \n",
      "Run: 165\t| Iteration: 900 \t| Log-Likelihood:-3.187237756232123 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.096761  \n",
      "Run: 166\t| Iteration: 0 \t| Log-Likelihood:-3.538558169232294 \t|  theta: tensor([[0.3067, 3.4454]], requires_grad=True)  |  Time needed: 0:00:00.088211  \n",
      "Run: 166\t| Iteration: 100 \t| Log-Likelihood:-3.1975568734178226 \t|  theta: tensor([[0.0501, 3.1259]], requires_grad=True)  |  Time needed: 0:00:09.298959  \n",
      "Run: 166\t| Iteration: 200 \t| Log-Likelihood:-3.188075440393373 \t|  theta: tensor([[0.0501, 3.0351]], requires_grad=True)  |  Time needed: 0:00:09.341326  \n",
      "Run: 166\t| Iteration: 300 \t| Log-Likelihood:-3.1873058406028525 \t|  theta: tensor([[0.0501, 3.0092]], requires_grad=True)  |  Time needed: 0:00:09.306152  \n",
      "Run: 166\t| Iteration: 400 \t| Log-Likelihood:-3.187243281365919 \t|  theta: tensor([[0.0501, 3.0018]], requires_grad=True)  |  Time needed: 0:00:09.297280  \n",
      "Run: 166\t| Iteration: 500 \t| Log-Likelihood:-3.1872381700872605 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.286736  \n",
      "Run: 166\t| Iteration: 600 \t| Log-Likelihood:-3.187237770486285 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.278539  \n",
      "Run: 166\t| Iteration: 700 \t| Log-Likelihood:-3.1872377665963514 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.405670  \n",
      "Run: 166\t| Iteration: 800 \t| Log-Likelihood:-3.1872377564330603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.291238  \n",
      "Run: 166\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.320897  \n",
      "Run: 167\t| Iteration: 0 \t| Log-Likelihood:-4.75658477477611 \t|  theta: tensor([[0.5393, 4.2217]], requires_grad=True)  |  Time needed: 0:00:00.089022  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 167\t| Iteration: 100 \t| Log-Likelihood:-3.264469886317078 \t|  theta: tensor([[0.0501, 3.3461]], requires_grad=True)  |  Time needed: 0:00:09.228388  \n",
      "Run: 167\t| Iteration: 200 \t| Log-Likelihood:-3.193481737143623 \t|  theta: tensor([[0.0501, 3.0977]], requires_grad=True)  |  Time needed: 0:00:09.091577  \n",
      "Run: 167\t| Iteration: 300 \t| Log-Likelihood:-3.187744931972664 \t|  theta: tensor([[0.0501, 3.0270]], requires_grad=True)  |  Time needed: 0:00:09.087383  \n",
      "Run: 167\t| Iteration: 400 \t| Log-Likelihood:-3.187278989511173 \t|  theta: tensor([[0.0501, 3.0069]], requires_grad=True)  |  Time needed: 0:00:09.180134  \n",
      "Run: 167\t| Iteration: 500 \t| Log-Likelihood:-3.1872410989983067 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.088668  \n",
      "Run: 167\t| Iteration: 600 \t| Log-Likelihood:-3.1872380220376355 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.088548  \n",
      "Run: 167\t| Iteration: 700 \t| Log-Likelihood:-3.187237748550246 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.106902  \n",
      "Run: 167\t| Iteration: 800 \t| Log-Likelihood:-3.187237765440043 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.077881  \n",
      "Run: 167\t| Iteration: 900 \t| Log-Likelihood:-3.187237756321787 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.076759  \n",
      "Run: 168\t| Iteration: 0 \t| Log-Likelihood:-4.245386035370332 \t|  theta: tensor([[0.2112, 0.9575]], requires_grad=True)  |  Time needed: 0:00:00.091349  \n",
      "Run: 168\t| Iteration: 100 \t| Log-Likelihood:-3.1905013293246394 \t|  theta: tensor([[0.4285, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.614967  \n",
      "Run: 168\t| Iteration: 200 \t| Log-Likelihood:-3.190462767378338 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.179301  \n",
      "Run: 168\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029578974 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.219166  \n",
      "Run: 168\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128229  \n",
      "Run: 168\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.124308  \n",
      "Run: 168\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125824  \n",
      "Run: 168\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.212828  \n",
      "Run: 168\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.140311  \n",
      "Run: 168\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.131913  \n",
      "Run: 169\t| Iteration: 0 \t| Log-Likelihood:-3.7623514148604023 \t|  theta: tensor([[0.5776, 1.4657]], requires_grad=True)  |  Time needed: 0:00:00.094076  \n",
      "Run: 169\t| Iteration: 100 \t| Log-Likelihood:-3.190465936556627 \t|  theta: tensor([[0.4318, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.163596  \n",
      "Run: 169\t| Iteration: 200 \t| Log-Likelihood:-3.1904627055366364 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123652  \n",
      "Run: 169\t| Iteration: 300 \t| Log-Likelihood:-3.190462673127851 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125276  \n",
      "Run: 169\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.175580  \n",
      "Run: 169\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156148  \n",
      "Run: 169\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.106766  \n",
      "Run: 169\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136482  \n",
      "Run: 169\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128498  \n",
      "Run: 169\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104301  \n",
      "Run: 170\t| Iteration: 0 \t| Log-Likelihood:-5.334408897759218 \t|  theta: tensor([[0.5738, 4.5063]], requires_grad=True)  |  Time needed: 0:00:00.093177  \n",
      "Run: 170\t| Iteration: 100 \t| Log-Likelihood:-3.3045824931127736 \t|  theta: tensor([[0.0501, 3.4268]], requires_grad=True)  |  Time needed: 0:00:09.235095  \n",
      "Run: 170\t| Iteration: 200 \t| Log-Likelihood:-3.1967158199328733 \t|  theta: tensor([[0.0501, 3.1206]], requires_grad=True)  |  Time needed: 0:00:09.108844  \n",
      "Run: 170\t| Iteration: 300 \t| Log-Likelihood:-3.1880072503104415 \t|  theta: tensor([[0.0501, 3.0336]], requires_grad=True)  |  Time needed: 0:00:09.121223  \n",
      "Run: 170\t| Iteration: 400 \t| Log-Likelihood:-3.1873002785269287 \t|  theta: tensor([[0.0501, 3.0088]], requires_grad=True)  |  Time needed: 0:00:09.119545  \n",
      "Run: 170\t| Iteration: 500 \t| Log-Likelihood:-3.1872428095187937 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.089337  \n",
      "Run: 170\t| Iteration: 600 \t| Log-Likelihood:-3.1872381292286174 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.107198  \n",
      "Run: 170\t| Iteration: 700 \t| Log-Likelihood:-3.1872377675204895 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.300954  \n",
      "Run: 170\t| Iteration: 800 \t| Log-Likelihood:-3.187237766334718 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.158609  \n",
      "Run: 170\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564145626 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108420  \n",
      "Run: 171\t| Iteration: 0 \t| Log-Likelihood:-3.766133226068709 \t|  theta: tensor([[0.0815, 1.5486]], requires_grad=True)  |  Time needed: 0:00:00.093679  \n",
      "Run: 171\t| Iteration: 100 \t| Log-Likelihood:-3.1912904658703782 \t|  theta: tensor([[0.4131, 1.0641]], requires_grad=True)  |  Time needed: 0:00:09.286333  \n",
      "Run: 171\t| Iteration: 200 \t| Log-Likelihood:-3.1904634552159554 \t|  theta: tensor([[0.4323, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.287632  \n",
      "Run: 171\t| Iteration: 300 \t| Log-Likelihood:-3.1904626737749706 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.322440  \n",
      "Run: 171\t| Iteration: 400 \t| Log-Likelihood:-3.190462673125561 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.676966  \n",
      "Run: 171\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.300191  \n",
      "Run: 171\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.337436  \n",
      "Run: 171\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.750910  \n",
      "Run: 171\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.321022  \n",
      "Run: 171\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.311372  \n",
      "Run: 172\t| Iteration: 0 \t| Log-Likelihood:-3.6011902877206468 \t|  theta: tensor([[0.3716, 1.4795]], requires_grad=True)  |  Time needed: 0:00:00.089131  \n",
      "Run: 172\t| Iteration: 100 \t| Log-Likelihood:-3.1906066037891723 \t|  theta: tensor([[0.4246, 1.0597]], requires_grad=True)  |  Time needed: 0:00:09.173434  \n",
      "Run: 172\t| Iteration: 200 \t| Log-Likelihood:-3.1904628012243172 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.090552  \n",
      "Run: 172\t| Iteration: 300 \t| Log-Likelihood:-3.1904627030400343 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137182  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 172\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.090708  \n",
      "Run: 172\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.094791  \n",
      "Run: 172\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108064  \n",
      "Run: 172\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.083915  \n",
      "Run: 172\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093914  \n",
      "Run: 172\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110406  \n",
      "Run: 173\t| Iteration: 0 \t| Log-Likelihood:-3.752700700889829 \t|  theta: tensor([[0.3164, 0.7562]], requires_grad=True)  |  Time needed: 0:00:00.096786  \n",
      "Run: 173\t| Iteration: 100 \t| Log-Likelihood:-3.1904657723614553 \t|  theta: tensor([[0.4317, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.105091  \n",
      "Run: 173\t| Iteration: 200 \t| Log-Likelihood:-3.1904627056658605 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.107845  \n",
      "Run: 173\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029302373 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.260509  \n",
      "Run: 173\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.242011  \n",
      "Run: 173\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.114294  \n",
      "Run: 173\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142088  \n",
      "Run: 173\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.121996  \n",
      "Run: 173\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102935  \n",
      "Run: 173\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.188034  \n",
      "Run: 174\t| Iteration: 0 \t| Log-Likelihood:-3.9093848519220473 \t|  theta: tensor([[0.0378, 4.0566]], requires_grad=True)  |  Time needed: 0:00:00.092020  \n",
      "Run: 174\t| Iteration: 100 \t| Log-Likelihood:-3.2450286587489225 \t|  theta: tensor([[0.0501, 3.2993]], requires_grad=True)  |  Time needed: 0:00:09.096306  \n",
      "Run: 174\t| Iteration: 200 \t| Log-Likelihood:-3.1919130227749615 \t|  theta: tensor([[0.0501, 3.0844]], requires_grad=True)  |  Time needed: 0:00:09.126767  \n",
      "Run: 174\t| Iteration: 300 \t| Log-Likelihood:-3.187617586941596 \t|  theta: tensor([[0.0501, 3.0233]], requires_grad=True)  |  Time needed: 0:00:09.233127  \n",
      "Run: 174\t| Iteration: 400 \t| Log-Likelihood:-3.1872686376444745 \t|  theta: tensor([[0.0501, 3.0058]], requires_grad=True)  |  Time needed: 0:00:09.123462  \n",
      "Run: 174\t| Iteration: 500 \t| Log-Likelihood:-3.1872402652580507 \t|  theta: tensor([[0.0501, 3.0009]], requires_grad=True)  |  Time needed: 0:00:09.139791  \n",
      "Run: 174\t| Iteration: 600 \t| Log-Likelihood:-3.187237934416481 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.163991  \n",
      "Run: 174\t| Iteration: 700 \t| Log-Likelihood:-3.1872377392292237 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.177981  \n",
      "Run: 174\t| Iteration: 800 \t| Log-Likelihood:-3.18723776123513 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.100834  \n",
      "Run: 174\t| Iteration: 900 \t| Log-Likelihood:-3.187237756272668 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.121312  \n",
      "Run: 175\t| Iteration: 0 \t| Log-Likelihood:-3.43689969274205 \t|  theta: tensor([[0.3059, 2.7902]], requires_grad=True)  |  Time needed: 0:00:00.092025  \n",
      "Run: 175\t| Iteration: 100 \t| Log-Likelihood:-3.189535147267289 \t|  theta: tensor([[0.0501, 2.9389]], requires_grad=True)  |  Time needed: 0:00:09.106601  \n",
      "Run: 175\t| Iteration: 200 \t| Log-Likelihood:-3.187425024199709 \t|  theta: tensor([[0.0501, 2.9818]], requires_grad=True)  |  Time needed: 0:00:09.104014  \n",
      "Run: 175\t| Iteration: 300 \t| Log-Likelihood:-3.18725298769409 \t|  theta: tensor([[0.0501, 2.9940]], requires_grad=True)  |  Time needed: 0:00:09.597727  \n",
      "Run: 175\t| Iteration: 400 \t| Log-Likelihood:-3.1872389649018245 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.095927  \n",
      "Run: 175\t| Iteration: 500 \t| Log-Likelihood:-3.1872378308505667 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.077360  \n",
      "Run: 175\t| Iteration: 600 \t| Log-Likelihood:-3.1872377271163006 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.126555  \n",
      "Run: 175\t| Iteration: 700 \t| Log-Likelihood:-3.1872377344832032 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.090213  \n",
      "Run: 175\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.102395  \n",
      "Run: 175\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.177765  \n",
      "Run: 176\t| Iteration: 0 \t| Log-Likelihood:-5.543494844268436 \t|  theta: tensor([[0.3340, 4.8070]], requires_grad=True)  |  Time needed: 0:00:00.092030  \n",
      "Run: 176\t| Iteration: 100 \t| Log-Likelihood:-3.3561110012999684 \t|  theta: tensor([[0.0501, 3.5122]], requires_grad=True)  |  Time needed: 0:00:09.384699  \n",
      "Run: 176\t| Iteration: 200 \t| Log-Likelihood:-3.2008675175566004 \t|  theta: tensor([[0.0501, 3.1448]], requires_grad=True)  |  Time needed: 0:00:09.327600  \n",
      "Run: 176\t| Iteration: 300 \t| Log-Likelihood:-3.1883436674393697 \t|  theta: tensor([[0.0501, 3.0405]], requires_grad=True)  |  Time needed: 0:00:09.303897  \n",
      "Run: 176\t| Iteration: 400 \t| Log-Likelihood:-3.187327677488949 \t|  theta: tensor([[0.0501, 3.0107]], requires_grad=True)  |  Time needed: 0:00:09.304263  \n",
      "Run: 176\t| Iteration: 500 \t| Log-Likelihood:-3.1872450775103736 \t|  theta: tensor([[0.0501, 3.0023]], requires_grad=True)  |  Time needed: 0:00:09.269839  \n",
      "Run: 176\t| Iteration: 600 \t| Log-Likelihood:-3.1872383372844655 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.402436  \n",
      "Run: 176\t| Iteration: 700 \t| Log-Likelihood:-3.187237789715 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.307728  \n",
      "Run: 176\t| Iteration: 800 \t| Log-Likelihood:-3.187237771296029 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.265438  \n",
      "Run: 176\t| Iteration: 900 \t| Log-Likelihood:-3.1872377565063426 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.301810  \n",
      "Run: 177\t| Iteration: 0 \t| Log-Likelihood:-5.62869794216384 \t|  theta: tensor([[0.2638, 4.8804]], requires_grad=True)  |  Time needed: 0:00:00.089248  \n",
      "Run: 177\t| Iteration: 100 \t| Log-Likelihood:-3.3701509931481617 \t|  theta: tensor([[0.0501, 3.5331]], requires_grad=True)  |  Time needed: 0:00:09.098391  \n",
      "Run: 177\t| Iteration: 200 \t| Log-Likelihood:-3.201998447889304 \t|  theta: tensor([[0.0501, 3.1508]], requires_grad=True)  |  Time needed: 0:00:09.143735  \n",
      "Run: 177\t| Iteration: 300 \t| Log-Likelihood:-3.188435243922202 \t|  theta: tensor([[0.0501, 3.0422]], requires_grad=True)  |  Time needed: 0:00:09.138664  \n",
      "Run: 177\t| Iteration: 400 \t| Log-Likelihood:-3.1873350708514647 \t|  theta: tensor([[0.0501, 3.0112]], requires_grad=True)  |  Time needed: 0:00:09.068857  \n",
      "Run: 177\t| Iteration: 500 \t| Log-Likelihood:-3.1872456464160637 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.132457  \n",
      "Run: 177\t| Iteration: 600 \t| Log-Likelihood:-3.187238392748556 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.198344  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 177\t| Iteration: 700 \t| Log-Likelihood:-3.187237797413597 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.076504  \n",
      "Run: 177\t| Iteration: 800 \t| Log-Likelihood:-3.18723777161017 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.077960  \n",
      "Run: 177\t| Iteration: 900 \t| Log-Likelihood:-3.187237756527817 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.120273  \n",
      "Run: 178\t| Iteration: 0 \t| Log-Likelihood:-6.463689370784283 \t|  theta: tensor([[0.1350, 0.4000]], requires_grad=True)  |  Time needed: 0:00:00.108317  \n",
      "Run: 178\t| Iteration: 100 \t| Log-Likelihood:-3.1904786959413327 \t|  theta: tensor([[0.4301, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.775758  \n",
      "Run: 178\t| Iteration: 200 \t| Log-Likelihood:-3.190462717247154 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.421484  \n",
      "Run: 178\t| Iteration: 300 \t| Log-Likelihood:-3.190462673138272 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.132947  \n",
      "Run: 178\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119567  \n",
      "Run: 178\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.187711  \n",
      "Run: 178\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.182849  \n",
      "Run: 178\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137538  \n",
      "Run: 178\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.234301  \n",
      "Run: 178\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.523207  \n",
      "Run: 179\t| Iteration: 0 \t| Log-Likelihood:-3.4049995323463875 \t|  theta: tensor([[0.3011, 3.0456]], requires_grad=True)  |  Time needed: 0:00:00.092608  \n",
      "Run: 179\t| Iteration: 100 \t| Log-Likelihood:-3.187350830183185 \t|  theta: tensor([[0.0501, 3.0122]], requires_grad=True)  |  Time needed: 0:00:09.080637  \n",
      "Run: 179\t| Iteration: 200 \t| Log-Likelihood:-3.1872469124652576 \t|  theta: tensor([[0.0501, 3.0027]], requires_grad=True)  |  Time needed: 0:00:09.118109  \n",
      "Run: 179\t| Iteration: 300 \t| Log-Likelihood:-3.1872385084591572 \t|  theta: tensor([[0.0501, 3.0000]], requires_grad=True)  |  Time needed: 0:00:09.114220  \n",
      "Run: 179\t| Iteration: 400 \t| Log-Likelihood:-3.1872378096479967 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.112421  \n",
      "Run: 179\t| Iteration: 500 \t| Log-Likelihood:-3.187237772300882 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.156935  \n",
      "Run: 179\t| Iteration: 600 \t| Log-Likelihood:-3.1872377565726784 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113534  \n",
      "Run: 179\t| Iteration: 700 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.181858  \n",
      "Run: 179\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.222884  \n",
      "Run: 179\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.243844  \n",
      "Run: 180\t| Iteration: 0 \t| Log-Likelihood:-3.5030184246621205 \t|  theta: tensor([[0.0468, 3.6578]], requires_grad=True)  |  Time needed: 0:00:00.093829  \n",
      "Run: 180\t| Iteration: 100 \t| Log-Likelihood:-3.2096813279082896 \t|  theta: tensor([[0.0501, 3.1861]], requires_grad=True)  |  Time needed: 0:00:09.082697  \n",
      "Run: 180\t| Iteration: 200 \t| Log-Likelihood:-3.189057223094653 \t|  theta: tensor([[0.0501, 3.0522]], requires_grad=True)  |  Time needed: 0:00:09.106947  \n",
      "Run: 180\t| Iteration: 300 \t| Log-Likelihood:-3.1873856308478223 \t|  theta: tensor([[0.0501, 3.0141]], requires_grad=True)  |  Time needed: 0:00:09.109610  \n",
      "Run: 180\t| Iteration: 400 \t| Log-Likelihood:-3.1872497750432958 \t|  theta: tensor([[0.0501, 3.0032]], requires_grad=True)  |  Time needed: 0:00:09.089145  \n",
      "Run: 180\t| Iteration: 500 \t| Log-Likelihood:-3.1872387045935633 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.129833  \n",
      "Run: 180\t| Iteration: 600 \t| Log-Likelihood:-3.1872378356103384 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.120955  \n",
      "Run: 180\t| Iteration: 700 \t| Log-Likelihood:-3.187237777562569 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.082467  \n",
      "Run: 180\t| Iteration: 800 \t| Log-Likelihood:-3.1872377603953455 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.095737  \n",
      "Run: 180\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.095926  \n",
      "Run: 181\t| Iteration: 0 \t| Log-Likelihood:-3.6896563040241324 \t|  theta: tensor([[0.2514, 1.6127]], requires_grad=True)  |  Time needed: 0:00:00.088541  \n",
      "Run: 181\t| Iteration: 100 \t| Log-Likelihood:-3.1913413728721087 \t|  theta: tensor([[0.4126, 1.0645]], requires_grad=True)  |  Time needed: 0:00:09.456161  \n",
      "Run: 181\t| Iteration: 200 \t| Log-Likelihood:-3.190463436487041 \t|  theta: tensor([[0.4323, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.417231  \n",
      "Run: 181\t| Iteration: 300 \t| Log-Likelihood:-3.1904626738083306 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.301768  \n",
      "Run: 181\t| Iteration: 400 \t| Log-Likelihood:-3.1904627029279125 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.291979  \n",
      "Run: 181\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.314246  \n",
      "Run: 181\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.288306  \n",
      "Run: 181\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.296607  \n",
      "Run: 181\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.315079  \n",
      "Run: 181\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.307520  \n",
      "Run: 182\t| Iteration: 0 \t| Log-Likelihood:-3.6619929495900543 \t|  theta: tensor([[0.3860, 3.4688]], requires_grad=True)  |  Time needed: 0:00:00.091144  \n",
      "Run: 182\t| Iteration: 100 \t| Log-Likelihood:-3.198664511044499 \t|  theta: tensor([[0.0501, 3.1325]], requires_grad=True)  |  Time needed: 0:00:09.120906  \n",
      "Run: 182\t| Iteration: 200 \t| Log-Likelihood:-3.18816519194087 \t|  theta: tensor([[0.0501, 3.0370]], requires_grad=True)  |  Time needed: 0:00:09.119688  \n",
      "Run: 182\t| Iteration: 300 \t| Log-Likelihood:-3.187313171437441 \t|  theta: tensor([[0.0501, 3.0097]], requires_grad=True)  |  Time needed: 0:00:09.090876  \n",
      "Run: 182\t| Iteration: 400 \t| Log-Likelihood:-3.1872438462317048 \t|  theta: tensor([[0.0501, 3.0020]], requires_grad=True)  |  Time needed: 0:00:09.223851  \n",
      "Run: 182\t| Iteration: 500 \t| Log-Likelihood:-3.1872382260635823 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.530224  \n",
      "Run: 182\t| Iteration: 600 \t| Log-Likelihood:-3.187237778056698 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.123110  \n",
      "Run: 182\t| Iteration: 700 \t| Log-Likelihood:-3.187237770660092 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.092779  \n",
      "Run: 182\t| Iteration: 800 \t| Log-Likelihood:-3.1872377564587167 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113651  \n",
      "Run: 182\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108692  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 183\t| Iteration: 0 \t| Log-Likelihood:-7.966281415038496 \t|  theta: tensor([[0.1989, 0.1908]], requires_grad=True)  |  Time needed: 0:00:00.093868  \n",
      "Run: 183\t| Iteration: 100 \t| Log-Likelihood:-3.190466574133112 \t|  theta: tensor([[0.4315, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.235096  \n",
      "Run: 183\t| Iteration: 200 \t| Log-Likelihood:-3.1904627360637425 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.489662  \n",
      "Run: 183\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731283283 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.153988  \n",
      "Run: 183\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.159164  \n",
      "Run: 183\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.130082  \n",
      "Run: 183\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.169746  \n",
      "Run: 183\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.268560  \n",
      "Run: 183\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.133308  \n",
      "Run: 183\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.095390  \n",
      "Run: 184\t| Iteration: 0 \t| Log-Likelihood:-3.500298312521384 \t|  theta: tensor([[0.3536, 3.2040]], requires_grad=True)  |  Time needed: 0:00:00.095934  \n",
      "Run: 184\t| Iteration: 100 \t| Log-Likelihood:-3.189418742960375 \t|  theta: tensor([[0.0501, 3.0573]], requires_grad=True)  |  Time needed: 0:00:09.121077  \n",
      "Run: 184\t| Iteration: 200 \t| Log-Likelihood:-3.187415013938711 \t|  theta: tensor([[0.0501, 3.0155]], requires_grad=True)  |  Time needed: 0:00:09.160506  \n",
      "Run: 184\t| Iteration: 300 \t| Log-Likelihood:-3.1872521860466367 \t|  theta: tensor([[0.0501, 3.0036]], requires_grad=True)  |  Time needed: 0:00:09.084889  \n",
      "Run: 184\t| Iteration: 400 \t| Log-Likelihood:-3.187238930241499 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.245480  \n",
      "Run: 184\t| Iteration: 500 \t| Log-Likelihood:-3.1872378553509826 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.094118  \n",
      "Run: 184\t| Iteration: 600 \t| Log-Likelihood:-3.18723777883386 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.116293  \n",
      "Run: 184\t| Iteration: 700 \t| Log-Likelihood:-3.1872377605218474 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.109103  \n",
      "Run: 184\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.082600  \n",
      "Run: 184\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.094351  \n",
      "Run: 185\t| Iteration: 0 \t| Log-Likelihood:-3.821957928734144 \t|  theta: tensor([[0.5210, 2.6770]], requires_grad=True)  |  Time needed: 0:00:00.094650  \n",
      "Run: 185\t| Iteration: 100 \t| Log-Likelihood:-3.1928277032604093 \t|  theta: tensor([[0.0501, 2.9053]], requires_grad=True)  |  Time needed: 0:00:09.166734  \n",
      "Run: 185\t| Iteration: 200 \t| Log-Likelihood:-3.1876941694970107 \t|  theta: tensor([[0.0501, 2.9721]], requires_grad=True)  |  Time needed: 0:00:09.161141  \n",
      "Run: 185\t| Iteration: 300 \t| Log-Likelihood:-3.187274924198988 \t|  theta: tensor([[0.0501, 2.9913]], requires_grad=True)  |  Time needed: 0:00:09.412235  \n",
      "Run: 185\t| Iteration: 400 \t| Log-Likelihood:-3.187240784268007 \t|  theta: tensor([[0.0501, 2.9967]], requires_grad=True)  |  Time needed: 0:00:09.113225  \n",
      "Run: 185\t| Iteration: 500 \t| Log-Likelihood:-3.1872379944227265 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.089706  \n",
      "Run: 185\t| Iteration: 600 \t| Log-Likelihood:-3.187237787339918 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.093012  \n",
      "Run: 185\t| Iteration: 700 \t| Log-Likelihood:-3.187237731708357 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.143473  \n",
      "Run: 185\t| Iteration: 800 \t| Log-Likelihood:-3.187237733951049 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.088968  \n",
      "Run: 185\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.087326  \n",
      "Run: 186\t| Iteration: 0 \t| Log-Likelihood:-3.8088879678528333 \t|  theta: tensor([[0.3370, 0.7363]], requires_grad=True)  |  Time needed: 0:00:00.098839  \n",
      "Run: 186\t| Iteration: 100 \t| Log-Likelihood:-3.190463617094452 \t|  theta: tensor([[0.4323, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.593342  \n",
      "Run: 186\t| Iteration: 200 \t| Log-Likelihood:-3.1904626739134074 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.362259  \n",
      "Run: 186\t| Iteration: 300 \t| Log-Likelihood:-3.190462702928024 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.270273  \n",
      "Run: 186\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.333493  \n",
      "Run: 186\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.361650  \n",
      "Run: 186\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.290582  \n",
      "Run: 186\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.320034  \n",
      "Run: 186\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.273397  \n",
      "Run: 186\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.280104  \n",
      "Run: 187\t| Iteration: 0 \t| Log-Likelihood:-4.204011809841864 \t|  theta: tensor([[0.5695, 2.1168]], requires_grad=True)  |  Time needed: 0:00:00.093451  \n",
      "Run: 187\t| Iteration: 100 \t| Log-Likelihood:-3.253882866605999 \t|  theta: tensor([[0.0505, 2.6739]], requires_grad=True)  |  Time needed: 0:00:09.172654  \n",
      "Run: 187\t| Iteration: 200 \t| Log-Likelihood:-3.1928460620212396 \t|  theta: tensor([[0.0501, 2.9051]], requires_grad=True)  |  Time needed: 0:00:09.167502  \n",
      "Run: 187\t| Iteration: 300 \t| Log-Likelihood:-3.187695714798836 \t|  theta: tensor([[0.0501, 2.9721]], requires_grad=True)  |  Time needed: 0:00:09.194829  \n",
      "Run: 187\t| Iteration: 400 \t| Log-Likelihood:-3.1872750444940405 \t|  theta: tensor([[0.0501, 2.9912]], requires_grad=True)  |  Time needed: 0:00:09.176171  \n",
      "Run: 187\t| Iteration: 500 \t| Log-Likelihood:-3.187240797367772 \t|  theta: tensor([[0.0501, 2.9967]], requires_grad=True)  |  Time needed: 0:00:09.170318  \n",
      "Run: 187\t| Iteration: 600 \t| Log-Likelihood:-3.187237996105088 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.193266  \n",
      "Run: 187\t| Iteration: 700 \t| Log-Likelihood:-3.187237787393204 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.276231  \n",
      "Run: 187\t| Iteration: 800 \t| Log-Likelihood:-3.1872377317235916 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.239271  \n",
      "Run: 187\t| Iteration: 900 \t| Log-Likelihood:-3.187237733951049 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.253273  \n",
      "Run: 188\t| Iteration: 0 \t| Log-Likelihood:-3.725675512740538 \t|  theta: tensor([[0.4460, 3.4108]], requires_grad=True)  |  Time needed: 0:00:00.092550  \n",
      "Run: 188\t| Iteration: 100 \t| Log-Likelihood:-3.196018809585248 \t|  theta: tensor([[0.0501, 3.1160]], requires_grad=True)  |  Time needed: 0:00:09.205524  \n",
      "Run: 188\t| Iteration: 200 \t| Log-Likelihood:-3.1879507302136254 \t|  theta: tensor([[0.0501, 3.0323]], requires_grad=True)  |  Time needed: 0:00:09.105607  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 188\t| Iteration: 300 \t| Log-Likelihood:-3.18729573692507 \t|  theta: tensor([[0.0501, 3.0084]], requires_grad=True)  |  Time needed: 0:00:09.137896  \n",
      "Run: 188\t| Iteration: 400 \t| Log-Likelihood:-3.1872424709002574 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.112336  \n",
      "Run: 188\t| Iteration: 500 \t| Log-Likelihood:-3.187238150723194 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.132381  \n",
      "Run: 188\t| Iteration: 600 \t| Log-Likelihood:-3.1872377650778683 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.136304  \n",
      "Run: 188\t| Iteration: 700 \t| Log-Likelihood:-3.1872377661606026 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.160364  \n",
      "Run: 188\t| Iteration: 800 \t| Log-Likelihood:-3.187237756396702 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.132836  \n",
      "Run: 188\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.135116  \n",
      "Run: 189\t| Iteration: 0 \t| Log-Likelihood:-3.6379556552146646 \t|  theta: tensor([[0.0833, 3.8274]], requires_grad=True)  |  Time needed: 0:00:00.090365  \n",
      "Run: 189\t| Iteration: 100 \t| Log-Likelihood:-3.222714418207773 \t|  theta: tensor([[0.0501, 3.2343]], requires_grad=True)  |  Time needed: 0:00:09.157620  \n",
      "Run: 189\t| Iteration: 200 \t| Log-Likelihood:-3.1901108862707868 \t|  theta: tensor([[0.0501, 3.0659]], requires_grad=True)  |  Time needed: 0:00:09.107796  \n",
      "Run: 189\t| Iteration: 300 \t| Log-Likelihood:-3.1874712295624046 \t|  theta: tensor([[0.0501, 3.0180]], requires_grad=True)  |  Time needed: 0:00:09.150646  \n",
      "Run: 189\t| Iteration: 400 \t| Log-Likelihood:-3.187256765438415 \t|  theta: tensor([[0.0501, 3.0043]], requires_grad=True)  |  Time needed: 0:00:09.220522  \n",
      "Run: 189\t| Iteration: 500 \t| Log-Likelihood:-3.1872392797504747 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.116319  \n",
      "Run: 189\t| Iteration: 600 \t| Log-Likelihood:-3.187237837413633 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.450074  \n",
      "Run: 189\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254139557 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.261922  \n",
      "Run: 189\t| Iteration: 800 \t| Log-Likelihood:-3.1872377607486975 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.407693  \n",
      "Run: 189\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.889447  \n",
      "Run: 190\t| Iteration: 0 \t| Log-Likelihood:-3.4060186984015584 \t|  theta: tensor([[0.2941, 3.1304]], requires_grad=True)  |  Time needed: 0:00:00.091907  \n",
      "Run: 190\t| Iteration: 100 \t| Log-Likelihood:-3.188134962450797 \t|  theta: tensor([[0.0501, 3.0363]], requires_grad=True)  |  Time needed: 0:00:09.127810  \n",
      "Run: 190\t| Iteration: 200 \t| Log-Likelihood:-3.1873106902417363 \t|  theta: tensor([[0.0501, 3.0096]], requires_grad=True)  |  Time needed: 0:00:09.122702  \n",
      "Run: 190\t| Iteration: 300 \t| Log-Likelihood:-3.1872436977123235 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.271517  \n",
      "Run: 190\t| Iteration: 400 \t| Log-Likelihood:-3.18723820917693 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.186616  \n",
      "Run: 190\t| Iteration: 500 \t| Log-Likelihood:-3.187237776778557 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.116629  \n",
      "Run: 190\t| Iteration: 600 \t| Log-Likelihood:-3.187237770531047 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.154376  \n",
      "Run: 190\t| Iteration: 700 \t| Log-Likelihood:-3.187237756452196 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.119435  \n",
      "Run: 190\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113547  \n",
      "Run: 190\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.164079  \n",
      "Run: 191\t| Iteration: 0 \t| Log-Likelihood:-3.2387530064029897 \t|  theta: tensor([[0.3692, 0.9735]], requires_grad=True)  |  Time needed: 0:00:00.088863  \n",
      "Run: 191\t| Iteration: 100 \t| Log-Likelihood:-3.190465259227482 \t|  theta: tensor([[0.4318, 1.0573]], requires_grad=True)  |  Time needed: 0:00:09.265907  \n",
      "Run: 191\t| Iteration: 200 \t| Log-Likelihood:-3.190462735058111 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.280350  \n",
      "Run: 191\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029300148 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.250759  \n",
      "Run: 191\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.261783  \n",
      "Run: 191\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.252818  \n",
      "Run: 191\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.459562  \n",
      "Run: 191\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.310943  \n",
      "Run: 191\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.250145  \n",
      "Run: 191\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.307424  \n",
      "Run: 192\t| Iteration: 0 \t| Log-Likelihood:-3.8244433733890215 \t|  theta: tensor([[0.2048, 0.7818]], requires_grad=True)  |  Time needed: 0:00:00.089714  \n",
      "Run: 192\t| Iteration: 100 \t| Log-Likelihood:-3.190487073655107 \t|  theta: tensor([[0.4294, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.151770  \n",
      "Run: 192\t| Iteration: 200 \t| Log-Likelihood:-3.1904627248469906 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144235  \n",
      "Run: 192\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029467263 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.126006  \n",
      "Run: 192\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113110  \n",
      "Run: 192\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.111405  \n",
      "Run: 192\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.139359  \n",
      "Run: 192\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.233528  \n",
      "Run: 192\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.141576  \n",
      "Run: 192\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.210903  \n",
      "Run: 193\t| Iteration: 0 \t| Log-Likelihood:-3.7548092216065116 \t|  theta: tensor([[0.4376, 2.4910]], requires_grad=True)  |  Time needed: 0:00:00.091882  \n",
      "Run: 193\t| Iteration: 100 \t| Log-Likelihood:-3.2018390738300218 \t|  theta: tensor([[0.0502, 2.8475]], requires_grad=True)  |  Time needed: 0:00:09.103001  \n",
      "Run: 193\t| Iteration: 200 \t| Log-Likelihood:-3.1884357317184935 \t|  theta: tensor([[0.0501, 2.9556]], requires_grad=True)  |  Time needed: 0:00:09.591173  \n",
      "Run: 193\t| Iteration: 300 \t| Log-Likelihood:-3.187335330520731 \t|  theta: tensor([[0.0501, 2.9865]], requires_grad=True)  |  Time needed: 0:00:09.135169  \n",
      "Run: 193\t| Iteration: 400 \t| Log-Likelihood:-3.1872456970079575 \t|  theta: tensor([[0.0501, 2.9954]], requires_grad=True)  |  Time needed: 0:00:09.122678  \n",
      "Run: 193\t| Iteration: 500 \t| Log-Likelihood:-3.187238386187097 \t|  theta: tensor([[0.0501, 2.9979]], requires_grad=True)  |  Time needed: 0:00:09.201980  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 193\t| Iteration: 600 \t| Log-Likelihood:-3.1872378011360105 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.200172  \n",
      "Run: 193\t| Iteration: 700 \t| Log-Likelihood:-3.1872377269059147 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.133891  \n",
      "Run: 193\t| Iteration: 800 \t| Log-Likelihood:-3.1872377341758487 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.137235  \n",
      "Run: 193\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.124545  \n",
      "Run: 194\t| Iteration: 0 \t| Log-Likelihood:-3.700643347651509 \t|  theta: tensor([[0.5692, 0.7478]], requires_grad=True)  |  Time needed: 0:00:00.092451  \n",
      "Run: 194\t| Iteration: 100 \t| Log-Likelihood:-3.1905233323374826 \t|  theta: tensor([[0.4385, 1.0555]], requires_grad=True)  |  Time needed: 0:00:09.166981  \n",
      "Run: 194\t| Iteration: 200 \t| Log-Likelihood:-3.190462757826378 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.213075  \n",
      "Run: 194\t| Iteration: 300 \t| Log-Likelihood:-3.190462732778976 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.207254  \n",
      "Run: 194\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.145816  \n",
      "Run: 194\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.143324  \n",
      "Run: 194\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.148577  \n",
      "Run: 194\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.141019  \n",
      "Run: 194\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.183518  \n",
      "Run: 194\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.158316  \n",
      "Run: 195\t| Iteration: 0 \t| Log-Likelihood:-3.3228982014071953 \t|  theta: tensor([[0.2191, 1.0273]], requires_grad=True)  |  Time needed: 0:00:00.090123  \n",
      "Run: 195\t| Iteration: 100 \t| Log-Likelihood:-3.190508146569489 \t|  theta: tensor([[0.4282, 1.0583]], requires_grad=True)  |  Time needed: 0:00:09.197363  \n",
      "Run: 195\t| Iteration: 200 \t| Log-Likelihood:-3.1904627436620556 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.879663  \n",
      "Run: 195\t| Iteration: 300 \t| Log-Likelihood:-3.190462673161242 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.469494  \n",
      "Run: 195\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.109839  \n",
      "Run: 195\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.174310  \n",
      "Run: 195\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.756579  \n",
      "Run: 195\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.870716  \n",
      "Run: 195\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.912044  \n",
      "Run: 195\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.010159  \n",
      "Run: 196\t| Iteration: 0 \t| Log-Likelihood:-3.458338285176262 \t|  theta: tensor([[0.3047, 2.7152]], requires_grad=True)  |  Time needed: 0:00:00.090307  \n",
      "Run: 196\t| Iteration: 100 \t| Log-Likelihood:-3.191521172229754 \t|  theta: tensor([[0.0501, 2.9170]], requires_grad=True)  |  Time needed: 0:00:09.337943  \n",
      "Run: 196\t| Iteration: 200 \t| Log-Likelihood:-3.187587240873914 \t|  theta: tensor([[0.0501, 2.9755]], requires_grad=True)  |  Time needed: 0:00:09.284883  \n",
      "Run: 196\t| Iteration: 300 \t| Log-Likelihood:-3.18726621750429 \t|  theta: tensor([[0.0501, 2.9922]], requires_grad=True)  |  Time needed: 0:00:09.275899  \n",
      "Run: 196\t| Iteration: 400 \t| Log-Likelihood:-3.187240067525368 \t|  theta: tensor([[0.0501, 2.9970]], requires_grad=True)  |  Time needed: 0:00:09.301984  \n",
      "Run: 196\t| Iteration: 500 \t| Log-Likelihood:-3.187237952254369 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.283889  \n",
      "Run: 196\t| Iteration: 600 \t| Log-Likelihood:-3.1872377267680503 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.299773  \n",
      "Run: 196\t| Iteration: 700 \t| Log-Likelihood:-3.187237731337146 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.457757  \n",
      "Run: 196\t| Iteration: 800 \t| Log-Likelihood:-3.1872377376303627 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.730245  \n",
      "Run: 196\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.330940  \n",
      "Run: 197\t| Iteration: 0 \t| Log-Likelihood:-3.670264204200304 \t|  theta: tensor([[0.4003, 1.5206]], requires_grad=True)  |  Time needed: 0:00:00.087677  \n",
      "Run: 197\t| Iteration: 100 \t| Log-Likelihood:-3.190627994289806 \t|  theta: tensor([[0.4240, 1.0600]], requires_grad=True)  |  Time needed: 0:00:09.199312  \n",
      "Run: 197\t| Iteration: 200 \t| Log-Likelihood:-3.1904628496872687 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.173573  \n",
      "Run: 197\t| Iteration: 300 \t| Log-Likelihood:-3.190462703058638 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.170150  \n",
      "Run: 197\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.223285  \n",
      "Run: 197\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.173230  \n",
      "Run: 197\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.229351  \n",
      "Run: 197\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.180220  \n",
      "Run: 197\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.175446  \n",
      "Run: 197\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.195204  \n",
      "Run: 198\t| Iteration: 0 \t| Log-Likelihood:-5.562725018594687 \t|  theta: tensor([[0.5801, 0.4201]], requires_grad=True)  |  Time needed: 0:00:00.093391  \n",
      "Run: 198\t| Iteration: 100 \t| Log-Likelihood:-3.1905678862683957 \t|  theta: tensor([[0.4402, 1.0550]], requires_grad=True)  |  Time needed: 0:00:09.176919  \n",
      "Run: 198\t| Iteration: 200 \t| Log-Likelihood:-3.1904627983316436 \t|  theta: tensor([[0.4332, 1.0569]], requires_grad=True)  |  Time needed: 0:00:09.143681  \n",
      "Run: 198\t| Iteration: 300 \t| Log-Likelihood:-3.190462732815214 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093337  \n",
      "Run: 198\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137221  \n",
      "Run: 198\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128438  \n",
      "Run: 198\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.134136  \n",
      "Run: 198\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.279632  \n",
      "Run: 198\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.171255  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 198\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128425  \n",
      "Run: 199\t| Iteration: 0 \t| Log-Likelihood:-4.344804256449571 \t|  theta: tensor([[0.0360, 4.3378]], requires_grad=True)  |  Time needed: 0:00:00.094772  \n",
      "Run: 199\t| Iteration: 100 \t| Log-Likelihood:-3.279818812252899 \t|  theta: tensor([[0.0501, 3.3790]], requires_grad=True)  |  Time needed: 0:00:09.126845  \n",
      "Run: 199\t| Iteration: 200 \t| Log-Likelihood:-3.1947195169290485 \t|  theta: tensor([[0.0501, 3.1070]], requires_grad=True)  |  Time needed: 0:00:09.222421  \n",
      "Run: 199\t| Iteration: 300 \t| Log-Likelihood:-3.187845366342975 \t|  theta: tensor([[0.0501, 3.0297]], requires_grad=True)  |  Time needed: 0:00:09.128441  \n",
      "Run: 199\t| Iteration: 400 \t| Log-Likelihood:-3.187287175341199 \t|  theta: tensor([[0.0501, 3.0077]], requires_grad=True)  |  Time needed: 0:00:09.191990  \n",
      "Run: 199\t| Iteration: 500 \t| Log-Likelihood:-3.187241742446255 \t|  theta: tensor([[0.0501, 3.0014]], requires_grad=True)  |  Time needed: 0:00:09.177062  \n",
      "Run: 199\t| Iteration: 600 \t| Log-Likelihood:-3.187238083702218 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.148748  \n",
      "Run: 199\t| Iteration: 700 \t| Log-Likelihood:-3.187237756681406 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.131278  \n",
      "Run: 199\t| Iteration: 800 \t| Log-Likelihood:-3.187237765811875 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.134003  \n",
      "Run: 199\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563575083 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108650  \n",
      "Run: 200\t| Iteration: 0 \t| Log-Likelihood:-3.235503777317572 \t|  theta: tensor([[0.5803, 1.0107]], requires_grad=True)  |  Time needed: 0:00:00.092931  \n",
      "Run: 200\t| Iteration: 100 \t| Log-Likelihood:-3.19050270523666 \t|  theta: tensor([[0.4374, 1.0558]], requires_grad=True)  |  Time needed: 0:00:09.144767  \n",
      "Run: 200\t| Iteration: 200 \t| Log-Likelihood:-3.190462739122004 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.145025  \n",
      "Run: 200\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029592127 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.315787  \n",
      "Run: 200\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.434966  \n",
      "Run: 200\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.128744  \n",
      "Run: 200\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.173172  \n",
      "Run: 200\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.149434  \n",
      "Run: 200\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.192951  \n",
      "Run: 200\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.130224  \n",
      "Run: 201\t| Iteration: 0 \t| Log-Likelihood:-3.568829734159221 \t|  theta: tensor([[0.1797, 3.6808]], requires_grad=True)  |  Time needed: 0:00:00.096273  \n",
      "Run: 201\t| Iteration: 100 \t| Log-Likelihood:-3.211279192016455 \t|  theta: tensor([[0.0501, 3.1927]], requires_grad=True)  |  Time needed: 0:00:09.259320  \n",
      "Run: 201\t| Iteration: 200 \t| Log-Likelihood:-3.1891864435143873 \t|  theta: tensor([[0.0501, 3.0541]], requires_grad=True)  |  Time needed: 0:00:09.258129  \n",
      "Run: 201\t| Iteration: 300 \t| Log-Likelihood:-3.187396155440164 \t|  theta: tensor([[0.0501, 3.0146]], requires_grad=True)  |  Time needed: 0:00:09.339240  \n",
      "Run: 201\t| Iteration: 400 \t| Log-Likelihood:-3.1872505969911775 \t|  theta: tensor([[0.0501, 3.0034]], requires_grad=True)  |  Time needed: 0:00:09.255591  \n",
      "Run: 201\t| Iteration: 500 \t| Log-Likelihood:-3.187238785480327 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.262684  \n",
      "Run: 201\t| Iteration: 600 \t| Log-Likelihood:-3.18723784122416 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.272765  \n",
      "Run: 201\t| Iteration: 700 \t| Log-Likelihood:-3.1872377779946244 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.253801  \n",
      "Run: 201\t| Iteration: 800 \t| Log-Likelihood:-3.18723776043893 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.273246  \n",
      "Run: 201\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.287338  \n",
      "Run: 202\t| Iteration: 0 \t| Log-Likelihood:-3.4825145976753764 \t|  theta: tensor([[0.2736, 3.4177]], requires_grad=True)  |  Time needed: 0:00:00.086684  \n",
      "Run: 202\t| Iteration: 100 \t| Log-Likelihood:-3.1963147824179847 \t|  theta: tensor([[0.0501, 3.1180]], requires_grad=True)  |  Time needed: 0:00:09.224587  \n",
      "Run: 202\t| Iteration: 200 \t| Log-Likelihood:-3.187974728576072 \t|  theta: tensor([[0.0501, 3.0328]], requires_grad=True)  |  Time needed: 0:00:09.116947  \n",
      "Run: 202\t| Iteration: 300 \t| Log-Likelihood:-3.187297651536998 \t|  theta: tensor([[0.0501, 3.0086]], requires_grad=True)  |  Time needed: 0:00:09.140771  \n",
      "Run: 202\t| Iteration: 400 \t| Log-Likelihood:-3.187242634943138 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.119830  \n",
      "Run: 202\t| Iteration: 500 \t| Log-Likelihood:-3.187238167376155 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.246383  \n",
      "Run: 202\t| Iteration: 600 \t| Log-Likelihood:-3.187237766084467 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.169573  \n",
      "Run: 202\t| Iteration: 700 \t| Log-Likelihood:-3.1872377662372786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.150246  \n",
      "Run: 202\t| Iteration: 800 \t| Log-Likelihood:-3.1872377564025847 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.107536  \n",
      "Run: 202\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.150843  \n",
      "Run: 203\t| Iteration: 0 \t| Log-Likelihood:-3.2144040448963733 \t|  theta: tensor([[0.3383, 1.1116]], requires_grad=True)  |  Time needed: 0:00:00.095619  \n",
      "Run: 203\t| Iteration: 100 \t| Log-Likelihood:-3.1904802072770018 \t|  theta: tensor([[0.4300, 1.0578]], requires_grad=True)  |  Time needed: 0:00:09.100293  \n",
      "Run: 203\t| Iteration: 200 \t| Log-Likelihood:-3.1904627484211447 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.148709  \n",
      "Run: 203\t| Iteration: 300 \t| Log-Likelihood:-3.190462702941835 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.148747  \n",
      "Run: 203\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.177331  \n",
      "Run: 203\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110939  \n",
      "Run: 203\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113221  \n",
      "Run: 203\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150808  \n",
      "Run: 203\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103551  \n",
      "Run: 203\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.498085  \n",
      "Run: 204\t| Iteration: 0 \t| Log-Likelihood:-3.264539244715087 \t|  theta: tensor([[0.5522, 1.1447]], requires_grad=True)  |  Time needed: 0:00:00.094557  \n",
      "Run: 204\t| Iteration: 100 \t| Log-Likelihood:-3.190477555870817 \t|  theta: tensor([[0.4357, 1.0563]], requires_grad=True)  |  Time needed: 0:00:09.139116  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 204\t| Iteration: 200 \t| Log-Likelihood:-3.1904626865548553 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135407  \n",
      "Run: 204\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731372114 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116436  \n",
      "Run: 204\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.141721  \n",
      "Run: 204\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.131596  \n",
      "Run: 204\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.180870  \n",
      "Run: 204\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.210311  \n",
      "Run: 204\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129191  \n",
      "Run: 204\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.157164  \n",
      "Run: 205\t| Iteration: 0 \t| Log-Likelihood:-3.3017060745179942 \t|  theta: tensor([[0.1542, 3.2888]], requires_grad=True)  |  Time needed: 0:00:00.091494  \n",
      "Run: 205\t| Iteration: 100 \t| Log-Likelihood:-3.191593326865686 \t|  theta: tensor([[0.0501, 3.0814]], requires_grad=True)  |  Time needed: 0:00:09.269000  \n",
      "Run: 205\t| Iteration: 200 \t| Log-Likelihood:-3.1875916109788465 \t|  theta: tensor([[0.0501, 3.0224]], requires_grad=True)  |  Time needed: 0:00:09.143364  \n",
      "Run: 205\t| Iteration: 300 \t| Log-Likelihood:-3.187266544839626 \t|  theta: tensor([[0.0501, 3.0056]], requires_grad=True)  |  Time needed: 0:00:09.075760  \n",
      "Run: 205\t| Iteration: 400 \t| Log-Likelihood:-3.187240080274141 \t|  theta: tensor([[0.0501, 3.0008]], requires_grad=True)  |  Time needed: 0:00:09.068948  \n",
      "Run: 205\t| Iteration: 500 \t| Log-Likelihood:-3.1872379205360786 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.328854  \n",
      "Run: 205\t| Iteration: 600 \t| Log-Likelihood:-3.1872377381792516 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.059692  \n",
      "Run: 205\t| Iteration: 700 \t| Log-Likelihood:-3.187237761153279 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.082452  \n",
      "Run: 205\t| Iteration: 800 \t| Log-Likelihood:-3.1872377562607603 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.190647  \n",
      "Run: 205\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.174917  \n",
      "Run: 206\t| Iteration: 0 \t| Log-Likelihood:-3.9524101253616313 \t|  theta: tensor([[0.4573, 2.2016]], requires_grad=True)  |  Time needed: 0:00:00.090379  \n",
      "Run: 206\t| Iteration: 100 \t| Log-Likelihood:-3.2322432345644208 \t|  theta: tensor([[0.0504, 2.7324]], requires_grad=True)  |  Time needed: 0:00:09.334207  \n",
      "Run: 206\t| Iteration: 200 \t| Log-Likelihood:-3.190985606702922 \t|  theta: tensor([[0.0501, 2.9223]], requires_grad=True)  |  Time needed: 0:00:09.320012  \n",
      "Run: 206\t| Iteration: 300 \t| Log-Likelihood:-3.187543461195058 \t|  theta: tensor([[0.0501, 2.9770]], requires_grad=True)  |  Time needed: 0:00:09.281014  \n",
      "Run: 206\t| Iteration: 400 \t| Log-Likelihood:-3.187262605446431 \t|  theta: tensor([[0.0501, 2.9926]], requires_grad=True)  |  Time needed: 0:00:09.309530  \n",
      "Run: 206\t| Iteration: 500 \t| Log-Likelihood:-3.1872397941297055 \t|  theta: tensor([[0.0501, 2.9971]], requires_grad=True)  |  Time needed: 0:00:09.354702  \n",
      "Run: 206\t| Iteration: 600 \t| Log-Likelihood:-3.1872379356700584 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.300214  \n",
      "Run: 206\t| Iteration: 700 \t| Log-Likelihood:-3.187237724917424 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.295352  \n",
      "Run: 206\t| Iteration: 800 \t| Log-Likelihood:-3.187237731207128 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.296564  \n",
      "Run: 206\t| Iteration: 900 \t| Log-Likelihood:-3.187237737612299 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.273286  \n",
      "Run: 207\t| Iteration: 0 \t| Log-Likelihood:-3.551647425783056 \t|  theta: tensor([[0.3540, 1.4466]], requires_grad=True)  |  Time needed: 0:00:00.112822  \n",
      "Run: 207\t| Iteration: 100 \t| Log-Likelihood:-3.1905899821821553 \t|  theta: tensor([[0.4250, 1.0595]], requires_grad=True)  |  Time needed: 0:00:09.460955  \n",
      "Run: 207\t| Iteration: 200 \t| Log-Likelihood:-3.1904628163283624 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.206992  \n",
      "Run: 207\t| Iteration: 300 \t| Log-Likelihood:-3.190462673225397 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.200452  \n",
      "Run: 207\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.242760  \n",
      "Run: 207\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.597428  \n",
      "Run: 207\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.168974  \n",
      "Run: 207\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.133841  \n",
      "Run: 207\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.156562  \n",
      "Run: 207\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.218969  \n",
      "Run: 208\t| Iteration: 0 \t| Log-Likelihood:-3.6904902828858486 \t|  theta: tensor([[0.4412, 3.3560]], requires_grad=True)  |  Time needed: 0:00:00.090449  \n",
      "Run: 208\t| Iteration: 100 \t| Log-Likelihood:-3.193840617751344 \t|  theta: tensor([[0.0501, 3.1005]], requires_grad=True)  |  Time needed: 0:00:09.110676  \n",
      "Run: 208\t| Iteration: 200 \t| Log-Likelihood:-3.1877740433287713 \t|  theta: tensor([[0.0501, 3.0278]], requires_grad=True)  |  Time needed: 0:00:09.094459  \n",
      "Run: 208\t| Iteration: 300 \t| Log-Likelihood:-3.1872813394502977 \t|  theta: tensor([[0.0501, 3.0071]], requires_grad=True)  |  Time needed: 0:00:09.092134  \n",
      "Run: 208\t| Iteration: 400 \t| Log-Likelihood:-3.1872413038724736 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.091899  \n",
      "Run: 208\t| Iteration: 500 \t| Log-Likelihood:-3.1872380376050446 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.169064  \n",
      "Run: 208\t| Iteration: 600 \t| Log-Likelihood:-3.187237749801322 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.151390  \n",
      "Run: 208\t| Iteration: 700 \t| Log-Likelihood:-3.187237765554633 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108512  \n",
      "Run: 208\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563316383 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.143777  \n",
      "Run: 208\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.191639  \n",
      "Run: 209\t| Iteration: 0 \t| Log-Likelihood:-5.691890800772943 \t|  theta: tensor([[0.3567, 0.4251]], requires_grad=True)  |  Time needed: 0:00:00.091638  \n",
      "Run: 209\t| Iteration: 100 \t| Log-Likelihood:-3.1904651739186676 \t|  theta: tensor([[0.4340, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.277378  \n",
      "Run: 209\t| Iteration: 200 \t| Log-Likelihood:-3.1904627051163685 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.191238  \n",
      "Run: 209\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029300565 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093865  \n",
      "Run: 209\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093221  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 209\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113254  \n",
      "Run: 209\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102526  \n",
      "Run: 209\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093938  \n",
      "Run: 209\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.170022  \n",
      "Run: 209\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.202427  \n",
      "Run: 210\t| Iteration: 0 \t| Log-Likelihood:-3.509885232367545 \t|  theta: tensor([[0.2770, 3.4591]], requires_grad=True)  |  Time needed: 0:00:00.090482  \n",
      "Run: 210\t| Iteration: 100 \t| Log-Likelihood:-3.198196270594103 \t|  theta: tensor([[0.0501, 3.1298]], requires_grad=True)  |  Time needed: 0:00:09.153694  \n",
      "Run: 210\t| Iteration: 200 \t| Log-Likelihood:-3.1881272533751295 \t|  theta: tensor([[0.0501, 3.0362]], requires_grad=True)  |  Time needed: 0:00:09.114929  \n",
      "Run: 210\t| Iteration: 300 \t| Log-Likelihood:-3.1873100474533076 \t|  theta: tensor([[0.0501, 3.0095]], requires_grad=True)  |  Time needed: 0:00:09.078953  \n",
      "Run: 210\t| Iteration: 400 \t| Log-Likelihood:-3.187243643655169 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.144041  \n",
      "Run: 210\t| Iteration: 500 \t| Log-Likelihood:-3.1872382004942885 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.138238  \n",
      "Run: 210\t| Iteration: 600 \t| Log-Likelihood:-3.187237776406531 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.122811  \n",
      "Run: 210\t| Iteration: 700 \t| Log-Likelihood:-3.1872377705097876 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.096254  \n",
      "Run: 210\t| Iteration: 800 \t| Log-Likelihood:-3.1872377564457466 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.126496  \n",
      "Run: 210\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.126677  \n",
      "Run: 211\t| Iteration: 0 \t| Log-Likelihood:-3.6820928797444856 \t|  theta: tensor([[0.2701, 2.2274]], requires_grad=True)  |  Time needed: 0:00:00.090614  \n",
      "Run: 211\t| Iteration: 100 \t| Log-Likelihood:-3.2261717488438304 \t|  theta: tensor([[0.0503, 2.7511]], requires_grad=True)  |  Time needed: 0:00:09.721916  \n",
      "Run: 211\t| Iteration: 200 \t| Log-Likelihood:-3.1904706452783804 \t|  theta: tensor([[0.0501, 2.9277]], requires_grad=True)  |  Time needed: 0:00:09.386261  \n",
      "Run: 211\t| Iteration: 300 \t| Log-Likelihood:-3.1875014069103047 \t|  theta: tensor([[0.0501, 2.9786]], requires_grad=True)  |  Time needed: 0:00:09.284467  \n",
      "Run: 211\t| Iteration: 400 \t| Log-Likelihood:-3.1872592092581202 \t|  theta: tensor([[0.0501, 2.9931]], requires_grad=True)  |  Time needed: 0:00:09.307631  \n",
      "Run: 211\t| Iteration: 500 \t| Log-Likelihood:-3.1872394832818993 \t|  theta: tensor([[0.0501, 2.9972]], requires_grad=True)  |  Time needed: 0:00:09.288089  \n",
      "Run: 211\t| Iteration: 600 \t| Log-Likelihood:-3.187237857251034 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.289080  \n",
      "Run: 211\t| Iteration: 700 \t| Log-Likelihood:-3.187237726789184 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.316092  \n",
      "Run: 211\t| Iteration: 800 \t| Log-Likelihood:-3.1872377310604585 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.358118  \n",
      "Run: 211\t| Iteration: 900 \t| Log-Likelihood:-3.1872377375929597 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.286240  \n",
      "Run: 212\t| Iteration: 0 \t| Log-Likelihood:-3.2696696630690516 \t|  theta: tensor([[0.1778, 2.9642]], requires_grad=True)  |  Time needed: 0:00:00.100814  \n",
      "Run: 212\t| Iteration: 100 \t| Log-Likelihood:-3.1873003197608263 \t|  theta: tensor([[0.0501, 2.9890]], requires_grad=True)  |  Time needed: 0:00:09.890218  \n",
      "Run: 212\t| Iteration: 200 \t| Log-Likelihood:-3.1872428044097485 \t|  theta: tensor([[0.0501, 2.9961]], requires_grad=True)  |  Time needed: 0:00:09.234867  \n",
      "Run: 212\t| Iteration: 300 \t| Log-Likelihood:-3.187238133184442 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.125853  \n",
      "Run: 212\t| Iteration: 400 \t| Log-Likelihood:-3.187237789869979 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.166519  \n",
      "Run: 212\t| Iteration: 500 \t| Log-Likelihood:-3.1872377290812 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.290396  \n",
      "Run: 212\t| Iteration: 600 \t| Log-Likelihood:-3.187237734062632 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.129400  \n",
      "Run: 212\t| Iteration: 700 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.297677  \n",
      "Run: 212\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.141650  \n",
      "Run: 212\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.119498  \n",
      "Run: 213\t| Iteration: 0 \t| Log-Likelihood:-3.9582498596173767 \t|  theta: tensor([[0.5754, 2.6404]], requires_grad=True)  |  Time needed: 0:00:00.092183  \n",
      "Run: 213\t| Iteration: 100 \t| Log-Likelihood:-3.1942394372491187 \t|  theta: tensor([[0.0501, 2.8941]], requires_grad=True)  |  Time needed: 0:00:09.168663  \n",
      "Run: 213\t| Iteration: 200 \t| Log-Likelihood:-3.1878099436498344 \t|  theta: tensor([[0.0501, 2.9690]], requires_grad=True)  |  Time needed: 0:00:09.119354  \n",
      "Run: 213\t| Iteration: 300 \t| Log-Likelihood:-3.1872843038701313 \t|  theta: tensor([[0.0501, 2.9903]], requires_grad=True)  |  Time needed: 0:00:09.075028  \n",
      "Run: 213\t| Iteration: 400 \t| Log-Likelihood:-3.1872415072684968 \t|  theta: tensor([[0.0501, 2.9964]], requires_grad=True)  |  Time needed: 0:00:09.125060  \n",
      "Run: 213\t| Iteration: 500 \t| Log-Likelihood:-3.187238045753541 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.088496  \n",
      "Run: 213\t| Iteration: 600 \t| Log-Likelihood:-3.187237788694185 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.129054  \n",
      "Run: 213\t| Iteration: 700 \t| Log-Likelihood:-3.1872377284364046 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.132532  \n",
      "Run: 213\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339950435 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.199870  \n",
      "Run: 213\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.116652  \n",
      "Run: 214\t| Iteration: 0 \t| Log-Likelihood:-4.250495741371082 \t|  theta: tensor([[0.5555, 3.8052]], requires_grad=True)  |  Time needed: 0:00:00.097047  \n",
      "Run: 214\t| Iteration: 100 \t| Log-Likelihood:-3.220836977037592 \t|  theta: tensor([[0.0501, 3.2280]], requires_grad=True)  |  Time needed: 0:00:09.151633  \n",
      "Run: 214\t| Iteration: 200 \t| Log-Likelihood:-3.189959262092844 \t|  theta: tensor([[0.0501, 3.0641]], requires_grad=True)  |  Time needed: 0:00:09.127342  \n",
      "Run: 214\t| Iteration: 300 \t| Log-Likelihood:-3.187458949016577 \t|  theta: tensor([[0.0501, 3.0175]], requires_grad=True)  |  Time needed: 0:00:09.145603  \n",
      "Run: 214\t| Iteration: 400 \t| Log-Likelihood:-3.1872557410327866 \t|  theta: tensor([[0.0501, 3.0042]], requires_grad=True)  |  Time needed: 0:00:09.131640  \n",
      "Run: 214\t| Iteration: 500 \t| Log-Likelihood:-3.1872391905598056 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.151041  \n",
      "Run: 214\t| Iteration: 600 \t| Log-Likelihood:-3.1872378864410744 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.147734  \n",
      "Run: 214\t| Iteration: 700 \t| Log-Likelihood:-3.1872377248876553 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.611207  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 214\t| Iteration: 800 \t| Log-Likelihood:-3.187237760704901 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.180148  \n",
      "Run: 214\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.149803  \n",
      "Run: 215\t| Iteration: 0 \t| Log-Likelihood:-3.3825814568688415 \t|  theta: tensor([[0.3159, 1.3146]], requires_grad=True)  |  Time needed: 0:00:00.092668  \n",
      "Run: 215\t| Iteration: 100 \t| Log-Likelihood:-3.190535657044936 \t|  theta: tensor([[0.4269, 1.0588]], requires_grad=True)  |  Time needed: 0:00:09.176610  \n",
      "Run: 215\t| Iteration: 200 \t| Log-Likelihood:-3.1904627980577134 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113671  \n",
      "Run: 215\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029841746 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.111521  \n",
      "Run: 215\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.160745  \n",
      "Run: 215\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.237499  \n",
      "Run: 215\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.081551  \n",
      "Run: 215\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.114956  \n",
      "Run: 215\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093414  \n",
      "Run: 215\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110553  \n",
      "Run: 216\t| Iteration: 0 \t| Log-Likelihood:-4.627949081829141 \t|  theta: tensor([[0.3281, 4.3604]], requires_grad=True)  |  Time needed: 0:00:00.091374  \n",
      "Run: 216\t| Iteration: 100 \t| Log-Likelihood:-3.28297689866363 \t|  theta: tensor([[0.0501, 3.3855]], requires_grad=True)  |  Time needed: 0:00:09.291776  \n",
      "Run: 216\t| Iteration: 200 \t| Log-Likelihood:-3.194974170182921 \t|  theta: tensor([[0.0501, 3.1089]], requires_grad=True)  |  Time needed: 0:00:09.294423  \n",
      "Run: 216\t| Iteration: 300 \t| Log-Likelihood:-3.1878659872284847 \t|  theta: tensor([[0.0501, 3.0302]], requires_grad=True)  |  Time needed: 0:00:09.466392  \n",
      "Run: 216\t| Iteration: 400 \t| Log-Likelihood:-3.1872888193860716 \t|  theta: tensor([[0.0501, 3.0078]], requires_grad=True)  |  Time needed: 0:00:09.404628  \n",
      "Run: 216\t| Iteration: 500 \t| Log-Likelihood:-3.1872418876753077 \t|  theta: tensor([[0.0501, 3.0014]], requires_grad=True)  |  Time needed: 0:00:09.299184  \n",
      "Run: 216\t| Iteration: 600 \t| Log-Likelihood:-3.1872380982888466 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.340802  \n",
      "Run: 216\t| Iteration: 700 \t| Log-Likelihood:-3.187237757672912 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.313589  \n",
      "Run: 216\t| Iteration: 800 \t| Log-Likelihood:-3.1872377658831654 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.340175  \n",
      "Run: 216\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563683525 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.386106  \n",
      "Run: 217\t| Iteration: 0 \t| Log-Likelihood:-3.478038467138346 \t|  theta: tensor([[0.3543, 2.9224]], requires_grad=True)  |  Time needed: 0:00:00.092904  \n",
      "Run: 217\t| Iteration: 100 \t| Log-Likelihood:-3.187544361760985 \t|  theta: tensor([[0.0501, 2.9770]], requires_grad=True)  |  Time needed: 0:00:09.141377  \n",
      "Run: 217\t| Iteration: 200 \t| Log-Likelihood:-3.1872626862574753 \t|  theta: tensor([[0.0501, 2.9926]], requires_grad=True)  |  Time needed: 0:00:09.197898  \n",
      "Run: 217\t| Iteration: 300 \t| Log-Likelihood:-3.187239802169434 \t|  theta: tensor([[0.0501, 2.9971]], requires_grad=True)  |  Time needed: 0:00:09.179408  \n",
      "Run: 217\t| Iteration: 400 \t| Log-Likelihood:-3.1872379328624776 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.157528  \n",
      "Run: 217\t| Iteration: 500 \t| Log-Likelihood:-3.187237724917424 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.141184  \n",
      "Run: 217\t| Iteration: 600 \t| Log-Likelihood:-3.187237731207128 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.190470  \n",
      "Run: 217\t| Iteration: 700 \t| Log-Likelihood:-3.187237737612299 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.261814  \n",
      "Run: 217\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.133814  \n",
      "Run: 217\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.171077  \n",
      "Run: 218\t| Iteration: 0 \t| Log-Likelihood:-3.412499566780692 \t|  theta: tensor([[0.1999, 2.5514]], requires_grad=True)  |  Time needed: 0:00:00.092681  \n",
      "Run: 218\t| Iteration: 100 \t| Log-Likelihood:-3.198172414358139 \t|  theta: tensor([[0.0502, 2.8679]], requires_grad=True)  |  Time needed: 0:00:09.116171  \n",
      "Run: 218\t| Iteration: 200 \t| Log-Likelihood:-3.1881332418795556 \t|  theta: tensor([[0.0501, 2.9614]], requires_grad=True)  |  Time needed: 0:00:09.218780  \n",
      "Run: 218\t| Iteration: 300 \t| Log-Likelihood:-3.1873106332099 \t|  theta: tensor([[0.0501, 2.9882]], requires_grad=True)  |  Time needed: 0:00:09.601456  \n",
      "Run: 218\t| Iteration: 400 \t| Log-Likelihood:-3.1872436583699217 \t|  theta: tensor([[0.0501, 2.9958]], requires_grad=True)  |  Time needed: 0:00:09.146934  \n",
      "Run: 218\t| Iteration: 500 \t| Log-Likelihood:-3.1872382498801555 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.127358  \n",
      "Run: 218\t| Iteration: 600 \t| Log-Likelihood:-3.187237795402561 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.144567  \n",
      "Run: 218\t| Iteration: 700 \t| Log-Likelihood:-3.187237729552187 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.223566  \n",
      "Run: 218\t| Iteration: 800 \t| Log-Likelihood:-3.1872377341002522 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.119565  \n",
      "Run: 218\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.414100  \n",
      "Run: 219\t| Iteration: 0 \t| Log-Likelihood:-5.3460682767268395 \t|  theta: tensor([[0.1627, 0.5205]], requires_grad=True)  |  Time needed: 0:00:00.092077  \n",
      "Run: 219\t| Iteration: 100 \t| Log-Likelihood:-3.1904801973830508 \t|  theta: tensor([[0.4299, 1.0577]], requires_grad=True)  |  Time needed: 0:00:09.150641  \n",
      "Run: 219\t| Iteration: 200 \t| Log-Likelihood:-3.190462688795776 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.151738  \n",
      "Run: 219\t| Iteration: 300 \t| Log-Likelihood:-3.190462673139355 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129142  \n",
      "Run: 219\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123239  \n",
      "Run: 219\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.180283  \n",
      "Run: 219\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117657  \n",
      "Run: 219\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099055  \n",
      "Run: 219\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093780  \n",
      "Run: 219\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.236730  \n",
      "Run: 220\t| Iteration: 0 \t| Log-Likelihood:-3.7580856568262426 \t|  theta: tensor([[0.2438, 2.0228]], requires_grad=True)  |  Time needed: 0:00:00.093878  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 220\t| Iteration: 100 \t| Log-Likelihood:-3.273566704395381 \t|  theta: tensor([[0.0508, 2.6283]], requires_grad=True)  |  Time needed: 0:00:09.128011  \n",
      "Run: 220\t| Iteration: 200 \t| Log-Likelihood:-3.19457730849924 \t|  theta: tensor([[0.0501, 2.8916]], requires_grad=True)  |  Time needed: 0:00:09.164733  \n",
      "Run: 220\t| Iteration: 300 \t| Log-Likelihood:-3.1878376452054265 \t|  theta: tensor([[0.0501, 2.9682]], requires_grad=True)  |  Time needed: 0:00:09.264890  \n",
      "Run: 220\t| Iteration: 400 \t| Log-Likelihood:-3.1872865700933186 \t|  theta: tensor([[0.0501, 2.9901]], requires_grad=True)  |  Time needed: 0:00:09.108796  \n",
      "Run: 220\t| Iteration: 500 \t| Log-Likelihood:-3.1872417425923976 \t|  theta: tensor([[0.0501, 2.9964]], requires_grad=True)  |  Time needed: 0:00:09.144154  \n",
      "Run: 220\t| Iteration: 600 \t| Log-Likelihood:-3.1872380572600534 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.121196  \n",
      "Run: 220\t| Iteration: 700 \t| Log-Likelihood:-3.187237789900922 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.115750  \n",
      "Run: 220\t| Iteration: 800 \t| Log-Likelihood:-3.1872377285232036 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.133472  \n",
      "Run: 220\t| Iteration: 900 \t| Log-Likelihood:-3.1872377340056004 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.183443  \n",
      "Run: 221\t| Iteration: 0 \t| Log-Likelihood:-3.484011981270601 \t|  theta: tensor([[0.2155, 3.5261]], requires_grad=True)  |  Time needed: 0:00:00.090175  \n",
      "Run: 221\t| Iteration: 100 \t| Log-Likelihood:-3.201613742812054 \t|  theta: tensor([[0.0501, 3.1488]], requires_grad=True)  |  Time needed: 0:00:09.253287  \n",
      "Run: 221\t| Iteration: 200 \t| Log-Likelihood:-3.1884041862559003 \t|  theta: tensor([[0.0501, 3.0416]], requires_grad=True)  |  Time needed: 0:00:09.288594  \n",
      "Run: 221\t| Iteration: 300 \t| Log-Likelihood:-3.187332594734489 \t|  theta: tensor([[0.0501, 3.0111]], requires_grad=True)  |  Time needed: 0:00:09.244698  \n",
      "Run: 221\t| Iteration: 400 \t| Log-Likelihood:-3.1872454389910825 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.258976  \n",
      "Run: 221\t| Iteration: 500 \t| Log-Likelihood:-3.187238373110457 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.301619  \n",
      "Run: 221\t| Iteration: 600 \t| Log-Likelihood:-3.1872377924032227 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.358667  \n",
      "Run: 221\t| Iteration: 700 \t| Log-Likelihood:-3.1872377715122355 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.268480  \n",
      "Run: 221\t| Iteration: 800 \t| Log-Likelihood:-3.187237756520588 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.430513  \n",
      "Run: 221\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.558542  \n",
      "Run: 222\t| Iteration: 0 \t| Log-Likelihood:-5.309721469123025 \t|  theta: tensor([[0.4290, 4.6368]], requires_grad=True)  |  Time needed: 0:00:00.090218  \n",
      "Run: 222\t| Iteration: 100 \t| Log-Likelihood:-3.325791519318333 \t|  theta: tensor([[0.0501, 3.4639]], requires_grad=True)  |  Time needed: 0:00:09.247120  \n",
      "Run: 222\t| Iteration: 200 \t| Log-Likelihood:-3.198424967562139 \t|  theta: tensor([[0.0501, 3.1311]], requires_grad=True)  |  Time needed: 0:00:09.215387  \n",
      "Run: 222\t| Iteration: 300 \t| Log-Likelihood:-3.1881457661583696 \t|  theta: tensor([[0.0501, 3.0366]], requires_grad=True)  |  Time needed: 0:00:09.169783  \n",
      "Run: 222\t| Iteration: 400 \t| Log-Likelihood:-3.1873115787352106 \t|  theta: tensor([[0.0501, 3.0096]], requires_grad=True)  |  Time needed: 0:00:09.147219  \n",
      "Run: 222\t| Iteration: 500 \t| Log-Likelihood:-3.1872437731849246 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.160328  \n",
      "Run: 222\t| Iteration: 600 \t| Log-Likelihood:-3.187238215212159 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.112503  \n",
      "Run: 222\t| Iteration: 700 \t| Log-Likelihood:-3.1872377773023706 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.116628  \n",
      "Run: 222\t| Iteration: 800 \t| Log-Likelihood:-3.187237770595251 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.226815  \n",
      "Run: 222\t| Iteration: 900 \t| Log-Likelihood:-3.187237756452196 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.195678  \n",
      "Run: 223\t| Iteration: 0 \t| Log-Likelihood:-3.2689732087479593 \t|  theta: tensor([[0.1689, 2.8852]], requires_grad=True)  |  Time needed: 0:00:00.103383  \n",
      "Run: 223\t| Iteration: 100 \t| Log-Likelihood:-3.187913261967163 \t|  theta: tensor([[0.0501, 2.9664]], requires_grad=True)  |  Time needed: 0:00:09.303530  \n",
      "Run: 223\t| Iteration: 200 \t| Log-Likelihood:-3.1872927521379344 \t|  theta: tensor([[0.0501, 2.9896]], requires_grad=True)  |  Time needed: 0:00:09.136724  \n",
      "Run: 223\t| Iteration: 300 \t| Log-Likelihood:-3.187242217764863 \t|  theta: tensor([[0.0501, 2.9962]], requires_grad=True)  |  Time needed: 0:00:09.102815  \n",
      "Run: 223\t| Iteration: 400 \t| Log-Likelihood:-3.187238090404084 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.117183  \n",
      "Run: 223\t| Iteration: 500 \t| Log-Likelihood:-3.187237789510567 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.114186  \n",
      "Run: 223\t| Iteration: 600 \t| Log-Likelihood:-3.18723772879423 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.100629  \n",
      "Run: 223\t| Iteration: 700 \t| Log-Likelihood:-3.18723773403323 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.111581  \n",
      "Run: 223\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.144172  \n",
      "Run: 223\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.104483  \n",
      "Run: 224\t| Iteration: 0 \t| Log-Likelihood:-4.864897319444322 \t|  theta: tensor([[0.4280, 4.4104]], requires_grad=True)  |  Time needed: 0:00:00.092907  \n",
      "Run: 224\t| Iteration: 100 \t| Log-Likelihood:-3.290134147728862 \t|  theta: tensor([[0.0501, 3.3996]], requires_grad=True)  |  Time needed: 0:00:09.160572  \n",
      "Run: 224\t| Iteration: 200 \t| Log-Likelihood:-3.195551133393811 \t|  theta: tensor([[0.0501, 3.1129]], requires_grad=True)  |  Time needed: 0:00:09.216733  \n",
      "Run: 224\t| Iteration: 300 \t| Log-Likelihood:-3.187912740584182 \t|  theta: tensor([[0.0501, 3.0314]], requires_grad=True)  |  Time needed: 0:00:09.161538  \n",
      "Run: 224\t| Iteration: 400 \t| Log-Likelihood:-3.1872926163194824 \t|  theta: tensor([[0.0501, 3.0081]], requires_grad=True)  |  Time needed: 0:00:09.132044  \n",
      "Run: 224\t| Iteration: 500 \t| Log-Likelihood:-3.1872422097236823 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.148266  \n",
      "Run: 224\t| Iteration: 600 \t| Log-Likelihood:-3.187238126305909 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.134119  \n",
      "Run: 224\t| Iteration: 700 \t| Log-Likelihood:-3.187237759516252 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.134302  \n",
      "Run: 224\t| Iteration: 800 \t| Log-Likelihood:-3.1872377660291473 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.197537  \n",
      "Run: 224\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563794796 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.206993  \n",
      "Run: 225\t| Iteration: 0 \t| Log-Likelihood:-4.289864594081686 \t|  theta: tensor([[0.4908, 3.9593]], requires_grad=True)  |  Time needed: 0:00:00.093122  \n",
      "Run: 225\t| Iteration: 100 \t| Log-Likelihood:-3.2348931344824137 \t|  theta: tensor([[0.0501, 3.2717]], requires_grad=True)  |  Time needed: 0:00:09.114744  \n",
      "Run: 225\t| Iteration: 200 \t| Log-Likelihood:-3.191094700772694 \t|  theta: tensor([[0.0501, 3.0765]], requires_grad=True)  |  Time needed: 0:00:09.238722  \n",
      "Run: 225\t| Iteration: 300 \t| Log-Likelihood:-3.187551171298965 \t|  theta: tensor([[0.0501, 3.0210]], requires_grad=True)  |  Time needed: 0:00:09.106532  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 225\t| Iteration: 400 \t| Log-Likelihood:-3.1872632325081045 \t|  theta: tensor([[0.0501, 3.0052]], requires_grad=True)  |  Time needed: 0:00:09.393352  \n",
      "Run: 225\t| Iteration: 500 \t| Log-Likelihood:-3.1872397910587362 \t|  theta: tensor([[0.0501, 3.0007]], requires_grad=True)  |  Time needed: 0:00:09.477925  \n",
      "Run: 225\t| Iteration: 600 \t| Log-Likelihood:-3.187237891242354 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.081507  \n",
      "Run: 225\t| Iteration: 700 \t| Log-Likelihood:-3.187237732676935 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.074477  \n",
      "Run: 225\t| Iteration: 800 \t| Log-Likelihood:-3.1872377610225295 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.165328  \n",
      "Run: 225\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562423306 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108767  \n",
      "Run: 226\t| Iteration: 0 \t| Log-Likelihood:-4.938360778410125 \t|  theta: tensor([[0.3680, 4.4993]], requires_grad=True)  |  Time needed: 0:00:00.088991  \n",
      "Run: 226\t| Iteration: 100 \t| Log-Likelihood:-3.303501080379438 \t|  theta: tensor([[0.0501, 3.4249]], requires_grad=True)  |  Time needed: 0:00:09.332017  \n",
      "Run: 226\t| Iteration: 200 \t| Log-Likelihood:-3.196628600202125 \t|  theta: tensor([[0.0501, 3.1200]], requires_grad=True)  |  Time needed: 0:00:09.361120  \n",
      "Run: 226\t| Iteration: 300 \t| Log-Likelihood:-3.1880001730197334 \t|  theta: tensor([[0.0501, 3.0334]], requires_grad=True)  |  Time needed: 0:00:09.266931  \n",
      "Run: 226\t| Iteration: 400 \t| Log-Likelihood:-3.1872997661511535 \t|  theta: tensor([[0.0501, 3.0087]], requires_grad=True)  |  Time needed: 0:00:09.295624  \n",
      "Run: 226\t| Iteration: 500 \t| Log-Likelihood:-3.187242757492949 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.294554  \n",
      "Run: 226\t| Iteration: 600 \t| Log-Likelihood:-3.1872381812411854 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.297362  \n",
      "Run: 226\t| Iteration: 700 \t| Log-Likelihood:-3.187237767175745 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.429636  \n",
      "Run: 226\t| Iteration: 800 \t| Log-Likelihood:-3.187237766315089 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.368712  \n",
      "Run: 226\t| Iteration: 900 \t| Log-Likelihood:-3.187237756408538 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.338519  \n",
      "Run: 227\t| Iteration: 0 \t| Log-Likelihood:-3.6794495625750137 \t|  theta: tensor([[0.4687, 2.8092]], requires_grad=True)  |  Time needed: 0:00:00.093087  \n",
      "Run: 227\t| Iteration: 100 \t| Log-Likelihood:-3.1891414853009583 \t|  theta: tensor([[0.0501, 2.9443]], requires_grad=True)  |  Time needed: 0:00:09.186816  \n",
      "Run: 227\t| Iteration: 200 \t| Log-Likelihood:-3.1873928551152657 \t|  theta: tensor([[0.0501, 2.9833]], requires_grad=True)  |  Time needed: 0:00:09.154468  \n",
      "Run: 227\t| Iteration: 300 \t| Log-Likelihood:-3.18725039428763 \t|  theta: tensor([[0.0501, 2.9944]], requires_grad=True)  |  Time needed: 0:00:09.158530  \n",
      "Run: 227\t| Iteration: 400 \t| Log-Likelihood:-3.187238783371181 \t|  theta: tensor([[0.0501, 2.9976]], requires_grad=True)  |  Time needed: 0:00:09.210894  \n",
      "Run: 227\t| Iteration: 500 \t| Log-Likelihood:-3.187237817229614 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.226966  \n",
      "Run: 227\t| Iteration: 600 \t| Log-Likelihood:-3.1872377256836852 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.131552  \n",
      "Run: 227\t| Iteration: 700 \t| Log-Likelihood:-3.1872377343439786 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.177417  \n",
      "Run: 227\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.145082  \n",
      "Run: 227\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.151367  \n",
      "Run: 228\t| Iteration: 0 \t| Log-Likelihood:-3.1955299242998714 \t|  theta: tensor([[0.3852, 1.0765]], requires_grad=True)  |  Time needed: 0:00:00.092352  \n",
      "Run: 228\t| Iteration: 100 \t| Log-Likelihood:-3.1904669303024815 \t|  theta: tensor([[0.4315, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.210503  \n",
      "Run: 228\t| Iteration: 200 \t| Log-Likelihood:-3.1904627067350804 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136550  \n",
      "Run: 228\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327331183 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097635  \n",
      "Run: 228\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127485  \n",
      "Run: 228\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.109478  \n",
      "Run: 228\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.199742  \n",
      "Run: 228\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123958  \n",
      "Run: 228\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.182877  \n",
      "Run: 228\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.209805  \n",
      "Run: 229\t| Iteration: 0 \t| Log-Likelihood:-4.0169724976880365 \t|  theta: tensor([[0.3198, 3.9574]], requires_grad=True)  |  Time needed: 0:00:00.100634  \n",
      "Run: 229\t| Iteration: 100 \t| Log-Likelihood:-3.2347087202572804 \t|  theta: tensor([[0.0501, 3.2712]], requires_grad=True)  |  Time needed: 0:00:09.248194  \n",
      "Run: 229\t| Iteration: 200 \t| Log-Likelihood:-3.1910797265865467 \t|  theta: tensor([[0.0501, 3.0764]], requires_grad=True)  |  Time needed: 0:00:09.158476  \n",
      "Run: 229\t| Iteration: 300 \t| Log-Likelihood:-3.187549905315997 \t|  theta: tensor([[0.0501, 3.0210]], requires_grad=True)  |  Time needed: 0:00:09.133786  \n",
      "Run: 229\t| Iteration: 400 \t| Log-Likelihood:-3.187263135736797 \t|  theta: tensor([[0.0501, 3.0052]], requires_grad=True)  |  Time needed: 0:00:09.228410  \n",
      "Run: 229\t| Iteration: 500 \t| Log-Likelihood:-3.1872397856430887 \t|  theta: tensor([[0.0501, 3.0007]], requires_grad=True)  |  Time needed: 0:00:09.170280  \n",
      "Run: 229\t| Iteration: 600 \t| Log-Likelihood:-3.187237890624581 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.098637  \n",
      "Run: 229\t| Iteration: 700 \t| Log-Likelihood:-3.187237732632788 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.128425  \n",
      "Run: 229\t| Iteration: 800 \t| Log-Likelihood:-3.1872377610225295 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.110653  \n",
      "Run: 229\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562423306 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.133621  \n",
      "Run: 230\t| Iteration: 0 \t| Log-Likelihood:-3.2794767382105032 \t|  theta: tensor([[0.3395, 1.2173]], requires_grad=True)  |  Time needed: 0:00:00.091103  \n",
      "Run: 230\t| Iteration: 100 \t| Log-Likelihood:-3.1904951235208885 \t|  theta: tensor([[0.4289, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.203500  \n",
      "Run: 230\t| Iteration: 200 \t| Log-Likelihood:-3.1904627320313095 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.161568  \n",
      "Run: 230\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029530825 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.274032  \n",
      "Run: 230\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.123112  \n",
      "Run: 230\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.136558  \n",
      "Run: 230\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.188741  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 230\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.178997  \n",
      "Run: 230\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.220624  \n",
      "Run: 230\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144206  \n",
      "Run: 231\t| Iteration: 0 \t| Log-Likelihood:-3.9235191230063067 \t|  theta: tensor([[0.2501, 0.7328]], requires_grad=True)  |  Time needed: 0:00:00.087813  \n",
      "Run: 231\t| Iteration: 100 \t| Log-Likelihood:-3.1904751548267156 \t|  theta: tensor([[0.4304, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.272067  \n",
      "Run: 231\t| Iteration: 200 \t| Log-Likelihood:-3.190462743938828 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.269718  \n",
      "Run: 231\t| Iteration: 300 \t| Log-Likelihood:-3.190462732739551 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.290174  \n",
      "Run: 231\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.353629  \n",
      "Run: 231\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.260398  \n",
      "Run: 231\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.482500  \n",
      "Run: 231\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.261503  \n",
      "Run: 231\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.344332  \n",
      "Run: 231\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.308847  \n",
      "Run: 232\t| Iteration: 0 \t| Log-Likelihood:-5.264239278278179 \t|  theta: tensor([[0.5053, 4.5470]], requires_grad=True)  |  Time needed: 0:00:00.086955  \n",
      "Run: 232\t| Iteration: 100 \t| Log-Likelihood:-3.3110027903431622 \t|  theta: tensor([[0.0501, 3.4384]], requires_grad=True)  |  Time needed: 0:00:09.107938  \n",
      "Run: 232\t| Iteration: 200 \t| Log-Likelihood:-3.1972330150620643 \t|  theta: tensor([[0.0501, 3.1239]], requires_grad=True)  |  Time needed: 0:00:09.513396  \n",
      "Run: 232\t| Iteration: 300 \t| Log-Likelihood:-3.188049152182657 \t|  theta: tensor([[0.0501, 3.0345]], requires_grad=True)  |  Time needed: 0:00:09.843659  \n",
      "Run: 232\t| Iteration: 400 \t| Log-Likelihood:-3.1873037403377484 \t|  theta: tensor([[0.0501, 3.0090]], requires_grad=True)  |  Time needed: 0:00:09.889633  \n",
      "Run: 232\t| Iteration: 500 \t| Log-Likelihood:-3.1872431007276187 \t|  theta: tensor([[0.0501, 3.0018]], requires_grad=True)  |  Time needed: 0:00:10.011809  \n",
      "Run: 232\t| Iteration: 600 \t| Log-Likelihood:-3.1872381555399714 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.697715  \n",
      "Run: 232\t| Iteration: 700 \t| Log-Likelihood:-3.1872377692707863 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.115880  \n",
      "Run: 232\t| Iteration: 800 \t| Log-Likelihood:-3.187237766474109 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.081765  \n",
      "Run: 232\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564268235 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.130600  \n",
      "Run: 233\t| Iteration: 0 \t| Log-Likelihood:-3.5743049258705684 \t|  theta: tensor([[0.4824, 1.4102]], requires_grad=True)  |  Time needed: 0:00:00.096822  \n",
      "Run: 233\t| Iteration: 100 \t| Log-Likelihood:-3.1904807602058285 \t|  theta: tensor([[0.4300, 1.0580]], requires_grad=True)  |  Time needed: 0:00:09.137048  \n",
      "Run: 233\t| Iteration: 200 \t| Log-Likelihood:-3.190462748756204 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.140661  \n",
      "Run: 233\t| Iteration: 300 \t| Log-Likelihood:-3.190462702941835 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.162362  \n",
      "Run: 233\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.106522  \n",
      "Run: 233\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.112860  \n",
      "Run: 233\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105925  \n",
      "Run: 233\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099385  \n",
      "Run: 233\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.258995  \n",
      "Run: 233\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.195610  \n",
      "Run: 234\t| Iteration: 0 \t| Log-Likelihood:-3.2243911587605645 \t|  theta: tensor([[0.5650, 1.0282]], requires_grad=True)  |  Time needed: 0:00:00.094567  \n",
      "Run: 234\t| Iteration: 100 \t| Log-Likelihood:-3.19049377220696 \t|  theta: tensor([[0.4369, 1.0560]], requires_grad=True)  |  Time needed: 0:00:09.126134  \n",
      "Run: 234\t| Iteration: 200 \t| Log-Likelihood:-3.1904627608353158 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.181340  \n",
      "Run: 234\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731499137 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129048  \n",
      "Run: 234\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.132172  \n",
      "Run: 234\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.157975  \n",
      "Run: 234\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.233633  \n",
      "Run: 234\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127035  \n",
      "Run: 234\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.146434  \n",
      "Run: 234\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.193578  \n",
      "Run: 235\t| Iteration: 0 \t| Log-Likelihood:-3.650922835144597 \t|  theta: tensor([[0.2541, 3.6867]], requires_grad=True)  |  Time needed: 0:00:00.088232  \n",
      "Run: 235\t| Iteration: 100 \t| Log-Likelihood:-3.2116937337635307 \t|  theta: tensor([[0.0501, 3.1944]], requires_grad=True)  |  Time needed: 0:00:09.052959  \n",
      "Run: 235\t| Iteration: 200 \t| Log-Likelihood:-3.1892199443036238 \t|  theta: tensor([[0.0501, 3.0546]], requires_grad=True)  |  Time needed: 0:00:09.151459  \n",
      "Run: 235\t| Iteration: 300 \t| Log-Likelihood:-3.187398845959697 \t|  theta: tensor([[0.0501, 3.0148]], requires_grad=True)  |  Time needed: 0:00:09.104809  \n",
      "Run: 235\t| Iteration: 400 \t| Log-Likelihood:-3.187250832442946 \t|  theta: tensor([[0.0501, 3.0034]], requires_grad=True)  |  Time needed: 0:00:09.091655  \n",
      "Run: 235\t| Iteration: 500 \t| Log-Likelihood:-3.1872388066195962 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.100371  \n",
      "Run: 235\t| Iteration: 600 \t| Log-Likelihood:-3.1872378427683117 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.069206  \n",
      "Run: 235\t| Iteration: 700 \t| Log-Likelihood:-3.1872377780890147 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.078731  \n",
      "Run: 235\t| Iteration: 800 \t| Log-Likelihood:-3.18723776044786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.099758  \n",
      "Run: 235\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.218073  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 236\t| Iteration: 0 \t| Log-Likelihood:-3.824839959724319 \t|  theta: tensor([[0.3475, 2.1332]], requires_grad=True)  |  Time needed: 0:00:00.089744  \n",
      "Run: 236\t| Iteration: 100 \t| Log-Likelihood:-3.2439914980245304 \t|  theta: tensor([[0.0505, 2.6993]], requires_grad=True)  |  Time needed: 0:00:09.410313  \n",
      "Run: 236\t| Iteration: 200 \t| Log-Likelihood:-3.1919906449513387 \t|  theta: tensor([[0.0501, 2.9126]], requires_grad=True)  |  Time needed: 0:00:09.606734  \n",
      "Run: 236\t| Iteration: 300 \t| Log-Likelihood:-3.1876256897299897 \t|  theta: tensor([[0.0501, 2.9742]], requires_grad=True)  |  Time needed: 0:00:09.309779  \n",
      "Run: 236\t| Iteration: 400 \t| Log-Likelihood:-3.187269343598029 \t|  theta: tensor([[0.0501, 2.9918]], requires_grad=True)  |  Time needed: 0:00:09.324329  \n",
      "Run: 236\t| Iteration: 500 \t| Log-Likelihood:-3.1872403041643045 \t|  theta: tensor([[0.0501, 2.9969]], requires_grad=True)  |  Time needed: 0:00:09.370731  \n",
      "Run: 236\t| Iteration: 600 \t| Log-Likelihood:-3.1872379688324797 \t|  theta: tensor([[0.0501, 2.9983]], requires_grad=True)  |  Time needed: 0:00:09.328731  \n",
      "Run: 236\t| Iteration: 700 \t| Log-Likelihood:-3.1872377283930637 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.380597  \n",
      "Run: 236\t| Iteration: 800 \t| Log-Likelihood:-3.1872377314462628 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.291922  \n",
      "Run: 236\t| Iteration: 900 \t| Log-Likelihood:-3.1872377339208 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.285819  \n",
      "Run: 237\t| Iteration: 0 \t| Log-Likelihood:-3.950180674142988 \t|  theta: tensor([[0.4847, 3.6401]], requires_grad=True)  |  Time needed: 0:00:00.086460  \n",
      "Run: 237\t| Iteration: 100 \t| Log-Likelihood:-3.2084931880118632 \t|  theta: tensor([[0.0501, 3.1811]], requires_grad=True)  |  Time needed: 0:00:09.245515  \n",
      "Run: 237\t| Iteration: 200 \t| Log-Likelihood:-3.1889611230476063 \t|  theta: tensor([[0.0501, 3.0508]], requires_grad=True)  |  Time needed: 0:00:09.236382  \n",
      "Run: 237\t| Iteration: 300 \t| Log-Likelihood:-3.1873778134222674 \t|  theta: tensor([[0.0501, 3.0137]], requires_grad=True)  |  Time needed: 0:00:09.144670  \n",
      "Run: 237\t| Iteration: 400 \t| Log-Likelihood:-3.187249126471278 \t|  theta: tensor([[0.0501, 3.0031]], requires_grad=True)  |  Time needed: 0:00:09.246935  \n",
      "Run: 237\t| Iteration: 500 \t| Log-Likelihood:-3.1872386505221297 \t|  theta: tensor([[0.0501, 3.0001]], requires_grad=True)  |  Time needed: 0:00:09.139731  \n",
      "Run: 237\t| Iteration: 600 \t| Log-Likelihood:-3.1872378278004256 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.124708  \n",
      "Run: 237\t| Iteration: 700 \t| Log-Likelihood:-3.187237777203291 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.135132  \n",
      "Run: 237\t| Iteration: 800 \t| Log-Likelihood:-3.187237760370045 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.227595  \n",
      "Run: 237\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.179282  \n",
      "Run: 238\t| Iteration: 0 \t| Log-Likelihood:-3.6932081108717254 \t|  theta: tensor([[0.1264, 1.5976]], requires_grad=True)  |  Time needed: 0:00:00.097493  \n",
      "Run: 238\t| Iteration: 100 \t| Log-Likelihood:-3.191646878473697 \t|  theta: tensor([[0.4095, 1.0659]], requires_grad=True)  |  Time needed: 0:00:09.134706  \n",
      "Run: 238\t| Iteration: 200 \t| Log-Likelihood:-3.1904636952468635 \t|  theta: tensor([[0.4322, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.100272  \n",
      "Run: 238\t| Iteration: 300 \t| Log-Likelihood:-3.1904627038411326 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.094483  \n",
      "Run: 238\t| Iteration: 400 \t| Log-Likelihood:-3.1904627029281483 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.227838  \n",
      "Run: 238\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.219097  \n",
      "Run: 238\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.101915  \n",
      "Run: 238\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127843  \n",
      "Run: 238\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135613  \n",
      "Run: 238\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103535  \n",
      "Run: 239\t| Iteration: 0 \t| Log-Likelihood:-3.4714131879059895 \t|  theta: tensor([[0.3356, 2.8077]], requires_grad=True)  |  Time needed: 0:00:00.092082  \n",
      "Run: 239\t| Iteration: 100 \t| Log-Likelihood:-3.1891645235065074 \t|  theta: tensor([[0.0501, 2.9440]], requires_grad=True)  |  Time needed: 0:00:09.129816  \n",
      "Run: 239\t| Iteration: 200 \t| Log-Likelihood:-3.1873947545500463 \t|  theta: tensor([[0.0501, 2.9832]], requires_grad=True)  |  Time needed: 0:00:09.109084  \n",
      "Run: 239\t| Iteration: 300 \t| Log-Likelihood:-3.1872505371026087 \t|  theta: tensor([[0.0501, 2.9944]], requires_grad=True)  |  Time needed: 0:00:09.109825  \n",
      "Run: 239\t| Iteration: 400 \t| Log-Likelihood:-3.1872387911241282 \t|  theta: tensor([[0.0501, 2.9976]], requires_grad=True)  |  Time needed: 0:00:09.146694  \n",
      "Run: 239\t| Iteration: 500 \t| Log-Likelihood:-3.187237818320503 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.095847  \n",
      "Run: 239\t| Iteration: 600 \t| Log-Likelihood:-3.187237725745828 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.082494  \n",
      "Run: 239\t| Iteration: 700 \t| Log-Likelihood:-3.1872377343527636 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.360146  \n",
      "Run: 239\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.352817  \n",
      "Run: 239\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.146884  \n",
      "Run: 240\t| Iteration: 0 \t| Log-Likelihood:-4.092499313086063 \t|  theta: tensor([[0.1637, 0.7420]], requires_grad=True)  |  Time needed: 0:00:00.092799  \n",
      "Run: 240\t| Iteration: 100 \t| Log-Likelihood:-3.190492479676024 \t|  theta: tensor([[0.4290, 1.0579]], requires_grad=True)  |  Time needed: 0:00:09.139863  \n",
      "Run: 240\t| Iteration: 200 \t| Log-Likelihood:-3.1904627296097248 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.096002  \n",
      "Run: 240\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731490535 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150920  \n",
      "Run: 240\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.211768  \n",
      "Run: 240\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.145073  \n",
      "Run: 240\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.100514  \n",
      "Run: 240\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.138462  \n",
      "Run: 240\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.122260  \n",
      "Run: 240\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.125932  \n",
      "Run: 241\t| Iteration: 0 \t| Log-Likelihood:-4.100333238212791 \t|  theta: tensor([[0.5650, 1.7307]], requires_grad=True)  |  Time needed: 0:00:00.088399  \n",
      "Run: 241\t| Iteration: 100 \t| Log-Likelihood:-3.1912939211599585 \t|  theta: tensor([[0.4136, 1.0650]], requires_grad=True)  |  Time needed: 0:00:09.322872  \n",
      "Run: 241\t| Iteration: 200 \t| Log-Likelihood:-3.1904634422540448 \t|  theta: tensor([[0.4323, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.315681  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 241\t| Iteration: 300 \t| Log-Likelihood:-3.1904627333664393 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.248634  \n",
      "Run: 241\t| Iteration: 400 \t| Log-Likelihood:-3.190462673125561 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.265305  \n",
      "Run: 241\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.236662  \n",
      "Run: 241\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.347975  \n",
      "Run: 241\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309198  \n",
      "Run: 241\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.313702  \n",
      "Run: 241\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.238096  \n",
      "Run: 242\t| Iteration: 0 \t| Log-Likelihood:-3.9425760108615413 \t|  theta: tensor([[0.5682, 3.3510]], requires_grad=True)  |  Time needed: 0:00:00.093549  \n",
      "Run: 242\t| Iteration: 100 \t| Log-Likelihood:-3.193656391007334 \t|  theta: tensor([[0.0501, 3.0991]], requires_grad=True)  |  Time needed: 0:00:09.126707  \n",
      "Run: 242\t| Iteration: 200 \t| Log-Likelihood:-3.187759100568346 \t|  theta: tensor([[0.0501, 3.0274]], requires_grad=True)  |  Time needed: 0:00:09.118504  \n",
      "Run: 242\t| Iteration: 300 \t| Log-Likelihood:-3.187280162089194 \t|  theta: tensor([[0.0501, 3.0070]], requires_grad=True)  |  Time needed: 0:00:09.218509  \n",
      "Run: 242\t| Iteration: 400 \t| Log-Likelihood:-3.1872411992427234 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.489937  \n",
      "Run: 242\t| Iteration: 500 \t| Log-Likelihood:-3.18723802976745 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.200044  \n",
      "Run: 242\t| Iteration: 600 \t| Log-Likelihood:-3.1872377491714974 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.112220  \n",
      "Run: 242\t| Iteration: 700 \t| Log-Likelihood:-3.187237765488728 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.158962  \n",
      "Run: 242\t| Iteration: 800 \t| Log-Likelihood:-3.1872377563266774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.166372  \n",
      "Run: 242\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.156321  \n",
      "Run: 243\t| Iteration: 0 \t| Log-Likelihood:-4.134926748257727 \t|  theta: tensor([[0.5247, 1.9521]], requires_grad=True)  |  Time needed: 0:00:00.094581  \n",
      "Run: 243\t| Iteration: 100 \t| Log-Likelihood:-3.3724284159779048 \t|  theta: tensor([[0.0530, 2.4490]], requires_grad=True)  |  Time needed: 0:00:09.159473  \n",
      "Run: 243\t| Iteration: 200 \t| Log-Likelihood:-3.2040740537125916 \t|  theta: tensor([[0.0502, 2.8363]], requires_grad=True)  |  Time needed: 0:00:09.105080  \n",
      "Run: 243\t| Iteration: 300 \t| Log-Likelihood:-3.188620696846269 \t|  theta: tensor([[0.0501, 2.9523]], requires_grad=True)  |  Time needed: 0:00:09.418474  \n",
      "Run: 243\t| Iteration: 400 \t| Log-Likelihood:-3.1873504109870376 \t|  theta: tensor([[0.0501, 2.9856]], requires_grad=True)  |  Time needed: 0:00:09.262770  \n",
      "Run: 243\t| Iteration: 500 \t| Log-Likelihood:-3.1872469356268227 \t|  theta: tensor([[0.0501, 2.9951]], requires_grad=True)  |  Time needed: 0:00:09.095133  \n",
      "Run: 243\t| Iteration: 600 \t| Log-Likelihood:-3.1872384770088598 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.111477  \n",
      "Run: 243\t| Iteration: 700 \t| Log-Likelihood:-3.187237805733848 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.200183  \n",
      "Run: 243\t| Iteration: 800 \t| Log-Likelihood:-3.1872377275700643 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.150402  \n",
      "Run: 243\t| Iteration: 900 \t| Log-Likelihood:-3.187237734220697 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.118743  \n",
      "Run: 244\t| Iteration: 0 \t| Log-Likelihood:-3.9222561772404583 \t|  theta: tensor([[0.4624, 2.2742]], requires_grad=True)  |  Time needed: 0:00:00.094702  \n",
      "Run: 244\t| Iteration: 100 \t| Log-Likelihood:-3.221470214632377 \t|  theta: tensor([[0.0503, 2.7667]], requires_grad=True)  |  Time needed: 0:00:09.162933  \n",
      "Run: 244\t| Iteration: 200 \t| Log-Likelihood:-3.1900737486427957 \t|  theta: tensor([[0.0501, 2.9322]], requires_grad=True)  |  Time needed: 0:00:09.161376  \n",
      "Run: 244\t| Iteration: 300 \t| Log-Likelihood:-3.187468954572031 \t|  theta: tensor([[0.0501, 2.9799]], requires_grad=True)  |  Time needed: 0:00:09.259721  \n",
      "Run: 244\t| Iteration: 400 \t| Log-Likelihood:-3.187256576598063 \t|  theta: tensor([[0.0501, 2.9935]], requires_grad=True)  |  Time needed: 0:00:09.131469  \n",
      "Run: 244\t| Iteration: 500 \t| Log-Likelihood:-3.187239287581521 \t|  theta: tensor([[0.0501, 2.9973]], requires_grad=True)  |  Time needed: 0:00:09.126609  \n",
      "Run: 244\t| Iteration: 600 \t| Log-Likelihood:-3.187237846986457 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.138159  \n",
      "Run: 244\t| Iteration: 700 \t| Log-Likelihood:-3.1872377253367197 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.126427  \n",
      "Run: 244\t| Iteration: 800 \t| Log-Likelihood:-3.1872377309349766 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.132035  \n",
      "Run: 244\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.245972  \n",
      "Run: 245\t| Iteration: 0 \t| Log-Likelihood:-3.567529604332787 \t|  theta: tensor([[0.5415, 1.3736]], requires_grad=True)  |  Time needed: 0:00:00.093458  \n",
      "Run: 245\t| Iteration: 100 \t| Log-Likelihood:-3.190463088348741 \t|  theta: tensor([[0.4326, 1.0573]], requires_grad=True)  |  Time needed: 0:00:09.180161  \n",
      "Run: 245\t| Iteration: 200 \t| Log-Likelihood:-3.1904626733983785 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150294  \n",
      "Run: 245\t| Iteration: 300 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.161708  \n",
      "Run: 245\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.101419  \n",
      "Run: 245\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.087829  \n",
      "Run: 245\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.111570  \n",
      "Run: 245\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.088327  \n",
      "Run: 245\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.069785  \n",
      "Run: 245\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103332  \n",
      "Run: 246\t| Iteration: 0 \t| Log-Likelihood:-4.012605430186667 \t|  theta: tensor([[0.1251, 0.8789]], requires_grad=True)  |  Time needed: 0:00:00.090162  \n",
      "Run: 246\t| Iteration: 100 \t| Log-Likelihood:-3.19051220652631 \t|  theta: tensor([[0.4279, 1.0583]], requires_grad=True)  |  Time needed: 0:00:09.292978  \n",
      "Run: 246\t| Iteration: 200 \t| Log-Likelihood:-3.1904627473588105 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.304406  \n",
      "Run: 246\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327682666 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.331552  \n",
      "Run: 246\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.366377  \n",
      "Run: 246\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.370998  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 246\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309133  \n",
      "Run: 246\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309691  \n",
      "Run: 246\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.292715  \n",
      "Run: 246\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.743694  \n",
      "Run: 247\t| Iteration: 0 \t| Log-Likelihood:-4.6656608538611675 \t|  theta: tensor([[0.5230, 0.5485]], requires_grad=True)  |  Time needed: 0:00:00.088328  \n",
      "Run: 247\t| Iteration: 100 \t| Log-Likelihood:-3.1905147459710976 \t|  theta: tensor([[0.4381, 1.0556]], requires_grad=True)  |  Time needed: 0:00:09.166490  \n",
      "Run: 247\t| Iteration: 200 \t| Log-Likelihood:-3.190462749999718 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.215399  \n",
      "Run: 247\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029681003 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.167182  \n",
      "Run: 247\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.177558  \n",
      "Run: 247\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.284861  \n",
      "Run: 247\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.234001  \n",
      "Run: 247\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.234787  \n",
      "Run: 247\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.187171  \n",
      "Run: 247\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.286223  \n",
      "Run: 248\t| Iteration: 0 \t| Log-Likelihood:-3.6683059172134165 \t|  theta: tensor([[0.0718, 3.8603]], requires_grad=True)  |  Time needed: 0:00:00.094040  \n",
      "Run: 248\t| Iteration: 100 \t| Log-Likelihood:-3.225582840277424 \t|  theta: tensor([[0.0501, 3.2436]], requires_grad=True)  |  Time needed: 0:00:09.171861  \n",
      "Run: 248\t| Iteration: 200 \t| Log-Likelihood:-3.190342644357565 \t|  theta: tensor([[0.0501, 3.0686]], requires_grad=True)  |  Time needed: 0:00:09.111298  \n",
      "Run: 248\t| Iteration: 300 \t| Log-Likelihood:-3.187490076323062 \t|  theta: tensor([[0.0501, 3.0187]], requires_grad=True)  |  Time needed: 0:00:09.077122  \n",
      "Run: 248\t| Iteration: 400 \t| Log-Likelihood:-3.1872582703234325 \t|  theta: tensor([[0.0501, 3.0045]], requires_grad=True)  |  Time needed: 0:00:09.094582  \n",
      "Run: 248\t| Iteration: 500 \t| Log-Likelihood:-3.1872394192340896 \t|  theta: tensor([[0.0501, 3.0005]], requires_grad=True)  |  Time needed: 0:00:09.105008  \n",
      "Run: 248\t| Iteration: 600 \t| Log-Likelihood:-3.1872378513589688 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.079891  \n",
      "Run: 248\t| Iteration: 700 \t| Log-Likelihood:-3.187237726269059 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.100876  \n",
      "Run: 248\t| Iteration: 800 \t| Log-Likelihood:-3.1872377608165183 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.120835  \n",
      "Run: 248\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562136216 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.192907  \n",
      "Run: 249\t| Iteration: 0 \t| Log-Likelihood:-3.6897577386867413 \t|  theta: tensor([[0.4252, 3.4091]], requires_grad=True)  |  Time needed: 0:00:00.091275  \n",
      "Run: 249\t| Iteration: 100 \t| Log-Likelihood:-3.1959460580098407 \t|  theta: tensor([[0.0501, 3.1156]], requires_grad=True)  |  Time needed: 0:00:09.096595  \n",
      "Run: 249\t| Iteration: 200 \t| Log-Likelihood:-3.1879447645874666 \t|  theta: tensor([[0.0501, 3.0321]], requires_grad=True)  |  Time needed: 0:00:09.134042  \n",
      "Run: 249\t| Iteration: 300 \t| Log-Likelihood:-3.1872952583321705 \t|  theta: tensor([[0.0501, 3.0084]], requires_grad=True)  |  Time needed: 0:00:09.094408  \n",
      "Run: 249\t| Iteration: 400 \t| Log-Likelihood:-3.187242432558948 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.086530  \n",
      "Run: 249\t| Iteration: 500 \t| Log-Likelihood:-3.187238147931098 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.189625  \n",
      "Run: 249\t| Iteration: 600 \t| Log-Likelihood:-3.1872377647458787 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.100893  \n",
      "Run: 249\t| Iteration: 700 \t| Log-Likelihood:-3.187237766141611 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.098466  \n",
      "Run: 249\t| Iteration: 800 \t| Log-Likelihood:-3.18723775639089 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108293  \n",
      "Run: 249\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.106105  \n",
      "Run: 250\t| Iteration: 0 \t| Log-Likelihood:-3.4255648529161764 \t|  theta: tensor([[0.1622, 1.2425]], requires_grad=True)  |  Time needed: 0:00:00.092520  \n",
      "Run: 250\t| Iteration: 100 \t| Log-Likelihood:-3.190589473421733 \t|  theta: tensor([[0.4250, 1.0593]], requires_grad=True)  |  Time needed: 0:00:09.107443  \n",
      "Run: 250\t| Iteration: 200 \t| Log-Likelihood:-3.1904627865625197 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.146971  \n",
      "Run: 250\t| Iteration: 300 \t| Log-Likelihood:-3.190462673225397 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.210398  \n",
      "Run: 250\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.084792  \n",
      "Run: 250\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.596916  \n",
      "Run: 250\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116640  \n",
      "Run: 250\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.112250  \n",
      "Run: 250\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.174545  \n",
      "Run: 250\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113355  \n",
      "Run: 251\t| Iteration: 0 \t| Log-Likelihood:-3.6440410589132397 \t|  theta: tensor([[0.1047, 1.4089]], requires_grad=True)  |  Time needed: 0:00:00.087998  \n",
      "Run: 251\t| Iteration: 100 \t| Log-Likelihood:-3.19077133194851 \t|  theta: tensor([[0.4206, 1.0608]], requires_grad=True)  |  Time needed: 0:00:09.270193  \n",
      "Run: 251\t| Iteration: 200 \t| Log-Likelihood:-3.190462977038435 \t|  theta: tensor([[0.4326, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.244682  \n",
      "Run: 251\t| Iteration: 300 \t| Log-Likelihood:-3.1904627031765034 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.236340  \n",
      "Run: 251\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.318855  \n",
      "Run: 251\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.376524  \n",
      "Run: 251\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.390375  \n",
      "Run: 251\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.238561  \n",
      "Run: 251\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.259789  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 251\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.241648  \n",
      "Run: 252\t| Iteration: 0 \t| Log-Likelihood:-3.852888328845228 \t|  theta: tensor([[0.4345, 2.3131]], requires_grad=True)  |  Time needed: 0:00:00.092453  \n",
      "Run: 252\t| Iteration: 100 \t| Log-Likelihood:-3.2166977570530775 \t|  theta: tensor([[0.0503, 2.7835]], requires_grad=True)  |  Time needed: 0:00:09.206977  \n",
      "Run: 252\t| Iteration: 200 \t| Log-Likelihood:-3.1896727731207433 \t|  theta: tensor([[0.0501, 2.9371]], requires_grad=True)  |  Time needed: 0:00:09.097580  \n",
      "Run: 252\t| Iteration: 300 \t| Log-Likelihood:-3.187436212382954 \t|  theta: tensor([[0.0501, 2.9813]], requires_grad=True)  |  Time needed: 0:00:09.096394  \n",
      "Run: 252\t| Iteration: 400 \t| Log-Likelihood:-3.1872538729534465 \t|  theta: tensor([[0.0501, 2.9938]], requires_grad=True)  |  Time needed: 0:00:09.115717  \n",
      "Run: 252\t| Iteration: 500 \t| Log-Likelihood:-3.1872390335800356 \t|  theta: tensor([[0.0501, 2.9974]], requires_grad=True)  |  Time needed: 0:00:09.110565  \n",
      "Run: 252\t| Iteration: 600 \t| Log-Likelihood:-3.187237833312207 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.095021  \n",
      "Run: 252\t| Iteration: 700 \t| Log-Likelihood:-3.1872377276360484 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.213626  \n",
      "Run: 252\t| Iteration: 800 \t| Log-Likelihood:-3.1872377345331544 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.153457  \n",
      "Run: 252\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.181282  \n",
      "Run: 253\t| Iteration: 0 \t| Log-Likelihood:-4.461637198903779 \t|  theta: tensor([[0.4594, 4.1303]], requires_grad=True)  |  Time needed: 0:00:00.093755  \n",
      "Run: 253\t| Iteration: 100 \t| Log-Likelihood:-3.2533633911968143 \t|  theta: tensor([[0.0501, 3.3202]], requires_grad=True)  |  Time needed: 0:00:09.116440  \n",
      "Run: 253\t| Iteration: 200 \t| Log-Likelihood:-3.1925855480808214 \t|  theta: tensor([[0.0501, 3.0903]], requires_grad=True)  |  Time needed: 0:00:09.093776  \n",
      "Run: 253\t| Iteration: 300 \t| Log-Likelihood:-3.18767214538907 \t|  theta: tensor([[0.0501, 3.0249]], requires_grad=True)  |  Time needed: 0:00:09.086984  \n",
      "Run: 253\t| Iteration: 400 \t| Log-Likelihood:-3.187273095055161 \t|  theta: tensor([[0.0501, 3.0063]], requires_grad=True)  |  Time needed: 0:00:09.106146  \n",
      "Run: 253\t| Iteration: 500 \t| Log-Likelihood:-3.1872405873253924 \t|  theta: tensor([[0.0501, 3.0010]], requires_grad=True)  |  Time needed: 0:00:09.111469  \n",
      "Run: 253\t| Iteration: 600 \t| Log-Likelihood:-3.187237971274342 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.083939  \n",
      "Run: 253\t| Iteration: 700 \t| Log-Likelihood:-3.187237741691061 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.095327  \n",
      "Run: 253\t| Iteration: 800 \t| Log-Likelihood:-3.1872377651465165 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.096173  \n",
      "Run: 253\t| Iteration: 900 \t| Log-Likelihood:-3.187237756293932 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.079093  \n",
      "Run: 254\t| Iteration: 0 \t| Log-Likelihood:-3.2308180852704003 \t|  theta: tensor([[0.0354, 3.2289]], requires_grad=True)  |  Time needed: 0:00:00.098245  \n",
      "Run: 254\t| Iteration: 100 \t| Log-Likelihood:-3.1899803145993415 \t|  theta: tensor([[0.0501, 3.0644]], requires_grad=True)  |  Time needed: 0:00:09.605055  \n",
      "Run: 254\t| Iteration: 200 \t| Log-Likelihood:-3.1874606769571625 \t|  theta: tensor([[0.0501, 3.0175]], requires_grad=True)  |  Time needed: 0:00:09.273444  \n",
      "Run: 254\t| Iteration: 300 \t| Log-Likelihood:-3.1872558770247337 \t|  theta: tensor([[0.0501, 3.0042]], requires_grad=True)  |  Time needed: 0:00:09.142476  \n",
      "Run: 254\t| Iteration: 400 \t| Log-Likelihood:-3.187239204781192 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.128566  \n",
      "Run: 254\t| Iteration: 500 \t| Log-Likelihood:-3.187237887482743 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.123815  \n",
      "Run: 254\t| Iteration: 600 \t| Log-Likelihood:-3.1872377249247874 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.185977  \n",
      "Run: 254\t| Iteration: 700 \t| Log-Likelihood:-3.187237760704901 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.135774  \n",
      "Run: 254\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.103542  \n",
      "Run: 254\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113093  \n",
      "Run: 255\t| Iteration: 0 \t| Log-Likelihood:-3.9312175595192467 \t|  theta: tensor([[0.4120, 3.7589]], requires_grad=True)  |  Time needed: 0:00:00.091992  \n",
      "Run: 255\t| Iteration: 100 \t| Log-Likelihood:-3.217096575187574 \t|  theta: tensor([[0.0501, 3.2149]], requires_grad=True)  |  Time needed: 0:00:09.167524  \n",
      "Run: 255\t| Iteration: 200 \t| Log-Likelihood:-3.1896568733816526 \t|  theta: tensor([[0.0501, 3.0604]], requires_grad=True)  |  Time needed: 0:00:09.096955  \n",
      "Run: 255\t| Iteration: 300 \t| Log-Likelihood:-3.1874343987657987 \t|  theta: tensor([[0.0501, 3.0164]], requires_grad=True)  |  Time needed: 0:00:09.051258  \n",
      "Run: 255\t| Iteration: 400 \t| Log-Likelihood:-3.1872537437308495 \t|  theta: tensor([[0.0501, 3.0039]], requires_grad=True)  |  Time needed: 0:00:09.102993  \n",
      "Run: 255\t| Iteration: 500 \t| Log-Likelihood:-3.1872390724239246 \t|  theta: tensor([[0.0501, 3.0003]], requires_grad=True)  |  Time needed: 0:00:09.200283  \n",
      "Run: 255\t| Iteration: 600 \t| Log-Likelihood:-3.1872378695867862 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.097127  \n",
      "Run: 255\t| Iteration: 700 \t| Log-Likelihood:-3.1872377238066374 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.102589  \n",
      "Run: 255\t| Iteration: 800 \t| Log-Likelihood:-3.1872377606003703 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.074481  \n",
      "Run: 255\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.080345  \n",
      "Run: 256\t| Iteration: 0 \t| Log-Likelihood:-3.639798094526086 \t|  theta: tensor([[0.2245, 0.8286]], requires_grad=True)  |  Time needed: 0:00:00.088307  \n",
      "Run: 256\t| Iteration: 100 \t| Log-Likelihood:-3.1904860175556897 \t|  theta: tensor([[0.4295, 1.0578]], requires_grad=True)  |  Time needed: 0:00:09.312116  \n",
      "Run: 256\t| Iteration: 200 \t| Log-Likelihood:-3.1904627238585697 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.280516  \n",
      "Run: 256\t| Iteration: 300 \t| Log-Likelihood:-3.1904627327479282 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.311578  \n",
      "Run: 256\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:10.121375  \n",
      "Run: 256\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.610060  \n",
      "Run: 256\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.293646  \n",
      "Run: 256\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.309668  \n",
      "Run: 256\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.411244  \n",
      "Run: 256\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.328376  \n",
      "Run: 257\t| Iteration: 0 \t| Log-Likelihood:-3.7926999001307737 \t|  theta: tensor([[0.1623, 3.9146]], requires_grad=True)  |  Time needed: 0:00:00.089735  \n",
      "Run: 257\t| Iteration: 100 \t| Log-Likelihood:-3.230566505976359 \t|  theta: tensor([[0.0501, 3.2590]], requires_grad=True)  |  Time needed: 0:00:09.164249  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 257\t| Iteration: 200 \t| Log-Likelihood:-3.1907452433529433 \t|  theta: tensor([[0.0501, 3.0729]], requires_grad=True)  |  Time needed: 0:00:09.157523  \n",
      "Run: 257\t| Iteration: 300 \t| Log-Likelihood:-3.1875227751466473 \t|  theta: tensor([[0.0501, 3.0200]], requires_grad=True)  |  Time needed: 0:00:09.195420  \n",
      "Run: 257\t| Iteration: 400 \t| Log-Likelihood:-3.187260928492443 \t|  theta: tensor([[0.0501, 3.0049]], requires_grad=True)  |  Time needed: 0:00:09.145248  \n",
      "Run: 257\t| Iteration: 500 \t| Log-Likelihood:-3.1872396499138045 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.154741  \n",
      "Run: 257\t| Iteration: 600 \t| Log-Likelihood:-3.187237872560408 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.156530  \n",
      "Run: 257\t| Iteration: 700 \t| Log-Likelihood:-3.1872377313833344 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.596356  \n",
      "Run: 257\t| Iteration: 800 \t| Log-Likelihood:-3.187237760935221 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.168267  \n",
      "Run: 257\t| Iteration: 900 \t| Log-Likelihood:-3.1872377562288623 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.226598  \n",
      "Run: 258\t| Iteration: 0 \t| Log-Likelihood:-3.6374403332882532 \t|  theta: tensor([[0.2248, 3.7075]], requires_grad=True)  |  Time needed: 0:00:00.097679  \n",
      "Run: 258\t| Iteration: 100 \t| Log-Likelihood:-3.2131907471066277 \t|  theta: tensor([[0.0501, 3.2002]], requires_grad=True)  |  Time needed: 0:00:09.214973  \n",
      "Run: 258\t| Iteration: 200 \t| Log-Likelihood:-3.189341071827618 \t|  theta: tensor([[0.0501, 3.0562]], requires_grad=True)  |  Time needed: 0:00:09.116642  \n",
      "Run: 258\t| Iteration: 300 \t| Log-Likelihood:-3.187408705979798 \t|  theta: tensor([[0.0501, 3.0152]], requires_grad=True)  |  Time needed: 0:00:09.084472  \n",
      "Run: 258\t| Iteration: 400 \t| Log-Likelihood:-3.187251658231074 \t|  theta: tensor([[0.0501, 3.0035]], requires_grad=True)  |  Time needed: 0:00:09.118801  \n",
      "Run: 258\t| Iteration: 500 \t| Log-Likelihood:-3.1872388811513344 \t|  theta: tensor([[0.0501, 3.0002]], requires_grad=True)  |  Time needed: 0:00:09.099461  \n",
      "Run: 258\t| Iteration: 600 \t| Log-Likelihood:-3.187237852007507 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.170106  \n",
      "Run: 258\t| Iteration: 700 \t| Log-Likelihood:-3.1872377785705313 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.084947  \n",
      "Run: 258\t| Iteration: 800 \t| Log-Likelihood:-3.1872377604935704 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.108070  \n",
      "Run: 258\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.107900  \n",
      "Run: 259\t| Iteration: 0 \t| Log-Likelihood:-3.390829515397285 \t|  theta: tensor([[0.1658, 2.5327]], requires_grad=True)  |  Time needed: 0:00:00.094696  \n",
      "Run: 259\t| Iteration: 100 \t| Log-Likelihood:-3.1991400654736295 \t|  theta: tensor([[0.0502, 2.8622]], requires_grad=True)  |  Time needed: 0:00:09.104189  \n",
      "Run: 259\t| Iteration: 200 \t| Log-Likelihood:-3.188212877646286 \t|  theta: tensor([[0.0501, 2.9598]], requires_grad=True)  |  Time needed: 0:00:09.097188  \n",
      "Run: 259\t| Iteration: 300 \t| Log-Likelihood:-3.187317159732675 \t|  theta: tensor([[0.0501, 2.9877]], requires_grad=True)  |  Time needed: 0:00:09.130975  \n",
      "Run: 259\t| Iteration: 400 \t| Log-Likelihood:-3.187244224113699 \t|  theta: tensor([[0.0501, 2.9957]], requires_grad=True)  |  Time needed: 0:00:09.269251  \n",
      "Run: 259\t| Iteration: 500 \t| Log-Likelihood:-3.1872382857238586 \t|  theta: tensor([[0.0501, 2.9980]], requires_grad=True)  |  Time needed: 0:00:09.131402  \n",
      "Run: 259\t| Iteration: 600 \t| Log-Likelihood:-3.1872377951829143 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.112933  \n",
      "Run: 259\t| Iteration: 700 \t| Log-Likelihood:-3.1872377298572268 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.096877  \n",
      "Run: 259\t| Iteration: 800 \t| Log-Likelihood:-3.187237734120019 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.097504  \n",
      "Run: 259\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.086294  \n",
      "Run: 260\t| Iteration: 0 \t| Log-Likelihood:-3.4035344759609987 \t|  theta: tensor([[0.4180, 0.8551]], requires_grad=True)  |  Time needed: 0:00:00.093141  \n",
      "Run: 260\t| Iteration: 100 \t| Log-Likelihood:-3.1904640718042834 \t|  theta: tensor([[0.4338, 1.0567]], requires_grad=True)  |  Time needed: 0:00:09.121539  \n",
      "Run: 260\t| Iteration: 200 \t| Log-Likelihood:-3.190462704156086 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.108026  \n",
      "Run: 260\t| Iteration: 300 \t| Log-Likelihood:-3.190462702928652 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129061  \n",
      "Run: 260\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104874  \n",
      "Run: 260\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117933  \n",
      "Run: 260\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.139198  \n",
      "Run: 260\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.238540  \n",
      "Run: 260\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.142300  \n",
      "Run: 260\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137528  \n",
      "Run: 261\t| Iteration: 0 \t| Log-Likelihood:-3.429859477516715 \t|  theta: tensor([[0.1496, 1.1799]], requires_grad=True)  |  Time needed: 0:00:00.088109  \n",
      "Run: 261\t| Iteration: 100 \t| Log-Likelihood:-3.1905684546305775 \t|  theta: tensor([[0.4257, 1.0590]], requires_grad=True)  |  Time needed: 0:00:09.265022  \n",
      "Run: 261\t| Iteration: 200 \t| Log-Likelihood:-3.1904627976401074 \t|  theta: tensor([[0.4327, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.356058  \n",
      "Run: 261\t| Iteration: 300 \t| Log-Likelihood:-3.1904627030111916 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.689495  \n",
      "Run: 261\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.253125  \n",
      "Run: 261\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.258729  \n",
      "Run: 261\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.262216  \n",
      "Run: 261\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.236017  \n",
      "Run: 261\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.258891  \n",
      "Run: 261\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.403102  \n",
      "Run: 262\t| Iteration: 0 \t| Log-Likelihood:-3.505357691732516 \t|  theta: tensor([[0.3206, 2.6461]], requires_grad=True)  |  Time needed: 0:00:00.091520  \n",
      "Run: 262\t| Iteration: 100 \t| Log-Likelihood:-3.1939408048120375 \t|  theta: tensor([[0.0501, 2.8964]], requires_grad=True)  |  Time needed: 0:00:09.131424  \n",
      "Run: 262\t| Iteration: 200 \t| Log-Likelihood:-3.1877854354751043 \t|  theta: tensor([[0.0501, 2.9696]], requires_grad=True)  |  Time needed: 0:00:09.186536  \n",
      "Run: 262\t| Iteration: 300 \t| Log-Likelihood:-3.187282337132475 \t|  theta: tensor([[0.0501, 2.9905]], requires_grad=True)  |  Time needed: 0:00:09.184973  \n",
      "Run: 262\t| Iteration: 400 \t| Log-Likelihood:-3.187241356669997 \t|  theta: tensor([[0.0501, 2.9965]], requires_grad=True)  |  Time needed: 0:00:09.120089  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 262\t| Iteration: 500 \t| Log-Likelihood:-3.1872380368615527 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.123845  \n",
      "Run: 262\t| Iteration: 600 \t| Log-Likelihood:-3.187237787574039 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.169131  \n",
      "Run: 262\t| Iteration: 700 \t| Log-Likelihood:-3.1872377320598737 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.110103  \n",
      "Run: 262\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339847713 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.100334  \n",
      "Run: 262\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.137548  \n",
      "Run: 263\t| Iteration: 0 \t| Log-Likelihood:-4.12112356233788 \t|  theta: tensor([[0.1527, 4.1665]], requires_grad=True)  |  Time needed: 0:00:00.092597  \n",
      "Run: 263\t| Iteration: 100 \t| Log-Likelihood:-3.2576515088121276 \t|  theta: tensor([[0.0501, 3.3304]], requires_grad=True)  |  Time needed: 0:00:09.101066  \n",
      "Run: 263\t| Iteration: 200 \t| Log-Likelihood:-3.192931582440883 \t|  theta: tensor([[0.0501, 3.0932]], requires_grad=True)  |  Time needed: 0:00:09.108944  \n",
      "Run: 263\t| Iteration: 300 \t| Log-Likelihood:-3.1877002597880653 \t|  theta: tensor([[0.0501, 3.0258]], requires_grad=True)  |  Time needed: 0:00:09.206278  \n",
      "Run: 263\t| Iteration: 400 \t| Log-Likelihood:-3.187275356692717 \t|  theta: tensor([[0.0501, 3.0065]], requires_grad=True)  |  Time needed: 0:00:09.141364  \n",
      "Run: 263\t| Iteration: 500 \t| Log-Likelihood:-3.1872407851870177 \t|  theta: tensor([[0.0501, 3.0011]], requires_grad=True)  |  Time needed: 0:00:09.108108  \n",
      "Run: 263\t| Iteration: 600 \t| Log-Likelihood:-3.1872379897870657 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.146542  \n",
      "Run: 263\t| Iteration: 700 \t| Log-Likelihood:-3.187237746470078 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.116789  \n",
      "Run: 263\t| Iteration: 800 \t| Log-Likelihood:-3.1872377652669885 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.124165  \n",
      "Run: 263\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563029333 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.137307  \n",
      "Run: 264\t| Iteration: 0 \t| Log-Likelihood:-3.6657799704807 \t|  theta: tensor([[0.0360, 3.8454]], requires_grad=True)  |  Time needed: 0:00:00.094930  \n",
      "Run: 264\t| Iteration: 100 \t| Log-Likelihood:-3.2242647040549977 \t|  theta: tensor([[0.0501, 3.2394]], requires_grad=True)  |  Time needed: 0:00:09.135169  \n",
      "Run: 264\t| Iteration: 200 \t| Log-Likelihood:-3.1902361225734337 \t|  theta: tensor([[0.0501, 3.0674]], requires_grad=True)  |  Time needed: 0:00:09.165361  \n",
      "Run: 264\t| Iteration: 300 \t| Log-Likelihood:-3.1874814058212895 \t|  theta: tensor([[0.0501, 3.0184]], requires_grad=True)  |  Time needed: 0:00:09.121721  \n",
      "Run: 264\t| Iteration: 400 \t| Log-Likelihood:-3.18725755407201 \t|  theta: tensor([[0.0501, 3.0044]], requires_grad=True)  |  Time needed: 0:00:09.219159  \n",
      "Run: 264\t| Iteration: 500 \t| Log-Likelihood:-3.1872393539047184 \t|  theta: tensor([[0.0501, 3.0005]], requires_grad=True)  |  Time needed: 0:00:09.205430  \n",
      "Run: 264\t| Iteration: 600 \t| Log-Likelihood:-3.1872378425419736 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.256548  \n",
      "Run: 264\t| Iteration: 700 \t| Log-Likelihood:-3.1872377259150984 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.200809  \n",
      "Run: 264\t| Iteration: 800 \t| Log-Likelihood:-3.1872377607822893 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.128451  \n",
      "Run: 264\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.693488  \n",
      "Run: 265\t| Iteration: 0 \t| Log-Likelihood:-5.685028084591986 \t|  theta: tensor([[0.2821, 4.8948]], requires_grad=True)  |  Time needed: 0:00:00.092303  \n",
      "Run: 265\t| Iteration: 100 \t| Log-Likelihood:-3.372974685023314 \t|  theta: tensor([[0.0501, 3.5372]], requires_grad=True)  |  Time needed: 0:00:09.108535  \n",
      "Run: 265\t| Iteration: 200 \t| Log-Likelihood:-3.202225771554605 \t|  theta: tensor([[0.0501, 3.1519]], requires_grad=True)  |  Time needed: 0:00:09.111556  \n",
      "Run: 265\t| Iteration: 300 \t| Log-Likelihood:-3.1884536632463374 \t|  theta: tensor([[0.0501, 3.0425]], requires_grad=True)  |  Time needed: 0:00:09.085180  \n",
      "Run: 265\t| Iteration: 400 \t| Log-Likelihood:-3.187336577323274 \t|  theta: tensor([[0.0501, 3.0113]], requires_grad=True)  |  Time needed: 0:00:09.108426  \n",
      "Run: 265\t| Iteration: 500 \t| Log-Likelihood:-3.1872457766913738 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.100750  \n",
      "Run: 265\t| Iteration: 600 \t| Log-Likelihood:-3.187238403061579 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.074085  \n",
      "Run: 265\t| Iteration: 700 \t| Log-Likelihood:-3.1872377981054933 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.076088  \n",
      "Run: 265\t| Iteration: 800 \t| Log-Likelihood:-3.1872377716595626 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.179751  \n",
      "Run: 265\t| Iteration: 900 \t| Log-Likelihood:-3.1872377565351164 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.102984  \n",
      "Run: 266\t| Iteration: 0 \t| Log-Likelihood:-5.0227729853634315 \t|  theta: tensor([[0.4518, 0.5002]], requires_grad=True)  |  Time needed: 0:00:00.096920  \n",
      "Run: 266\t| Iteration: 100 \t| Log-Likelihood:-3.190484786319635 \t|  theta: tensor([[0.4363, 1.0560]], requires_grad=True)  |  Time needed: 0:00:09.389096  \n",
      "Run: 266\t| Iteration: 200 \t| Log-Likelihood:-3.190462722848572 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.329699  \n",
      "Run: 266\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731424166 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.285776  \n",
      "Run: 266\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.276690  \n",
      "Run: 266\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.286441  \n",
      "Run: 266\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.302393  \n",
      "Run: 266\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.291850  \n",
      "Run: 266\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.316205  \n",
      "Run: 266\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.281444  \n",
      "Run: 267\t| Iteration: 0 \t| Log-Likelihood:-3.8398120209765962 \t|  theta: tensor([[0.4919, 2.5131]], requires_grad=True)  |  Time needed: 0:00:00.086504  \n",
      "Run: 267\t| Iteration: 100 \t| Log-Likelihood:-3.200538653308705 \t|  theta: tensor([[0.0502, 2.8544]], requires_grad=True)  |  Time needed: 0:00:09.168073  \n",
      "Run: 267\t| Iteration: 200 \t| Log-Likelihood:-3.1883283247197127 \t|  theta: tensor([[0.0501, 2.9576]], requires_grad=True)  |  Time needed: 0:00:09.307003  \n",
      "Run: 267\t| Iteration: 300 \t| Log-Likelihood:-3.18732656746694 \t|  theta: tensor([[0.0501, 2.9871]], requires_grad=True)  |  Time needed: 0:00:09.229516  \n",
      "Run: 267\t| Iteration: 400 \t| Log-Likelihood:-3.187244951611977 \t|  theta: tensor([[0.0501, 2.9955]], requires_grad=True)  |  Time needed: 0:00:09.141256  \n",
      "Run: 267\t| Iteration: 500 \t| Log-Likelihood:-3.187238340334122 \t|  theta: tensor([[0.0501, 2.9979]], requires_grad=True)  |  Time needed: 0:00:09.179477  \n",
      "Run: 267\t| Iteration: 600 \t| Log-Likelihood:-3.187237796502133 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.318752  \n",
      "Run: 267\t| Iteration: 700 \t| Log-Likelihood:-3.18723772654454 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.385307  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 267\t| Iteration: 800 \t| Log-Likelihood:-3.187237734154381 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.187810  \n",
      "Run: 267\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.193340  \n",
      "Run: 268\t| Iteration: 0 \t| Log-Likelihood:-3.2351037086723995 \t|  theta: tensor([[0.4229, 1.1656]], requires_grad=True)  |  Time needed: 0:00:00.093716  \n",
      "Run: 268\t| Iteration: 100 \t| Log-Likelihood:-3.190465575765672 \t|  theta: tensor([[0.4317, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.172325  \n",
      "Run: 268\t| Iteration: 200 \t| Log-Likelihood:-3.1904627353292523 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.586319  \n",
      "Run: 268\t| Iteration: 300 \t| Log-Likelihood:-3.190462673127851 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.129917  \n",
      "Run: 268\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.143394  \n",
      "Run: 268\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.225901  \n",
      "Run: 268\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.195546  \n",
      "Run: 268\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.087935  \n",
      "Run: 268\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.112211  \n",
      "Run: 268\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119653  \n",
      "Run: 269\t| Iteration: 0 \t| Log-Likelihood:-7.101413713157374 \t|  theta: tensor([[0.2703, 0.2849]], requires_grad=True)  |  Time needed: 0:00:00.091703  \n",
      "Run: 269\t| Iteration: 100 \t| Log-Likelihood:-3.190463060933181 \t|  theta: tensor([[0.4325, 1.0569]], requires_grad=True)  |  Time needed: 0:00:09.217522  \n",
      "Run: 269\t| Iteration: 200 \t| Log-Likelihood:-3.1904627031483277 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.102032  \n",
      "Run: 269\t| Iteration: 300 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.094211  \n",
      "Run: 269\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.137789  \n",
      "Run: 269\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105856  \n",
      "Run: 269\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.115669  \n",
      "Run: 269\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082338  \n",
      "Run: 269\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.162529  \n",
      "Run: 269\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.175490  \n",
      "Run: 270\t| Iteration: 0 \t| Log-Likelihood:-3.394330118310953 \t|  theta: tensor([[0.1230, 2.4668]], requires_grad=True)  |  Time needed: 0:00:00.096372  \n",
      "Run: 270\t| Iteration: 100 \t| Log-Likelihood:-3.2029872197531146 \t|  theta: tensor([[0.0502, 2.8416]], requires_grad=True)  |  Time needed: 0:00:09.126470  \n",
      "Run: 270\t| Iteration: 200 \t| Log-Likelihood:-3.1885307224477484 \t|  theta: tensor([[0.0501, 2.9539]], requires_grad=True)  |  Time needed: 0:00:09.105791  \n",
      "Run: 270\t| Iteration: 300 \t| Log-Likelihood:-3.187343037812152 \t|  theta: tensor([[0.0501, 2.9860]], requires_grad=True)  |  Time needed: 0:00:09.097048  \n",
      "Run: 270\t| Iteration: 400 \t| Log-Likelihood:-3.187246304199077 \t|  theta: tensor([[0.0501, 2.9952]], requires_grad=True)  |  Time needed: 0:00:09.127988  \n",
      "Run: 270\t| Iteration: 500 \t| Log-Likelihood:-3.187238433938049 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.114643  \n",
      "Run: 270\t| Iteration: 600 \t| Log-Likelihood:-3.187237801629999 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.128869  \n",
      "Run: 270\t| Iteration: 700 \t| Log-Likelihood:-3.187237727206493 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.135749  \n",
      "Run: 270\t| Iteration: 800 \t| Log-Likelihood:-3.187237734197954 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.116550  \n",
      "Run: 270\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.124087  \n",
      "Run: 271\t| Iteration: 0 \t| Log-Likelihood:-3.718051921097648 \t|  theta: tensor([[0.1396, 0.8975]], requires_grad=True)  |  Time needed: 0:00:00.088629  \n",
      "Run: 271\t| Iteration: 100 \t| Log-Likelihood:-3.190511735658207 \t|  theta: tensor([[0.4280, 1.0583]], requires_grad=True)  |  Time needed: 0:00:09.273909  \n",
      "Run: 271\t| Iteration: 200 \t| Log-Likelihood:-3.190462746911714 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.300009  \n",
      "Run: 271\t| Iteration: 300 \t| Log-Likelihood:-3.190462702965677 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.296413  \n",
      "Run: 271\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.278910  \n",
      "Run: 271\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.251282  \n",
      "Run: 271\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.265556  \n",
      "Run: 271\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.738657  \n",
      "Run: 271\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.435493  \n",
      "Run: 271\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.264014  \n",
      "Run: 272\t| Iteration: 0 \t| Log-Likelihood:-3.7772154240152234 \t|  theta: tensor([[0.4823, 2.6025]], requires_grad=True)  |  Time needed: 0:00:00.088222  \n",
      "Run: 272\t| Iteration: 100 \t| Log-Likelihood:-3.195842802886969 \t|  theta: tensor([[0.0502, 2.8827]], requires_grad=True)  |  Time needed: 0:00:09.111369  \n",
      "Run: 272\t| Iteration: 200 \t| Log-Likelihood:-3.1879415591170006 \t|  theta: tensor([[0.0501, 2.9657]], requires_grad=True)  |  Time needed: 0:00:09.105024  \n",
      "Run: 272\t| Iteration: 300 \t| Log-Likelihood:-3.187295076268571 \t|  theta: tensor([[0.0501, 2.9894]], requires_grad=True)  |  Time needed: 0:00:09.161172  \n",
      "Run: 272\t| Iteration: 400 \t| Log-Likelihood:-3.1872423965340917 \t|  theta: tensor([[0.0501, 2.9962]], requires_grad=True)  |  Time needed: 0:00:09.119251  \n",
      "Run: 272\t| Iteration: 500 \t| Log-Likelihood:-3.1872381022882785 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.179003  \n",
      "Run: 272\t| Iteration: 600 \t| Log-Likelihood:-3.1872377906884655 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.150347  \n",
      "Run: 272\t| Iteration: 700 \t| Log-Likelihood:-3.1872377288691967 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.234960  \n",
      "Run: 272\t| Iteration: 800 \t| Log-Likelihood:-3.1872377340389684 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.110076  \n",
      "Run: 272\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.136966  \n",
      "Run: 273\t| Iteration: 0 \t| Log-Likelihood:-4.533917043400455 \t|  theta: tensor([[0.4174, 0.5780]], requires_grad=True)  |  Time needed: 0:00:00.095034  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 273\t| Iteration: 100 \t| Log-Likelihood:-3.190471199072389 \t|  theta: tensor([[0.4350, 1.0564]], requires_grad=True)  |  Time needed: 0:00:09.158738  \n",
      "Run: 273\t| Iteration: 200 \t| Log-Likelihood:-3.1904627105735757 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.080767  \n",
      "Run: 273\t| Iteration: 300 \t| Log-Likelihood:-3.19046270293489 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.121198  \n",
      "Run: 273\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.081787  \n",
      "Run: 273\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099511  \n",
      "Run: 273\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105494  \n",
      "Run: 273\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.093546  \n",
      "Run: 273\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.151553  \n",
      "Run: 273\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.147075  \n",
      "Run: 274\t| Iteration: 0 \t| Log-Likelihood:-4.076829549509251 \t|  theta: tensor([[0.4771, 3.7930]], requires_grad=True)  |  Time needed: 0:00:00.096508  \n",
      "Run: 274\t| Iteration: 100 \t| Log-Likelihood:-3.21982996112947 \t|  theta: tensor([[0.0501, 3.2245]], requires_grad=True)  |  Time needed: 0:00:09.118422  \n",
      "Run: 274\t| Iteration: 200 \t| Log-Likelihood:-3.1898777549493476 \t|  theta: tensor([[0.0501, 3.0631]], requires_grad=True)  |  Time needed: 0:00:09.108246  \n",
      "Run: 274\t| Iteration: 300 \t| Log-Likelihood:-3.187452335948939 \t|  theta: tensor([[0.0501, 3.0172]], requires_grad=True)  |  Time needed: 0:00:09.279084  \n",
      "Run: 274\t| Iteration: 400 \t| Log-Likelihood:-3.1872551794209016 \t|  theta: tensor([[0.0501, 3.0041]], requires_grad=True)  |  Time needed: 0:00:09.219022  \n",
      "Run: 274\t| Iteration: 500 \t| Log-Likelihood:-3.1872391420836124 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.126728  \n",
      "Run: 274\t| Iteration: 600 \t| Log-Likelihood:-3.187237882703042 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.129542  \n",
      "Run: 274\t| Iteration: 700 \t| Log-Likelihood:-3.1872377245566534 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.146134  \n",
      "Run: 274\t| Iteration: 800 \t| Log-Likelihood:-3.1872377606727973 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.139781  \n",
      "Run: 274\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.136148  \n",
      "Run: 275\t| Iteration: 0 \t| Log-Likelihood:-3.79217313424321 \t|  theta: tensor([[0.4950, 2.6232]], requires_grad=True)  |  Time needed: 0:00:00.093306  \n",
      "Run: 275\t| Iteration: 100 \t| Log-Likelihood:-3.194934828580655 \t|  theta: tensor([[0.0501, 2.8890]], requires_grad=True)  |  Time needed: 0:00:09.125588  \n",
      "Run: 275\t| Iteration: 200 \t| Log-Likelihood:-3.187867006599989 \t|  theta: tensor([[0.0501, 2.9675]], requires_grad=True)  |  Time needed: 0:00:09.074821  \n",
      "Run: 275\t| Iteration: 300 \t| Log-Likelihood:-3.1872889812760437 \t|  theta: tensor([[0.0501, 2.9899]], requires_grad=True)  |  Time needed: 0:00:09.456937  \n",
      "Run: 275\t| Iteration: 400 \t| Log-Likelihood:-3.18724192665443 \t|  theta: tensor([[0.0501, 2.9963]], requires_grad=True)  |  Time needed: 0:00:09.168209  \n",
      "Run: 275\t| Iteration: 500 \t| Log-Likelihood:-3.1872380691339037 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.075095  \n",
      "Run: 275\t| Iteration: 600 \t| Log-Likelihood:-3.1872377875357816 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.112222  \n",
      "Run: 275\t| Iteration: 700 \t| Log-Likelihood:-3.1872377286297007 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.066618  \n",
      "Run: 275\t| Iteration: 800 \t| Log-Likelihood:-3.1872377340164393 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.074732  \n",
      "Run: 275\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.133870  \n",
      "Run: 276\t| Iteration: 0 \t| Log-Likelihood:-3.4118386203511584 \t|  theta: tensor([[0.2488, 2.6624]], requires_grad=True)  |  Time needed: 0:00:00.089988  \n",
      "Run: 276\t| Iteration: 100 \t| Log-Likelihood:-3.193297387817293 \t|  theta: tensor([[0.0501, 2.9014]], requires_grad=True)  |  Time needed: 0:00:09.243881  \n",
      "Run: 276\t| Iteration: 200 \t| Log-Likelihood:-3.187732669433267 \t|  theta: tensor([[0.0501, 2.9710]], requires_grad=True)  |  Time needed: 0:00:09.262051  \n",
      "Run: 276\t| Iteration: 300 \t| Log-Likelihood:-3.187278058006823 \t|  theta: tensor([[0.0501, 2.9909]], requires_grad=True)  |  Time needed: 0:00:09.365468  \n",
      "Run: 276\t| Iteration: 400 \t| Log-Likelihood:-3.187241027879254 \t|  theta: tensor([[0.0501, 2.9966]], requires_grad=True)  |  Time needed: 0:00:09.322561  \n",
      "Run: 276\t| Iteration: 500 \t| Log-Likelihood:-3.1872380122367816 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.279359  \n",
      "Run: 276\t| Iteration: 600 \t| Log-Likelihood:-3.187237789024741 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.283388  \n",
      "Run: 276\t| Iteration: 700 \t| Log-Likelihood:-3.187237731863886 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.480445  \n",
      "Run: 276\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339650764 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.822827  \n",
      "Run: 276\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.893371  \n",
      "Run: 277\t| Iteration: 0 \t| Log-Likelihood:-4.5563983556404075 \t|  theta: tensor([[0.3629, 4.2902]], requires_grad=True)  |  Time needed: 0:00:00.102521  \n",
      "Run: 277\t| Iteration: 100 \t| Log-Likelihood:-3.2733572963433146 \t|  theta: tensor([[0.0501, 3.3655]], requires_grad=True)  |  Time needed: 0:00:09.565901  \n",
      "Run: 277\t| Iteration: 200 \t| Log-Likelihood:-3.194198435496022 \t|  theta: tensor([[0.0501, 3.1032]], requires_grad=True)  |  Time needed: 0:00:09.180270  \n",
      "Run: 277\t| Iteration: 300 \t| Log-Likelihood:-3.1878031045496913 \t|  theta: tensor([[0.0501, 3.0286]], requires_grad=True)  |  Time needed: 0:00:09.122039  \n",
      "Run: 277\t| Iteration: 400 \t| Log-Likelihood:-3.187283745006258 \t|  theta: tensor([[0.0501, 3.0074]], requires_grad=True)  |  Time needed: 0:00:09.258409  \n",
      "Run: 277\t| Iteration: 500 \t| Log-Likelihood:-3.1872415054444763 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.129722  \n",
      "Run: 277\t| Iteration: 600 \t| Log-Likelihood:-3.187238056290388 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.197007  \n",
      "Run: 277\t| Iteration: 700 \t| Log-Likelihood:-3.1872377509684253 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.198108  \n",
      "Run: 277\t| Iteration: 800 \t| Log-Likelihood:-3.1872377656556163 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.189045  \n",
      "Run: 277\t| Iteration: 900 \t| Log-Likelihood:-3.187237756341774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.213773  \n",
      "Run: 278\t| Iteration: 0 \t| Log-Likelihood:-3.7274851641163753 \t|  theta: tensor([[0.4885, 2.7658]], requires_grad=True)  |  Time needed: 0:00:00.093352  \n",
      "Run: 278\t| Iteration: 100 \t| Log-Likelihood:-3.1901270018111925 \t|  theta: tensor([[0.0501, 2.9316]], requires_grad=True)  |  Time needed: 0:00:09.091070  \n",
      "Run: 278\t| Iteration: 200 \t| Log-Likelihood:-3.187473335740147 \t|  theta: tensor([[0.0501, 2.9797]], requires_grad=True)  |  Time needed: 0:00:09.149749  \n",
      "Run: 278\t| Iteration: 300 \t| Log-Likelihood:-3.1872569263518256 \t|  theta: tensor([[0.0501, 2.9934]], requires_grad=True)  |  Time needed: 0:00:09.448035  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 278\t| Iteration: 400 \t| Log-Likelihood:-3.1872393119358122 \t|  theta: tensor([[0.0501, 2.9973]], requires_grad=True)  |  Time needed: 0:00:09.089573  \n",
      "Run: 278\t| Iteration: 500 \t| Log-Likelihood:-3.1872378457963277 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.154541  \n",
      "Run: 278\t| Iteration: 600 \t| Log-Likelihood:-3.187237725489066 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.090995  \n",
      "Run: 278\t| Iteration: 700 \t| Log-Likelihood:-3.187237730957153 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.079005  \n",
      "Run: 278\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.094429  \n",
      "Run: 278\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.586045  \n",
      "Run: 279\t| Iteration: 0 \t| Log-Likelihood:-4.177404050305483 \t|  theta: tensor([[0.5556, 1.8809]], requires_grad=True)  |  Time needed: 0:00:00.096981  \n",
      "Run: 279\t| Iteration: 100 \t| Log-Likelihood:-3.7023102514933397 \t|  theta: tensor([[0.1643, 1.6505]], requires_grad=True)  |  Time needed: 0:00:09.207627  \n",
      "Run: 279\t| Iteration: 200 \t| Log-Likelihood:-3.1924575686817254 \t|  theta: tensor([[0.4031, 1.0696]], requires_grad=True)  |  Time needed: 0:00:09.140637  \n",
      "Run: 279\t| Iteration: 300 \t| Log-Likelihood:-3.190464385558594 \t|  theta: tensor([[0.4320, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.103799  \n",
      "Run: 279\t| Iteration: 400 \t| Log-Likelihood:-3.190462674644802 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.101597  \n",
      "Run: 279\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731270542 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.171916  \n",
      "Run: 279\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.105021  \n",
      "Run: 279\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082239  \n",
      "Run: 279\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.174975  \n",
      "Run: 279\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.130221  \n",
      "Run: 280\t| Iteration: 0 \t| Log-Likelihood:-3.9690704446379974 \t|  theta: tensor([[0.4294, 3.7689]], requires_grad=True)  |  Time needed: 0:00:00.092159  \n",
      "Run: 280\t| Iteration: 100 \t| Log-Likelihood:-3.2178813475343424 \t|  theta: tensor([[0.0501, 3.2177]], requires_grad=True)  |  Time needed: 0:00:09.121238  \n",
      "Run: 280\t| Iteration: 200 \t| Log-Likelihood:-3.1897202791562305 \t|  theta: tensor([[0.0501, 3.0612]], requires_grad=True)  |  Time needed: 0:00:09.184722  \n",
      "Run: 280\t| Iteration: 300 \t| Log-Likelihood:-3.187439504169656 \t|  theta: tensor([[0.0501, 3.0166]], requires_grad=True)  |  Time needed: 0:00:09.214206  \n",
      "Run: 280\t| Iteration: 400 \t| Log-Likelihood:-3.187254171591861 \t|  theta: tensor([[0.0501, 3.0039]], requires_grad=True)  |  Time needed: 0:00:09.134309  \n",
      "Run: 280\t| Iteration: 500 \t| Log-Likelihood:-3.187239050257978 \t|  theta: tensor([[0.0501, 3.0003]], requires_grad=True)  |  Time needed: 0:00:09.123982  \n",
      "Run: 280\t| Iteration: 600 \t| Log-Likelihood:-3.1872378723001566 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.109596  \n",
      "Run: 280\t| Iteration: 700 \t| Log-Likelihood:-3.187237724017739 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.225174  \n",
      "Run: 280\t| Iteration: 800 \t| Log-Likelihood:-3.1872377606207096 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.139448  \n",
      "Run: 280\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.103585  \n",
      "Run: 281\t| Iteration: 0 \t| Log-Likelihood:-4.951023196399348 \t|  theta: tensor([[0.4924, 4.3945]], requires_grad=True)  |  Time needed: 0:00:00.091249  \n",
      "Run: 281\t| Iteration: 100 \t| Log-Likelihood:-3.2878295235682056 \t|  theta: tensor([[0.0501, 3.3951]], requires_grad=True)  |  Time needed: 0:00:09.270154  \n",
      "Run: 281\t| Iteration: 200 \t| Log-Likelihood:-3.1953653477536124 \t|  theta: tensor([[0.0501, 3.1116]], requires_grad=True)  |  Time needed: 0:00:09.302493  \n",
      "Run: 281\t| Iteration: 300 \t| Log-Likelihood:-3.187897714802624 \t|  theta: tensor([[0.0501, 3.0310]], requires_grad=True)  |  Time needed: 0:00:09.257934  \n",
      "Run: 281\t| Iteration: 400 \t| Log-Likelihood:-3.187291434085646 \t|  theta: tensor([[0.0501, 3.0080]], requires_grad=True)  |  Time needed: 0:00:09.243681  \n",
      "Run: 281\t| Iteration: 500 \t| Log-Likelihood:-3.1872421094784356 \t|  theta: tensor([[0.0501, 3.0015]], requires_grad=True)  |  Time needed: 0:00:09.387133  \n",
      "Run: 281\t| Iteration: 600 \t| Log-Likelihood:-3.1872381188626586 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.379018  \n",
      "Run: 281\t| Iteration: 700 \t| Log-Likelihood:-3.1872377590017926 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.282868  \n",
      "Run: 281\t| Iteration: 800 \t| Log-Likelihood:-3.1872377659922275 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.283830  \n",
      "Run: 281\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563794796 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.314340  \n",
      "Run: 282\t| Iteration: 0 \t| Log-Likelihood:-3.313183875490398 \t|  theta: tensor([[0.1746, 2.7245]], requires_grad=True)  |  Time needed: 0:00:00.089886  \n",
      "Run: 282\t| Iteration: 100 \t| Log-Likelihood:-3.1912241060164934 \t|  theta: tensor([[0.0501, 2.9199]], requires_grad=True)  |  Time needed: 0:00:09.173732  \n",
      "Run: 282\t| Iteration: 200 \t| Log-Likelihood:-3.1875629540552124 \t|  theta: tensor([[0.0501, 2.9763]], requires_grad=True)  |  Time needed: 0:00:09.116604  \n",
      "Run: 282\t| Iteration: 300 \t| Log-Likelihood:-3.1872642300003022 \t|  theta: tensor([[0.0501, 2.9924]], requires_grad=True)  |  Time needed: 0:00:09.104831  \n",
      "Run: 282\t| Iteration: 400 \t| Log-Likelihood:-3.1872399183330127 \t|  theta: tensor([[0.0501, 2.9970]], requires_grad=True)  |  Time needed: 0:00:09.077569  \n",
      "Run: 282\t| Iteration: 500 \t| Log-Likelihood:-3.1872379423373203 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.541118  \n",
      "Run: 282\t| Iteration: 600 \t| Log-Likelihood:-3.1872377256703013 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.111741  \n",
      "Run: 282\t| Iteration: 700 \t| Log-Likelihood:-3.1872377312582842 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.091364  \n",
      "Run: 282\t| Iteration: 800 \t| Log-Likelihood:-3.1872377376193115 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.117080  \n",
      "Run: 282\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.232219  \n",
      "Run: 283\t| Iteration: 0 \t| Log-Likelihood:-3.797949929918655 \t|  theta: tensor([[0.2598, 1.8691]], requires_grad=True)  |  Time needed: 0:00:00.091928  \n",
      "Run: 283\t| Iteration: 100 \t| Log-Likelihood:-3.4612316041896767 \t|  theta: tensor([[0.0573, 2.3186]], requires_grad=True)  |  Time needed: 0:00:09.106191  \n",
      "Run: 283\t| Iteration: 200 \t| Log-Likelihood:-3.214454825320227 \t|  theta: tensor([[0.0502, 2.7919]], requires_grad=True)  |  Time needed: 0:00:09.084599  \n",
      "Run: 283\t| Iteration: 300 \t| Log-Likelihood:-3.189484896977421 \t|  theta: tensor([[0.0501, 2.9396]], requires_grad=True)  |  Time needed: 0:00:09.056263  \n",
      "Run: 283\t| Iteration: 400 \t| Log-Likelihood:-3.1874209037763883 \t|  theta: tensor([[0.0501, 2.9819]], requires_grad=True)  |  Time needed: 0:00:09.180188  \n",
      "Run: 283\t| Iteration: 500 \t| Log-Likelihood:-3.187252656852487 \t|  theta: tensor([[0.0501, 2.9940]], requires_grad=True)  |  Time needed: 0:00:09.077178  \n",
      "Run: 283\t| Iteration: 600 \t| Log-Likelihood:-3.1872389407159294 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.090077  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 283\t| Iteration: 700 \t| Log-Likelihood:-3.187237828829214 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.081962  \n",
      "Run: 283\t| Iteration: 800 \t| Log-Likelihood:-3.1872377269465946 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.114103  \n",
      "Run: 283\t| Iteration: 900 \t| Log-Likelihood:-3.1872377344734257 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.206294  \n",
      "Run: 284\t| Iteration: 0 \t| Log-Likelihood:-3.705371129682349 \t|  theta: tensor([[0.5119, 0.7451]], requires_grad=True)  |  Time needed: 0:00:00.091848  \n",
      "Run: 284\t| Iteration: 100 \t| Log-Likelihood:-3.1904937707400562 \t|  theta: tensor([[0.4369, 1.0559]], requires_grad=True)  |  Time needed: 0:00:09.164342  \n",
      "Run: 284\t| Iteration: 200 \t| Log-Likelihood:-3.1904627011943467 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.277532  \n",
      "Run: 284\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731499137 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.170057  \n",
      "Run: 284\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135152  \n",
      "Run: 284\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116215  \n",
      "Run: 284\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.124719  \n",
      "Run: 284\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116616  \n",
      "Run: 284\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.457995  \n",
      "Run: 284\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.126785  \n",
      "Run: 285\t| Iteration: 0 \t| Log-Likelihood:-3.368982217313977 \t|  theta: tensor([[0.0446, 2.4564]], requires_grad=True)  |  Time needed: 0:00:00.091255  \n",
      "Run: 285\t| Iteration: 100 \t| Log-Likelihood:-3.203581736479882 \t|  theta: tensor([[0.0502, 2.8387]], requires_grad=True)  |  Time needed: 0:00:09.087794  \n",
      "Run: 285\t| Iteration: 200 \t| Log-Likelihood:-3.188579927432757 \t|  theta: tensor([[0.0501, 2.9530]], requires_grad=True)  |  Time needed: 0:00:09.039162  \n",
      "Run: 285\t| Iteration: 300 \t| Log-Likelihood:-3.18734706143969 \t|  theta: tensor([[0.0501, 2.9858]], requires_grad=True)  |  Time needed: 0:00:09.059252  \n",
      "Run: 285\t| Iteration: 400 \t| Log-Likelihood:-3.1872466167948525 \t|  theta: tensor([[0.0501, 2.9951]], requires_grad=True)  |  Time needed: 0:00:09.076777  \n",
      "Run: 285\t| Iteration: 500 \t| Log-Likelihood:-3.187238457492363 \t|  theta: tensor([[0.0501, 2.9978]], requires_grad=True)  |  Time needed: 0:00:09.267846  \n",
      "Run: 285\t| Iteration: 600 \t| Log-Likelihood:-3.187237803800862 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.054641  \n",
      "Run: 285\t| Iteration: 700 \t| Log-Likelihood:-3.187237727438623 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.226163  \n",
      "Run: 285\t| Iteration: 800 \t| Log-Likelihood:-3.1872377342130447 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.076811  \n",
      "Run: 285\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.085502  \n",
      "Run: 286\t| Iteration: 0 \t| Log-Likelihood:-3.239163193766831 \t|  theta: tensor([[0.1319, 2.8766]], requires_grad=True)  |  Time needed: 0:00:00.093526  \n",
      "Run: 286\t| Iteration: 100 \t| Log-Likelihood:-3.1880191841096392 \t|  theta: tensor([[0.0501, 2.9639]], requires_grad=True)  |  Time needed: 0:00:09.718415  \n",
      "Run: 286\t| Iteration: 200 \t| Log-Likelihood:-3.1873013633906675 \t|  theta: tensor([[0.0501, 2.9889]], requires_grad=True)  |  Time needed: 0:00:09.270173  \n",
      "Run: 286\t| Iteration: 300 \t| Log-Likelihood:-3.187242940161242 \t|  theta: tensor([[0.0501, 2.9960]], requires_grad=True)  |  Time needed: 0:00:09.274109  \n",
      "Run: 286\t| Iteration: 400 \t| Log-Likelihood:-3.1872381360272435 \t|  theta: tensor([[0.0501, 2.9981]], requires_grad=True)  |  Time needed: 0:00:09.290775  \n",
      "Run: 286\t| Iteration: 500 \t| Log-Likelihood:-3.1872377903555797 \t|  theta: tensor([[0.0501, 2.9986]], requires_grad=True)  |  Time needed: 0:00:09.259367  \n",
      "Run: 286\t| Iteration: 600 \t| Log-Likelihood:-3.187237729120667 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.265635  \n",
      "Run: 286\t| Iteration: 700 \t| Log-Likelihood:-3.187237734062632 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.280830  \n",
      "Run: 286\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.340135  \n",
      "Run: 286\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.269422  \n",
      "Run: 287\t| Iteration: 0 \t| Log-Likelihood:-3.2382220313083465 \t|  theta: tensor([[0.2899, 1.1166]], requires_grad=True)  |  Time needed: 0:00:00.087550  \n",
      "Run: 287\t| Iteration: 100 \t| Log-Likelihood:-3.190496915301688 \t|  theta: tensor([[0.4288, 1.0581]], requires_grad=True)  |  Time needed: 0:00:09.129945  \n",
      "Run: 287\t| Iteration: 200 \t| Log-Likelihood:-3.1904627634411344 \t|  theta: tensor([[0.4328, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.223520  \n",
      "Run: 287\t| Iteration: 300 \t| Log-Likelihood:-3.1904626731520898 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127231  \n",
      "Run: 287\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.145502  \n",
      "Run: 287\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.117737  \n",
      "Run: 287\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.135512  \n",
      "Run: 287\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.180689  \n",
      "Run: 287\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.144283  \n",
      "Run: 287\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.159971  \n",
      "Run: 288\t| Iteration: 0 \t| Log-Likelihood:-3.5624718245010962 \t|  theta: tensor([[0.1171, 2.2066]], requires_grad=True)  |  Time needed: 0:00:00.097711  \n",
      "Run: 288\t| Iteration: 100 \t| Log-Likelihood:-3.227562267788779 \t|  theta: tensor([[0.0503, 2.7467]], requires_grad=True)  |  Time needed: 0:00:09.274013  \n",
      "Run: 288\t| Iteration: 200 \t| Log-Likelihood:-3.190588312651986 \t|  theta: tensor([[0.0501, 2.9264]], requires_grad=True)  |  Time needed: 0:00:09.085895  \n",
      "Run: 288\t| Iteration: 300 \t| Log-Likelihood:-3.1875110284915102 \t|  theta: tensor([[0.0501, 2.9782]], requires_grad=True)  |  Time needed: 0:00:09.144212  \n",
      "Run: 288\t| Iteration: 400 \t| Log-Likelihood:-3.187259976992537 \t|  theta: tensor([[0.0501, 2.9930]], requires_grad=True)  |  Time needed: 0:00:09.089337  \n",
      "Run: 288\t| Iteration: 500 \t| Log-Likelihood:-3.1872395400789166 \t|  theta: tensor([[0.0501, 2.9972]], requires_grad=True)  |  Time needed: 0:00:09.105195  \n",
      "Run: 288\t| Iteration: 600 \t| Log-Likelihood:-3.1872378624052535 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.079257  \n",
      "Run: 288\t| Iteration: 700 \t| Log-Likelihood:-3.187237727115985 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.136724  \n",
      "Run: 288\t| Iteration: 800 \t| Log-Likelihood:-3.187237731084195 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.413544  \n",
      "Run: 288\t| Iteration: 900 \t| Log-Likelihood:-3.187237737596006 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.121439  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 289\t| Iteration: 0 \t| Log-Likelihood:-3.898722179049487 \t|  theta: tensor([[0.3638, 1.9001]], requires_grad=True)  |  Time needed: 0:00:00.091601  \n",
      "Run: 289\t| Iteration: 100 \t| Log-Likelihood:-3.429021335180359 \t|  theta: tensor([[0.0554, 2.3642]], requires_grad=True)  |  Time needed: 0:00:09.103140  \n",
      "Run: 289\t| Iteration: 200 \t| Log-Likelihood:-3.210401013722554 \t|  theta: tensor([[0.0502, 2.8081]], requires_grad=True)  |  Time needed: 0:00:09.088393  \n",
      "Run: 289\t| Iteration: 300 \t| Log-Likelihood:-3.189146417394299 \t|  theta: tensor([[0.0501, 2.9442]], requires_grad=True)  |  Time needed: 0:00:09.201608  \n",
      "Run: 289\t| Iteration: 400 \t| Log-Likelihood:-3.1873933050746874 \t|  theta: tensor([[0.0501, 2.9833]], requires_grad=True)  |  Time needed: 0:00:09.229171  \n",
      "Run: 289\t| Iteration: 500 \t| Log-Likelihood:-3.187250421347928 \t|  theta: tensor([[0.0501, 2.9944]], requires_grad=True)  |  Time needed: 0:00:09.112645  \n",
      "Run: 289\t| Iteration: 600 \t| Log-Likelihood:-3.1872387864258087 \t|  theta: tensor([[0.0501, 2.9976]], requires_grad=True)  |  Time needed: 0:00:09.176827  \n",
      "Run: 289\t| Iteration: 700 \t| Log-Likelihood:-3.187237817665119 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.536609  \n",
      "Run: 289\t| Iteration: 800 \t| Log-Likelihood:-3.187237725714721 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.102221  \n",
      "Run: 289\t| Iteration: 900 \t| Log-Likelihood:-3.1872377343527636 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.087898  \n",
      "Run: 290\t| Iteration: 0 \t| Log-Likelihood:-4.522163221632482 \t|  theta: tensor([[0.5430, 0.5713]], requires_grad=True)  |  Time needed: 0:00:00.092538  \n",
      "Run: 290\t| Iteration: 100 \t| Log-Likelihood:-3.1905244451110564 \t|  theta: tensor([[0.4385, 1.0555]], requires_grad=True)  |  Time needed: 0:00:09.095972  \n",
      "Run: 290\t| Iteration: 200 \t| Log-Likelihood:-3.1904627886194383 \t|  theta: tensor([[0.4331, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.099704  \n",
      "Run: 290\t| Iteration: 300 \t| Log-Likelihood:-3.190462702976955 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.138882  \n",
      "Run: 290\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.092305  \n",
      "Run: 290\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.224610  \n",
      "Run: 290\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.196564  \n",
      "Run: 290\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.351771  \n",
      "Run: 290\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.802029  \n",
      "Run: 290\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.151209  \n",
      "Run: 291\t| Iteration: 0 \t| Log-Likelihood:-5.539338383884266 \t|  theta: tensor([[0.1023, 4.9056]], requires_grad=True)  |  Time needed: 0:00:00.094991  \n",
      "Run: 291\t| Iteration: 100 \t| Log-Likelihood:-3.375131957313957 \t|  theta: tensor([[0.0501, 3.5403]], requires_grad=True)  |  Time needed: 0:00:09.257967  \n",
      "Run: 291\t| Iteration: 200 \t| Log-Likelihood:-3.202399499444196 \t|  theta: tensor([[0.0501, 3.1528]], requires_grad=True)  |  Time needed: 0:00:09.266475  \n",
      "Run: 291\t| Iteration: 300 \t| Log-Likelihood:-3.188467826636155 \t|  theta: tensor([[0.0501, 3.0427]], requires_grad=True)  |  Time needed: 0:00:09.343195  \n",
      "Run: 291\t| Iteration: 400 \t| Log-Likelihood:-3.1873377522662696 \t|  theta: tensor([[0.0501, 3.0114]], requires_grad=True)  |  Time needed: 0:00:09.325880  \n",
      "Run: 291\t| Iteration: 500 \t| Log-Likelihood:-3.187245872497661 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.264700  \n",
      "Run: 291\t| Iteration: 600 \t| Log-Likelihood:-3.1872384097783626 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.312511  \n",
      "Run: 291\t| Iteration: 700 \t| Log-Likelihood:-3.187237798714624 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.243529  \n",
      "Run: 291\t| Iteration: 800 \t| Log-Likelihood:-3.1872377717092384 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.259855  \n",
      "Run: 291\t| Iteration: 900 \t| Log-Likelihood:-3.1872377565351164 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.292242  \n",
      "Run: 292\t| Iteration: 0 \t| Log-Likelihood:-4.663453879831815 \t|  theta: tensor([[0.0754, 4.5123]], requires_grad=True)  |  Time needed: 0:00:00.086542  \n",
      "Run: 292\t| Iteration: 100 \t| Log-Likelihood:-3.305520722146884 \t|  theta: tensor([[0.0501, 3.4285]], requires_grad=True)  |  Time needed: 0:00:09.123569  \n",
      "Run: 292\t| Iteration: 200 \t| Log-Likelihood:-3.1967913425988534 \t|  theta: tensor([[0.0501, 3.1211]], requires_grad=True)  |  Time needed: 0:00:09.141103  \n",
      "Run: 292\t| Iteration: 300 \t| Log-Likelihood:-3.1880132935025607 \t|  theta: tensor([[0.0501, 3.0337]], requires_grad=True)  |  Time needed: 0:00:09.142143  \n",
      "Run: 292\t| Iteration: 400 \t| Log-Likelihood:-3.1873007850177633 \t|  theta: tensor([[0.0501, 3.0088]], requires_grad=True)  |  Time needed: 0:00:09.094279  \n",
      "Run: 292\t| Iteration: 500 \t| Log-Likelihood:-3.1872428452560007 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.080962  \n",
      "Run: 292\t| Iteration: 600 \t| Log-Likelihood:-3.1872381323837393 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.165843  \n",
      "Run: 292\t| Iteration: 700 \t| Log-Likelihood:-3.1872377677975603 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.082193  \n",
      "Run: 292\t| Iteration: 800 \t| Log-Likelihood:-3.1872377663544182 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.119803  \n",
      "Run: 292\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564145626 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.100487  \n",
      "Run: 293\t| Iteration: 0 \t| Log-Likelihood:-5.06907838879424 \t|  theta: tensor([[0.5069, 4.4437]], requires_grad=True)  |  Time needed: 0:00:00.091386  \n",
      "Run: 293\t| Iteration: 100 \t| Log-Likelihood:-3.295036473681215 \t|  theta: tensor([[0.0501, 3.4091]], requires_grad=True)  |  Time needed: 0:00:09.082410  \n",
      "Run: 293\t| Iteration: 200 \t| Log-Likelihood:-3.195946400052924 \t|  theta: tensor([[0.0501, 3.1156]], requires_grad=True)  |  Time needed: 0:00:09.175437  \n",
      "Run: 293\t| Iteration: 300 \t| Log-Likelihood:-3.187944824660956 \t|  theta: tensor([[0.0501, 3.0321]], requires_grad=True)  |  Time needed: 0:00:09.520507  \n",
      "Run: 293\t| Iteration: 400 \t| Log-Likelihood:-3.187295261186972 \t|  theta: tensor([[0.0501, 3.0084]], requires_grad=True)  |  Time needed: 0:00:09.100152  \n",
      "Run: 293\t| Iteration: 500 \t| Log-Likelihood:-3.187242432558948 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.133887  \n",
      "Run: 293\t| Iteration: 600 \t| Log-Likelihood:-3.187238147931098 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.143556  \n",
      "Run: 293\t| Iteration: 700 \t| Log-Likelihood:-3.1872377647458787 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.211811  \n",
      "Run: 293\t| Iteration: 800 \t| Log-Likelihood:-3.187237766141611 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.079618  \n",
      "Run: 293\t| Iteration: 900 \t| Log-Likelihood:-3.18723775639089 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.154526  \n",
      "Run: 294\t| Iteration: 0 \t| Log-Likelihood:-4.056635036507706 \t|  theta: tensor([[0.4840, 3.7599]], requires_grad=True)  |  Time needed: 0:00:00.091725  \n",
      "Run: 294\t| Iteration: 100 \t| Log-Likelihood:-3.217169240365016 \t|  theta: tensor([[0.0501, 3.2151]], requires_grad=True)  |  Time needed: 0:00:09.119943  \n",
      "Run: 294\t| Iteration: 200 \t| Log-Likelihood:-3.1896627783305687 \t|  theta: tensor([[0.0501, 3.0605]], requires_grad=True)  |  Time needed: 0:00:09.202307  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 294\t| Iteration: 300 \t| Log-Likelihood:-3.187434856793311 \t|  theta: tensor([[0.0501, 3.0164]], requires_grad=True)  |  Time needed: 0:00:09.123850  \n",
      "Run: 294\t| Iteration: 400 \t| Log-Likelihood:-3.187253785911913 \t|  theta: tensor([[0.0501, 3.0039]], requires_grad=True)  |  Time needed: 0:00:09.115934  \n",
      "Run: 294\t| Iteration: 500 \t| Log-Likelihood:-3.1872390737126217 \t|  theta: tensor([[0.0501, 3.0003]], requires_grad=True)  |  Time needed: 0:00:09.123880  \n",
      "Run: 294\t| Iteration: 600 \t| Log-Likelihood:-3.1872378695867862 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.125965  \n",
      "Run: 294\t| Iteration: 700 \t| Log-Likelihood:-3.1872377238066374 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.246039  \n",
      "Run: 294\t| Iteration: 800 \t| Log-Likelihood:-3.1872377606003703 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.153789  \n",
      "Run: 294\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.137126  \n",
      "Run: 295\t| Iteration: 0 \t| Log-Likelihood:-3.9878612265201814 \t|  theta: tensor([[0.4626, 1.7913]], requires_grad=True)  |  Time needed: 0:00:00.091487  \n",
      "Run: 295\t| Iteration: 100 \t| Log-Likelihood:-3.197268985261499 \t|  theta: tensor([[0.3826, 1.0861]], requires_grad=True)  |  Time needed: 0:00:09.052362  \n",
      "Run: 295\t| Iteration: 200 \t| Log-Likelihood:-3.1904677896667044 \t|  theta: tensor([[0.4313, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.085927  \n",
      "Run: 295\t| Iteration: 300 \t| Log-Likelihood:-3.1904627075372836 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.074462  \n",
      "Run: 295\t| Iteration: 400 \t| Log-Likelihood:-3.1904627029315495 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.059789  \n",
      "Run: 295\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150414  \n",
      "Run: 295\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.056991  \n",
      "Run: 295\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.066920  \n",
      "Run: 295\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.077719  \n",
      "Run: 295\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.103088  \n",
      "Run: 296\t| Iteration: 0 \t| Log-Likelihood:-7.28540672676867 \t|  theta: tensor([[0.1943, 0.2786]], requires_grad=True)  |  Time needed: 0:00:00.088960  \n",
      "Run: 296\t| Iteration: 100 \t| Log-Likelihood:-3.1904685780389506 \t|  theta: tensor([[0.4312, 1.0573]], requires_grad=True)  |  Time needed: 0:00:09.292257  \n",
      "Run: 296\t| Iteration: 200 \t| Log-Likelihood:-3.1904626783050998 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.324884  \n",
      "Run: 296\t| Iteration: 300 \t| Log-Likelihood:-3.190462732734262 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.272646  \n",
      "Run: 296\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.255930  \n",
      "Run: 296\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.294192  \n",
      "Run: 296\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.344251  \n",
      "Run: 296\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.282590  \n",
      "Run: 296\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.415209  \n",
      "Run: 296\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.581715  \n",
      "Run: 297\t| Iteration: 0 \t| Log-Likelihood:-3.719888698757557 \t|  theta: tensor([[0.4252, 3.4628]], requires_grad=True)  |  Time needed: 0:00:00.087016  \n",
      "Run: 297\t| Iteration: 100 \t| Log-Likelihood:-3.1983748325585935 \t|  theta: tensor([[0.0501, 3.1308]], requires_grad=True)  |  Time needed: 0:00:09.114695  \n",
      "Run: 297\t| Iteration: 200 \t| Log-Likelihood:-3.1881417051019194 \t|  theta: tensor([[0.0501, 3.0365]], requires_grad=True)  |  Time needed: 0:00:09.148869  \n",
      "Run: 297\t| Iteration: 300 \t| Log-Likelihood:-3.1873112389458016 \t|  theta: tensor([[0.0501, 3.0096]], requires_grad=True)  |  Time needed: 0:00:09.219080  \n",
      "Run: 297\t| Iteration: 400 \t| Log-Likelihood:-3.187243744575234 \t|  theta: tensor([[0.0501, 3.0019]], requires_grad=True)  |  Time needed: 0:00:09.165128  \n",
      "Run: 297\t| Iteration: 500 \t| Log-Likelihood:-3.1872382136341373 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.227506  \n",
      "Run: 297\t| Iteration: 600 \t| Log-Likelihood:-3.187237777077454 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.121926  \n",
      "Run: 297\t| Iteration: 700 \t| Log-Likelihood:-3.1872377705737787 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.114374  \n",
      "Run: 297\t| Iteration: 800 \t| Log-Likelihood:-3.187237756452196 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.238813  \n",
      "Run: 297\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.228037  \n",
      "Run: 298\t| Iteration: 0 \t| Log-Likelihood:-3.5738848665299146 \t|  theta: tensor([[0.2609, 2.3842]], requires_grad=True)  |  Time needed: 0:00:00.091664  \n",
      "Run: 298\t| Iteration: 100 \t| Log-Likelihood:-3.2092805100750605 \t|  theta: tensor([[0.0502, 2.8127]], requires_grad=True)  |  Time needed: 0:00:09.137942  \n",
      "Run: 298\t| Iteration: 200 \t| Log-Likelihood:-3.1890530570303546 \t|  theta: tensor([[0.0501, 2.9456]], requires_grad=True)  |  Time needed: 0:00:09.095848  \n",
      "Run: 298\t| Iteration: 300 \t| Log-Likelihood:-3.187385643072366 \t|  theta: tensor([[0.0501, 2.9837]], requires_grad=True)  |  Time needed: 0:00:09.101791  \n",
      "Run: 298\t| Iteration: 400 \t| Log-Likelihood:-3.1872497637472508 \t|  theta: tensor([[0.0501, 2.9945]], requires_grad=True)  |  Time needed: 0:00:09.093011  \n",
      "Run: 298\t| Iteration: 500 \t| Log-Likelihood:-3.187238743682223 \t|  theta: tensor([[0.0501, 2.9976]], requires_grad=True)  |  Time needed: 0:00:09.130784  \n",
      "Run: 298\t| Iteration: 600 \t| Log-Likelihood:-3.187237817298884 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.177311  \n",
      "Run: 298\t| Iteration: 700 \t| Log-Likelihood:-3.18723772540755 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.125930  \n",
      "Run: 298\t| Iteration: 800 \t| Log-Likelihood:-3.187237734318047 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.101296  \n",
      "Run: 298\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.097246  \n",
      "Run: 299\t| Iteration: 0 \t| Log-Likelihood:-4.852735819374455 \t|  theta: tensor([[0.5720, 4.2352]], requires_grad=True)  |  Time needed: 0:00:00.091400  \n",
      "Run: 299\t| Iteration: 100 \t| Log-Likelihood:-3.2661775740394536 \t|  theta: tensor([[0.0501, 3.3499]], requires_grad=True)  |  Time needed: 0:00:09.119171  \n",
      "Run: 299\t| Iteration: 200 \t| Log-Likelihood:-3.193619383682508 \t|  theta: tensor([[0.0501, 3.0988]], requires_grad=True)  |  Time needed: 0:00:09.104362  \n",
      "Run: 299\t| Iteration: 300 \t| Log-Likelihood:-3.1877560896301222 \t|  theta: tensor([[0.0501, 3.0274]], requires_grad=True)  |  Time needed: 0:00:09.103264  \n",
      "Run: 299\t| Iteration: 400 \t| Log-Likelihood:-3.187279920921858 \t|  theta: tensor([[0.0501, 3.0070]], requires_grad=True)  |  Time needed: 0:00:09.095836  \n",
      "Run: 299\t| Iteration: 500 \t| Log-Likelihood:-3.18724117620417 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.093467  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 299\t| Iteration: 600 \t| Log-Likelihood:-3.187238027576333 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.099142  \n",
      "Run: 299\t| Iteration: 700 \t| Log-Likelihood:-3.187237749114665 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.100278  \n",
      "Run: 299\t| Iteration: 800 \t| Log-Likelihood:-3.187237765488728 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.153546  \n",
      "Run: 299\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563266774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.135252  \n",
      "Run: 300\t| Iteration: 0 \t| Log-Likelihood:-5.4892633325066695 \t|  theta: tensor([[0.2380, 0.4724]], requires_grad=True)  |  Time needed: 0:00:00.090665  \n",
      "Run: 300\t| Iteration: 100 \t| Log-Likelihood:-3.1904682300884666 \t|  theta: tensor([[0.4312, 1.0573]], requires_grad=True)  |  Time needed: 0:00:09.182868  \n",
      "Run: 300\t| Iteration: 200 \t| Log-Likelihood:-3.190462707824982 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.111979  \n",
      "Run: 300\t| Iteration: 300 \t| Log-Likelihood:-3.190462673129442 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.210408  \n",
      "Run: 300\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.284712  \n",
      "Run: 300\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.534651  \n",
      "Run: 300\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119054  \n",
      "Run: 300\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.107752  \n",
      "Run: 300\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116126  \n",
      "Run: 300\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.115985  \n",
      "Run: 301\t| Iteration: 0 \t| Log-Likelihood:-4.0843994266327845 \t|  theta: tensor([[0.3883, 3.9337]], requires_grad=True)  |  Time needed: 0:00:00.096852  \n",
      "Run: 301\t| Iteration: 100 \t| Log-Likelihood:-3.2323883714942157 \t|  theta: tensor([[0.0501, 3.2644]], requires_grad=True)  |  Time needed: 0:00:09.333126  \n",
      "Run: 301\t| Iteration: 200 \t| Log-Likelihood:-3.19089246340071 \t|  theta: tensor([[0.0501, 3.0745]], requires_grad=True)  |  Time needed: 0:00:09.320524  \n",
      "Run: 301\t| Iteration: 300 \t| Log-Likelihood:-3.1875347419182796 \t|  theta: tensor([[0.0501, 3.0204]], requires_grad=True)  |  Time needed: 0:00:09.343944  \n",
      "Run: 301\t| Iteration: 400 \t| Log-Likelihood:-3.1872619269970657 \t|  theta: tensor([[0.0501, 3.0050]], requires_grad=True)  |  Time needed: 0:00:09.394503  \n",
      "Run: 301\t| Iteration: 500 \t| Log-Likelihood:-3.1872396776972245 \t|  theta: tensor([[0.0501, 3.0006]], requires_grad=True)  |  Time needed: 0:00:09.307888  \n",
      "Run: 301\t| Iteration: 600 \t| Log-Likelihood:-3.1872378786703237 \t|  theta: tensor([[0.0501, 2.9994]], requires_grad=True)  |  Time needed: 0:00:09.253178  \n",
      "Run: 301\t| Iteration: 700 \t| Log-Likelihood:-3.1872377319360647 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.297855  \n",
      "Run: 301\t| Iteration: 800 \t| Log-Likelihood:-3.187237760972214 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.344721  \n",
      "Run: 301\t| Iteration: 900 \t| Log-Likelihood:-3.187237756235455 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.268630  \n",
      "Run: 302\t| Iteration: 0 \t| Log-Likelihood:-5.98306781063316 \t|  theta: tensor([[0.3511, 0.3923]], requires_grad=True)  |  Time needed: 0:00:00.086545  \n",
      "Run: 302\t| Iteration: 100 \t| Log-Likelihood:-3.1904651416666248 \t|  theta: tensor([[0.4340, 1.0566]], requires_grad=True)  |  Time needed: 0:00:09.161835  \n",
      "Run: 302\t| Iteration: 200 \t| Log-Likelihood:-3.190462675284071 \t|  theta: tensor([[0.4330, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.110814  \n",
      "Run: 302\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029300565 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.124400  \n",
      "Run: 302\t| Iteration: 400 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.127707  \n",
      "Run: 302\t| Iteration: 500 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.165025  \n",
      "Run: 302\t| Iteration: 600 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.116168  \n",
      "Run: 302\t| Iteration: 700 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.175979  \n",
      "Run: 302\t| Iteration: 800 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.114161  \n",
      "Run: 302\t| Iteration: 900 \t| Log-Likelihood:-3.1904626731256314 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.118337  \n",
      "Run: 303\t| Iteration: 0 \t| Log-Likelihood:-3.297481296857011 \t|  theta: tensor([[0.0506, 3.4137]], requires_grad=True)  |  Time needed: 0:00:00.096080  \n",
      "Run: 303\t| Iteration: 100 \t| Log-Likelihood:-3.1961430765933003 \t|  theta: tensor([[0.0501, 3.1169]], requires_grad=True)  |  Time needed: 0:00:09.216361  \n",
      "Run: 303\t| Iteration: 200 \t| Log-Likelihood:-3.1879608191000828 \t|  theta: tensor([[0.0501, 3.0325]], requires_grad=True)  |  Time needed: 0:00:09.154556  \n",
      "Run: 303\t| Iteration: 300 \t| Log-Likelihood:-3.187296511222624 \t|  theta: tensor([[0.0501, 3.0085]], requires_grad=True)  |  Time needed: 0:00:09.150888  \n",
      "Run: 303\t| Iteration: 400 \t| Log-Likelihood:-3.187242544363765 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:09.192601  \n",
      "Run: 303\t| Iteration: 500 \t| Log-Likelihood:-3.1872381565728345 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.236627  \n",
      "Run: 303\t| Iteration: 600 \t| Log-Likelihood:-3.1872377654116293 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.147375  \n",
      "Run: 303\t| Iteration: 700 \t| Log-Likelihood:-3.1872377661796656 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.150621  \n",
      "Run: 303\t| Iteration: 800 \t| Log-Likelihood:-3.187237756396702 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.188909  \n",
      "Run: 303\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.129121  \n",
      "Run: 304\t| Iteration: 0 \t| Log-Likelihood:-3.2494780924952655 \t|  theta: tensor([[0.0574, 3.1493]], requires_grad=True)  |  Time needed: 0:00:00.099080  \n",
      "Run: 304\t| Iteration: 100 \t| Log-Likelihood:-3.188412071474744 \t|  theta: tensor([[0.0501, 3.0417]], requires_grad=True)  |  Time needed: 0:00:09.323508  \n",
      "Run: 304\t| Iteration: 200 \t| Log-Likelihood:-3.1873332264771035 \t|  theta: tensor([[0.0501, 3.0111]], requires_grad=True)  |  Time needed: 0:00:09.148118  \n",
      "Run: 304\t| Iteration: 300 \t| Log-Likelihood:-3.18724548717123 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.186113  \n",
      "Run: 304\t| Iteration: 400 \t| Log-Likelihood:-3.1872383757986014 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.158133  \n",
      "Run: 304\t| Iteration: 500 \t| Log-Likelihood:-3.187237792658964 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.159507  \n",
      "Run: 304\t| Iteration: 600 \t| Log-Likelihood:-3.187237771536613 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.169101  \n",
      "Run: 304\t| Iteration: 700 \t| Log-Likelihood:-3.187237756527817 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.347935  \n",
      "Run: 304\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.167191  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 304\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.158066  \n",
      "Run: 305\t| Iteration: 0 \t| Log-Likelihood:-3.7537574157199014 \t|  theta: tensor([[0.3923, 1.5973]], requires_grad=True)  |  Time needed: 0:00:00.090772  \n",
      "Run: 305\t| Iteration: 100 \t| Log-Likelihood:-3.1908338018390263 \t|  theta: tensor([[0.4196, 1.0617]], requires_grad=True)  |  Time needed: 0:00:09.189151  \n",
      "Run: 305\t| Iteration: 200 \t| Log-Likelihood:-3.1904630591842253 \t|  theta: tensor([[0.4325, 1.0571]], requires_grad=True)  |  Time needed: 0:00:09.118824  \n",
      "Run: 305\t| Iteration: 300 \t| Log-Likelihood:-3.190462703225804 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.256390  \n",
      "Run: 305\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.082781  \n",
      "Run: 305\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.088918  \n",
      "Run: 305\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.092276  \n",
      "Run: 305\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.195263  \n",
      "Run: 305\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.143444  \n",
      "Run: 305\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104560  \n",
      "Run: 306\t| Iteration: 0 \t| Log-Likelihood:-3.224441204845431 \t|  theta: tensor([[0.0420, 2.9036]], requires_grad=True)  |  Time needed: 0:00:00.088803  \n",
      "Run: 306\t| Iteration: 100 \t| Log-Likelihood:-3.187711063092594 \t|  theta: tensor([[0.0501, 2.9717]], requires_grad=True)  |  Time needed: 0:00:09.297365  \n",
      "Run: 306\t| Iteration: 200 \t| Log-Likelihood:-3.187276265309722 \t|  theta: tensor([[0.0501, 2.9911]], requires_grad=True)  |  Time needed: 0:00:09.299374  \n",
      "Run: 306\t| Iteration: 300 \t| Log-Likelihood:-3.187240889735236 \t|  theta: tensor([[0.0501, 2.9967]], requires_grad=True)  |  Time needed: 0:00:09.339955  \n",
      "Run: 306\t| Iteration: 400 \t| Log-Likelihood:-3.187238003651688 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.355532  \n",
      "Run: 306\t| Iteration: 500 \t| Log-Likelihood:-3.1872377880381664 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.318785  \n",
      "Run: 306\t| Iteration: 600 \t| Log-Likelihood:-3.187237731785236 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.376665  \n",
      "Run: 306\t| Iteration: 700 \t| Log-Likelihood:-3.1872377339556537 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.315528  \n",
      "Run: 306\t| Iteration: 800 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.403740  \n",
      "Run: 306\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.364862  \n",
      "Run: 307\t| Iteration: 0 \t| Log-Likelihood:-5.163166498999076 \t|  theta: tensor([[0.1808, 4.7159]], requires_grad=True)  |  Time needed: 0:00:00.091010  \n",
      "Run: 307\t| Iteration: 100 \t| Log-Likelihood:-3.339507199195687 \t|  theta: tensor([[0.0501, 3.4863]], requires_grad=True)  |  Time needed: 0:00:09.178086  \n",
      "Run: 307\t| Iteration: 200 \t| Log-Likelihood:-3.1995298553048954 \t|  theta: tensor([[0.0501, 3.1375]], requires_grad=True)  |  Time needed: 0:00:09.164487  \n",
      "Run: 307\t| Iteration: 300 \t| Log-Likelihood:-3.188235328642481 \t|  theta: tensor([[0.0501, 3.0384]], requires_grad=True)  |  Time needed: 0:00:09.208424  \n",
      "Run: 307\t| Iteration: 400 \t| Log-Likelihood:-3.1873188900931413 \t|  theta: tensor([[0.0501, 3.0101]], requires_grad=True)  |  Time needed: 0:00:09.168738  \n",
      "Run: 307\t| Iteration: 500 \t| Log-Likelihood:-3.187244333024761 \t|  theta: tensor([[0.0501, 3.0021]], requires_grad=True)  |  Time needed: 0:00:09.183063  \n",
      "Run: 307\t| Iteration: 600 \t| Log-Likelihood:-3.1872382711896226 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:09.616382  \n",
      "Run: 307\t| Iteration: 700 \t| Log-Likelihood:-3.187237781223526 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.269714  \n",
      "Run: 307\t| Iteration: 800 \t| Log-Likelihood:-3.187237770925834 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.146550  \n",
      "Run: 307\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564787024 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.238968  \n",
      "Run: 308\t| Iteration: 0 \t| Log-Likelihood:-3.7850021893359886 \t|  theta: tensor([[0.4370, 3.5337]], requires_grad=True)  |  Time needed: 0:00:00.093105  \n",
      "Run: 308\t| Iteration: 100 \t| Log-Likelihood:-3.2020299937560446 \t|  theta: tensor([[0.0501, 3.1509]], requires_grad=True)  |  Time needed: 0:00:09.160267  \n",
      "Run: 308\t| Iteration: 200 \t| Log-Likelihood:-3.188437819776047 \t|  theta: tensor([[0.0501, 3.0422]], requires_grad=True)  |  Time needed: 0:00:09.191514  \n",
      "Run: 308\t| Iteration: 300 \t| Log-Likelihood:-3.187335290151558 \t|  theta: tensor([[0.0501, 3.0112]], requires_grad=True)  |  Time needed: 0:00:09.146937  \n",
      "Run: 308\t| Iteration: 400 \t| Log-Likelihood:-3.1872456697362512 \t|  theta: tensor([[0.0501, 3.0024]], requires_grad=True)  |  Time needed: 0:00:09.126555  \n",
      "Run: 308\t| Iteration: 500 \t| Log-Likelihood:-3.187238393352937 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.115401  \n",
      "Run: 308\t| Iteration: 600 \t| Log-Likelihood:-3.187237797413597 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.209676  \n",
      "Run: 308\t| Iteration: 700 \t| Log-Likelihood:-3.18723777161017 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.118363  \n",
      "Run: 308\t| Iteration: 800 \t| Log-Likelihood:-3.187237756527817 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.140907  \n",
      "Run: 308\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.176860  \n",
      "Run: 309\t| Iteration: 0 \t| Log-Likelihood:-5.286658243378055 \t|  theta: tensor([[0.5488, 4.5117]], requires_grad=True)  |  Time needed: 0:00:00.093208  \n",
      "Run: 309\t| Iteration: 100 \t| Log-Likelihood:-3.3054249765983896 \t|  theta: tensor([[0.0501, 3.4284]], requires_grad=True)  |  Time needed: 0:00:09.120199  \n",
      "Run: 309\t| Iteration: 200 \t| Log-Likelihood:-3.1967836067602335 \t|  theta: tensor([[0.0501, 3.1210]], requires_grad=True)  |  Time needed: 0:00:09.159731  \n",
      "Run: 309\t| Iteration: 300 \t| Log-Likelihood:-3.1880127131501594 \t|  theta: tensor([[0.0501, 3.0337]], requires_grad=True)  |  Time needed: 0:00:09.154143  \n",
      "Run: 309\t| Iteration: 400 \t| Log-Likelihood:-3.1873007237639155 \t|  theta: tensor([[0.0501, 3.0088]], requires_grad=True)  |  Time needed: 0:00:09.125906  \n",
      "Run: 309\t| Iteration: 500 \t| Log-Likelihood:-3.1872428409950166 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.132300  \n",
      "Run: 309\t| Iteration: 600 \t| Log-Likelihood:-3.1872381318975567 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.123307  \n",
      "Run: 309\t| Iteration: 700 \t| Log-Likelihood:-3.187237767728186 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.117964  \n",
      "Run: 309\t| Iteration: 800 \t| Log-Likelihood:-3.1872377663544182 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.112612  \n",
      "Run: 309\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564145626 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.130220  \n",
      "Run: 310\t| Iteration: 0 \t| Log-Likelihood:-5.447131744994333 \t|  theta: tensor([[0.1771, 4.8421]], requires_grad=True)  |  Time needed: 0:00:00.101563  \n",
      "Run: 310\t| Iteration: 100 \t| Log-Likelihood:-3.3627590667170315 \t|  theta: tensor([[0.0501, 3.5222]], requires_grad=True)  |  Time needed: 0:00:09.193668  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 310\t| Iteration: 200 \t| Log-Likelihood:-3.201402974902143 \t|  theta: tensor([[0.0501, 3.1477]], requires_grad=True)  |  Time needed: 0:00:09.245606  \n",
      "Run: 310\t| Iteration: 300 \t| Log-Likelihood:-3.188387036293282 \t|  theta: tensor([[0.0501, 3.0413]], requires_grad=True)  |  Time needed: 0:00:09.198406  \n",
      "Run: 310\t| Iteration: 400 \t| Log-Likelihood:-3.1873311770153556 \t|  theta: tensor([[0.0501, 3.0110]], requires_grad=True)  |  Time needed: 0:00:09.087790  \n",
      "Run: 310\t| Iteration: 500 \t| Log-Likelihood:-3.1872453169351256 \t|  theta: tensor([[0.0501, 3.0023]], requires_grad=True)  |  Time needed: 0:00:09.189892  \n",
      "Run: 310\t| Iteration: 600 \t| Log-Likelihood:-3.187238363303035 \t|  theta: tensor([[0.0501, 2.9999]], requires_grad=True)  |  Time needed: 0:00:09.112867  \n",
      "Run: 310\t| Iteration: 700 \t| Log-Likelihood:-3.1872377915553582 \t|  theta: tensor([[0.0501, 2.9992]], requires_grad=True)  |  Time needed: 0:00:09.109608  \n",
      "Run: 310\t| Iteration: 800 \t| Log-Likelihood:-3.1872377714395292 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.114252  \n",
      "Run: 310\t| Iteration: 900 \t| Log-Likelihood:-3.187237756520588 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.187610  \n",
      "Run: 311\t| Iteration: 0 \t| Log-Likelihood:-4.004114085531906 \t|  theta: tensor([[0.2602, 0.7099]], requires_grad=True)  |  Time needed: 0:00:00.093734  \n",
      "Run: 311\t| Iteration: 100 \t| Log-Likelihood:-3.1904724153823234 \t|  theta: tensor([[0.4307, 1.0575]], requires_grad=True)  |  Time needed: 0:00:09.247616  \n",
      "Run: 311\t| Iteration: 200 \t| Log-Likelihood:-3.190462741450428 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.682433  \n",
      "Run: 311\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029353634 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.274382  \n",
      "Run: 311\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.223956  \n",
      "Run: 311\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.271086  \n",
      "Run: 311\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.419653  \n",
      "Run: 311\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.269605  \n",
      "Run: 311\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.302417  \n",
      "Run: 311\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.278434  \n",
      "Run: 312\t| Iteration: 0 \t| Log-Likelihood:-3.654604076853736 \t|  theta: tensor([[0.2635, 2.2604]], requires_grad=True)  |  Time needed: 0:00:00.096729  \n",
      "Run: 312\t| Iteration: 100 \t| Log-Likelihood:-3.22179340239863 \t|  theta: tensor([[0.0503, 2.7656]], requires_grad=True)  |  Time needed: 0:00:09.111669  \n",
      "Run: 312\t| Iteration: 200 \t| Log-Likelihood:-3.190100956316142 \t|  theta: tensor([[0.0501, 2.9319]], requires_grad=True)  |  Time needed: 0:00:09.190936  \n",
      "Run: 312\t| Iteration: 300 \t| Log-Likelihood:-3.1874711620235883 \t|  theta: tensor([[0.0501, 2.9798]], requires_grad=True)  |  Time needed: 0:00:09.116393  \n",
      "Run: 312\t| Iteration: 400 \t| Log-Likelihood:-3.187256762310621 \t|  theta: tensor([[0.0501, 2.9934]], requires_grad=True)  |  Time needed: 0:00:09.138365  \n",
      "Run: 312\t| Iteration: 500 \t| Log-Likelihood:-3.1872393025255525 \t|  theta: tensor([[0.0501, 2.9973]], requires_grad=True)  |  Time needed: 0:00:09.155957  \n",
      "Run: 312\t| Iteration: 600 \t| Log-Likelihood:-3.1872378448593452 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.112837  \n",
      "Run: 312\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254127513 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.085514  \n",
      "Run: 312\t| Iteration: 800 \t| Log-Likelihood:-3.187237730946029 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.108161  \n",
      "Run: 312\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.290259  \n",
      "Run: 313\t| Iteration: 0 \t| Log-Likelihood:-3.9681560348561695 \t|  theta: tensor([[0.0351, 4.0935]], requires_grad=True)  |  Time needed: 0:00:00.092514  \n",
      "Run: 313\t| Iteration: 100 \t| Log-Likelihood:-3.2491365347514094 \t|  theta: tensor([[0.0501, 3.3098]], requires_grad=True)  |  Time needed: 0:00:09.156541  \n",
      "Run: 313\t| Iteration: 200 \t| Log-Likelihood:-3.192244576348552 \t|  theta: tensor([[0.0501, 3.0874]], requires_grad=True)  |  Time needed: 0:00:09.081914  \n",
      "Run: 313\t| Iteration: 300 \t| Log-Likelihood:-3.187644523461692 \t|  theta: tensor([[0.0501, 3.0241]], requires_grad=True)  |  Time needed: 0:00:09.216287  \n",
      "Run: 313\t| Iteration: 400 \t| Log-Likelihood:-3.1872708011813415 \t|  theta: tensor([[0.0501, 3.0061]], requires_grad=True)  |  Time needed: 0:00:09.084349  \n",
      "Run: 313\t| Iteration: 500 \t| Log-Likelihood:-3.1872404549461275 \t|  theta: tensor([[0.0501, 3.0009]], requires_grad=True)  |  Time needed: 0:00:09.109916  \n",
      "Run: 313\t| Iteration: 600 \t| Log-Likelihood:-3.1872379530388293 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.070726  \n",
      "Run: 313\t| Iteration: 700 \t| Log-Likelihood:-3.187237740413763 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.093462  \n",
      "Run: 313\t| Iteration: 800 \t| Log-Likelihood:-3.187237765044823 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.113720  \n",
      "Run: 313\t| Iteration: 900 \t| Log-Likelihood:-3.187237756280961 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.086752  \n",
      "Run: 314\t| Iteration: 0 \t| Log-Likelihood:-3.7377567627901622 \t|  theta: tensor([[0.2082, 3.8266]], requires_grad=True)  |  Time needed: 0:00:00.092525  \n",
      "Run: 314\t| Iteration: 100 \t| Log-Likelihood:-3.222640315673448 \t|  theta: tensor([[0.0501, 3.2340]], requires_grad=True)  |  Time needed: 0:00:09.162419  \n",
      "Run: 314\t| Iteration: 200 \t| Log-Likelihood:-3.190104926770664 \t|  theta: tensor([[0.0501, 3.0658]], requires_grad=True)  |  Time needed: 0:00:09.686238  \n",
      "Run: 314\t| Iteration: 300 \t| Log-Likelihood:-3.187470737061582 \t|  theta: tensor([[0.0501, 3.0180]], requires_grad=True)  |  Time needed: 0:00:09.148925  \n",
      "Run: 314\t| Iteration: 400 \t| Log-Likelihood:-3.1872567178861613 \t|  theta: tensor([[0.0501, 3.0043]], requires_grad=True)  |  Time needed: 0:00:09.170496  \n",
      "Run: 314\t| Iteration: 500 \t| Log-Likelihood:-3.18723927507322 \t|  theta: tensor([[0.0501, 3.0004]], requires_grad=True)  |  Time needed: 0:00:09.578388  \n",
      "Run: 314\t| Iteration: 600 \t| Log-Likelihood:-3.1872378368797607 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.877580  \n",
      "Run: 314\t| Iteration: 700 \t| Log-Likelihood:-3.1872377254139557 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.886527  \n",
      "Run: 314\t| Iteration: 800 \t| Log-Likelihood:-3.1872377607486975 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.962753  \n",
      "Run: 314\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.412994  \n",
      "Run: 315\t| Iteration: 0 \t| Log-Likelihood:-3.843848263383805 \t|  theta: tensor([[0.2944, 0.7380]], requires_grad=True)  |  Time needed: 0:00:00.089513  \n",
      "Run: 315\t| Iteration: 100 \t| Log-Likelihood:-3.190468038491883 \t|  theta: tensor([[0.4313, 1.0574]], requires_grad=True)  |  Time needed: 0:00:09.138138  \n",
      "Run: 315\t| Iteration: 200 \t| Log-Likelihood:-3.1904627375299146 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.084790  \n",
      "Run: 315\t| Iteration: 300 \t| Log-Likelihood:-3.190462673129442 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.068847  \n",
      "Run: 315\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.120440  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 315\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.141047  \n",
      "Run: 315\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.076517  \n",
      "Run: 315\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.219529  \n",
      "Run: 315\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.075453  \n",
      "Run: 315\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.064403  \n",
      "Run: 316\t| Iteration: 0 \t| Log-Likelihood:-4.058940481159972 \t|  theta: tensor([[0.2206, 4.0786]], requires_grad=True)  |  Time needed: 0:00:00.091095  \n",
      "Run: 316\t| Iteration: 100 \t| Log-Likelihood:-3.2474593348194802 \t|  theta: tensor([[0.0501, 3.3055]], requires_grad=True)  |  Time needed: 0:00:09.283908  \n",
      "Run: 316\t| Iteration: 200 \t| Log-Likelihood:-3.192109176669923 \t|  theta: tensor([[0.0501, 3.0862]], requires_grad=True)  |  Time needed: 0:00:09.267642  \n",
      "Run: 316\t| Iteration: 300 \t| Log-Likelihood:-3.1876334751883912 \t|  theta: tensor([[0.0501, 3.0238]], requires_grad=True)  |  Time needed: 0:00:09.271486  \n",
      "Run: 316\t| Iteration: 400 \t| Log-Likelihood:-3.187269953951011 \t|  theta: tensor([[0.0501, 3.0060]], requires_grad=True)  |  Time needed: 0:00:09.300747  \n",
      "Run: 316\t| Iteration: 500 \t| Log-Likelihood:-3.187240378837235 \t|  theta: tensor([[0.0501, 3.0009]], requires_grad=True)  |  Time needed: 0:00:09.260531  \n",
      "Run: 316\t| Iteration: 600 \t| Log-Likelihood:-3.1872379470866536 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.346119  \n",
      "Run: 316\t| Iteration: 700 \t| Log-Likelihood:-3.1872377399152447 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.294557  \n",
      "Run: 316\t| Iteration: 800 \t| Log-Likelihood:-3.1872377612770126 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.430361  \n",
      "Run: 316\t| Iteration: 900 \t| Log-Likelihood:-3.187237756276779 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.260500  \n",
      "Run: 317\t| Iteration: 0 \t| Log-Likelihood:-4.734265830143781 \t|  theta: tensor([[0.1549, 4.5206]], requires_grad=True)  |  Time needed: 0:00:00.094575  \n",
      "Run: 317\t| Iteration: 100 \t| Log-Likelihood:-3.306829070521793 \t|  theta: tensor([[0.0501, 3.4309]], requires_grad=True)  |  Time needed: 0:00:09.134525  \n",
      "Run: 317\t| Iteration: 200 \t| Log-Likelihood:-3.1968968991908766 \t|  theta: tensor([[0.0501, 3.1218]], requires_grad=True)  |  Time needed: 0:00:09.154616  \n",
      "Run: 317\t| Iteration: 300 \t| Log-Likelihood:-3.18802192463852 \t|  theta: tensor([[0.0501, 3.0339]], requires_grad=True)  |  Time needed: 0:00:09.161313  \n",
      "Run: 317\t| Iteration: 400 \t| Log-Likelihood:-3.187301497006576 \t|  theta: tensor([[0.0501, 3.0089]], requires_grad=True)  |  Time needed: 0:00:09.191166  \n",
      "Run: 317\t| Iteration: 500 \t| Log-Likelihood:-3.187242909678466 \t|  theta: tensor([[0.0501, 3.0017]], requires_grad=True)  |  Time needed: 0:00:09.151682  \n",
      "Run: 317\t| Iteration: 600 \t| Log-Likelihood:-3.1872381362834052 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.155181  \n",
      "Run: 317\t| Iteration: 700 \t| Log-Likelihood:-3.187237768006108 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.235219  \n",
      "Run: 317\t| Iteration: 800 \t| Log-Likelihood:-3.18723776637419 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.144918  \n",
      "Run: 317\t| Iteration: 900 \t| Log-Likelihood:-3.1872377564145626 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.161012  \n",
      "Run: 318\t| Iteration: 0 \t| Log-Likelihood:-5.713542446413815 \t|  theta: tensor([[0.2530, 0.4409]], requires_grad=True)  |  Time needed: 0:00:00.099134  \n",
      "Run: 318\t| Iteration: 100 \t| Log-Likelihood:-3.1904659529505977 \t|  theta: tensor([[0.4316, 1.0572]], requires_grad=True)  |  Time needed: 0:00:09.253329  \n",
      "Run: 318\t| Iteration: 200 \t| Log-Likelihood:-3.190462705778321 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.086444  \n",
      "Run: 318\t| Iteration: 300 \t| Log-Likelihood:-3.1904627029302373 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.256990  \n",
      "Run: 318\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.392994  \n",
      "Run: 318\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.091845  \n",
      "Run: 318\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.122836  \n",
      "Run: 318\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104175  \n",
      "Run: 318\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.090222  \n",
      "Run: 318\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.097647  \n",
      "Run: 319\t| Iteration: 0 \t| Log-Likelihood:-3.6288159651817744 \t|  theta: tensor([[0.4050, 2.6396]], requires_grad=True)  |  Time needed: 0:00:00.095886  \n",
      "Run: 319\t| Iteration: 100 \t| Log-Likelihood:-3.1942231126068656 \t|  theta: tensor([[0.0501, 2.8942]], requires_grad=True)  |  Time needed: 0:00:09.105858  \n",
      "Run: 319\t| Iteration: 200 \t| Log-Likelihood:-3.1878085744889644 \t|  theta: tensor([[0.0501, 2.9690]], requires_grad=True)  |  Time needed: 0:00:09.099074  \n",
      "Run: 319\t| Iteration: 300 \t| Log-Likelihood:-3.1872841869066106 \t|  theta: tensor([[0.0501, 2.9903]], requires_grad=True)  |  Time needed: 0:00:09.198013  \n",
      "Run: 319\t| Iteration: 400 \t| Log-Likelihood:-3.1872415028734573 \t|  theta: tensor([[0.0501, 2.9964]], requires_grad=True)  |  Time needed: 0:00:09.235006  \n",
      "Run: 319\t| Iteration: 500 \t| Log-Likelihood:-3.187238045335679 \t|  theta: tensor([[0.0501, 2.9982]], requires_grad=True)  |  Time needed: 0:00:09.130253  \n",
      "Run: 319\t| Iteration: 600 \t| Log-Likelihood:-3.18723778857507 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.115847  \n",
      "Run: 319\t| Iteration: 700 \t| Log-Likelihood:-3.187237728419258 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.127334  \n",
      "Run: 319\t| Iteration: 800 \t| Log-Likelihood:-3.1872377339950435 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.234773  \n",
      "Run: 319\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.106027  \n",
      "Run: 320\t| Iteration: 0 \t| Log-Likelihood:-4.352241263114114 \t|  theta: tensor([[0.1533, 4.3114]], requires_grad=True)  |  Time needed: 0:00:00.093241  \n",
      "Run: 320\t| Iteration: 100 \t| Log-Likelihood:-3.2762043148223907 \t|  theta: tensor([[0.0501, 3.3715]], requires_grad=True)  |  Time needed: 0:00:09.107237  \n",
      "Run: 320\t| Iteration: 200 \t| Log-Likelihood:-3.194428019424157 \t|  theta: tensor([[0.0501, 3.1049]], requires_grad=True)  |  Time needed: 0:00:09.110097  \n",
      "Run: 320\t| Iteration: 300 \t| Log-Likelihood:-3.187821646988838 \t|  theta: tensor([[0.0501, 3.0291]], requires_grad=True)  |  Time needed: 0:00:09.144434  \n",
      "Run: 320\t| Iteration: 400 \t| Log-Likelihood:-3.187285219576681 \t|  theta: tensor([[0.0501, 3.0075]], requires_grad=True)  |  Time needed: 0:00:09.106592  \n",
      "Run: 320\t| Iteration: 500 \t| Log-Likelihood:-3.187241575066183 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.091678  \n",
      "Run: 320\t| Iteration: 600 \t| Log-Likelihood:-3.1872380698473246 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.130273  \n",
      "Run: 320\t| Iteration: 700 \t| Log-Likelihood:-3.1872377556478075 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.322020  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 320\t| Iteration: 800 \t| Log-Likelihood:-3.1872377657243565 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.120125  \n",
      "Run: 320\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563521925 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.182979  \n",
      "Run: 321\t| Iteration: 0 \t| Log-Likelihood:-3.3373272789269093 \t|  theta: tensor([[0.2183, 3.2103]], requires_grad=True)  |  Time needed: 0:00:00.090272  \n",
      "Run: 321\t| Iteration: 100 \t| Log-Likelihood:-3.1895556880680527 \t|  theta: tensor([[0.0501, 3.0591]], requires_grad=True)  |  Time needed: 0:00:09.244596  \n",
      "Run: 321\t| Iteration: 200 \t| Log-Likelihood:-3.187426163960753 \t|  theta: tensor([[0.0501, 3.0160]], requires_grad=True)  |  Time needed: 0:00:09.275969  \n",
      "Run: 321\t| Iteration: 300 \t| Log-Likelihood:-3.1872530607111065 \t|  theta: tensor([[0.0501, 3.0038]], requires_grad=True)  |  Time needed: 0:00:09.292047  \n",
      "Run: 321\t| Iteration: 400 \t| Log-Likelihood:-3.187239010583035 \t|  theta: tensor([[0.0501, 3.0003]], requires_grad=True)  |  Time needed: 0:00:09.244887  \n",
      "Run: 321\t| Iteration: 500 \t| Log-Likelihood:-3.1872378651007356 \t|  theta: tensor([[0.0501, 2.9993]], requires_grad=True)  |  Time needed: 0:00:09.254404  \n",
      "Run: 321\t| Iteration: 600 \t| Log-Likelihood:-3.187237723494768 \t|  theta: tensor([[0.0501, 2.9990]], requires_grad=True)  |  Time needed: 0:00:09.276205  \n",
      "Run: 321\t| Iteration: 700 \t| Log-Likelihood:-3.187237760570393 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.260259  \n",
      "Run: 321\t| Iteration: 800 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.244717  \n",
      "Run: 321\t| Iteration: 900 \t| Log-Likelihood:-3.187237756210786 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.407599  \n",
      "Run: 322\t| Iteration: 0 \t| Log-Likelihood:-4.250425879434115 \t|  theta: tensor([[0.2334, 0.6667]], requires_grad=True)  |  Time needed: 0:00:00.093323  \n",
      "Run: 322\t| Iteration: 100 \t| Log-Likelihood:-3.1904752278056523 \t|  theta: tensor([[0.4304, 1.0576]], requires_grad=True)  |  Time needed: 0:00:09.118957  \n",
      "Run: 322\t| Iteration: 200 \t| Log-Likelihood:-3.190462743970864 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.107109  \n",
      "Run: 322\t| Iteration: 300 \t| Log-Likelihood:-3.190462732739551 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.150217  \n",
      "Run: 322\t| Iteration: 400 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.089303  \n",
      "Run: 322\t| Iteration: 500 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.104928  \n",
      "Run: 322\t| Iteration: 600 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.113368  \n",
      "Run: 322\t| Iteration: 700 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.119257  \n",
      "Run: 322\t| Iteration: 800 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.086250  \n",
      "Run: 322\t| Iteration: 900 \t| Log-Likelihood:-3.190462702927815 \t|  theta: tensor([[0.4329, 1.0570]], requires_grad=True)  |  Time needed: 0:00:09.205488  \n",
      "Run: 323\t| Iteration: 0 \t| Log-Likelihood:-3.372498511253717 \t|  theta: tensor([[0.2406, 2.7463]], requires_grad=True)  |  Time needed: 0:00:00.094152  \n",
      "Run: 323\t| Iteration: 100 \t| Log-Likelihood:-3.190612688986933 \t|  theta: tensor([[0.0501, 2.9262]], requires_grad=True)  |  Time needed: 0:00:09.204367  \n",
      "Run: 323\t| Iteration: 200 \t| Log-Likelihood:-3.187512989602248 \t|  theta: tensor([[0.0501, 2.9781]], requires_grad=True)  |  Time needed: 0:00:09.119194  \n",
      "Run: 323\t| Iteration: 300 \t| Log-Likelihood:-3.1872601333549353 \t|  theta: tensor([[0.0501, 2.9930]], requires_grad=True)  |  Time needed: 0:00:09.184020  \n",
      "Run: 323\t| Iteration: 400 \t| Log-Likelihood:-3.1872395537794147 \t|  theta: tensor([[0.0501, 2.9972]], requires_grad=True)  |  Time needed: 0:00:09.180924  \n",
      "Run: 323\t| Iteration: 500 \t| Log-Likelihood:-3.1872378635631065 \t|  theta: tensor([[0.0501, 2.9984]], requires_grad=True)  |  Time needed: 0:00:09.099690  \n",
      "Run: 323\t| Iteration: 600 \t| Log-Likelihood:-3.187237727281087 \t|  theta: tensor([[0.0501, 2.9987]], requires_grad=True)  |  Time needed: 0:00:09.178039  \n",
      "Run: 323\t| Iteration: 700 \t| Log-Likelihood:-3.1872377310961695 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.114938  \n",
      "Run: 323\t| Iteration: 800 \t| Log-Likelihood:-3.187237737599123 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.118719  \n",
      "Run: 323\t| Iteration: 900 \t| Log-Likelihood:-3.187237737584247 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.159000  \n",
      "Run: 324\t| Iteration: 0 \t| Log-Likelihood:-4.585255105115773 \t|  theta: tensor([[0.3636, 4.3069]], requires_grad=True)  |  Time needed: 0:00:00.092390  \n",
      "Run: 324\t| Iteration: 100 \t| Log-Likelihood:-3.2756056206096447 \t|  theta: tensor([[0.0501, 3.3703]], requires_grad=True)  |  Time needed: 0:00:09.119137  \n",
      "Run: 324\t| Iteration: 200 \t| Log-Likelihood:-3.194379806522781 \t|  theta: tensor([[0.0501, 3.1046]], requires_grad=True)  |  Time needed: 0:00:09.170129  \n",
      "Run: 324\t| Iteration: 300 \t| Log-Likelihood:-3.1878178003260778 \t|  theta: tensor([[0.0501, 3.0290]], requires_grad=True)  |  Time needed: 0:00:09.130704  \n",
      "Run: 324\t| Iteration: 400 \t| Log-Likelihood:-3.187284901318997 \t|  theta: tensor([[0.0501, 3.0075]], requires_grad=True)  |  Time needed: 0:00:09.120421  \n",
      "Run: 324\t| Iteration: 500 \t| Log-Likelihood:-3.187241548472708 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.155893  \n",
      "Run: 324\t| Iteration: 600 \t| Log-Likelihood:-3.1872380677423755 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.170560  \n",
      "Run: 324\t| Iteration: 700 \t| Log-Likelihood:-3.1872377553477054 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.333764  \n",
      "Run: 324\t| Iteration: 800 \t| Log-Likelihood:-3.187237765707065 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.159569  \n",
      "Run: 324\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563469474 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.225568  \n",
      "Run: 325\t| Iteration: 0 \t| Log-Likelihood:-4.417269320172261 \t|  theta: tensor([[0.2591, 4.2867]], requires_grad=True)  |  Time needed: 0:00:00.090840  \n",
      "Run: 325\t| Iteration: 100 \t| Log-Likelihood:-3.2728912089936992 \t|  theta: tensor([[0.0501, 3.3645]], requires_grad=True)  |  Time needed: 0:00:09.059778  \n",
      "Run: 325\t| Iteration: 200 \t| Log-Likelihood:-3.194160873920574 \t|  theta: tensor([[0.0501, 3.1029]], requires_grad=True)  |  Time needed: 0:00:09.093962  \n",
      "Run: 325\t| Iteration: 300 \t| Log-Likelihood:-3.1878000268468094 \t|  theta: tensor([[0.0501, 3.0285]], requires_grad=True)  |  Time needed: 0:00:09.130137  \n",
      "Run: 325\t| Iteration: 400 \t| Log-Likelihood:-3.1872834863572432 \t|  theta: tensor([[0.0501, 3.0073]], requires_grad=True)  |  Time needed: 0:00:09.079136  \n",
      "Run: 325\t| Iteration: 500 \t| Log-Likelihood:-3.187241485723293 \t|  theta: tensor([[0.0501, 3.0013]], requires_grad=True)  |  Time needed: 0:00:09.271039  \n",
      "Run: 325\t| Iteration: 600 \t| Log-Likelihood:-3.1872380554608806 \t|  theta: tensor([[0.0501, 2.9996]], requires_grad=True)  |  Time needed: 0:00:09.365752  \n",
      "Run: 325\t| Iteration: 700 \t| Log-Likelihood:-3.1872377509093974 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.045019  \n",
      "Run: 325\t| Iteration: 800 \t| Log-Likelihood:-3.187237765638609 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.076749  \n",
      "Run: 325\t| Iteration: 900 \t| Log-Likelihood:-3.187237756341774 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.111976  \n",
      "Run: 326\t| Iteration: 0 \t| Log-Likelihood:-4.514105037342361 \t|  theta: tensor([[0.3690, 4.2590]], requires_grad=True)  |  Time needed: 0:00:00.093169  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 326\t| Iteration: 100 \t| Log-Likelihood:-3.269254812204426 \t|  theta: tensor([[0.0501, 3.3567]], requires_grad=True)  |  Time needed: 0:00:09.287728  \n",
      "Run: 326\t| Iteration: 200 \t| Log-Likelihood:-3.1938675946095576 \t|  theta: tensor([[0.0501, 3.1007]], requires_grad=True)  |  Time needed: 0:00:09.419726  \n",
      "Run: 326\t| Iteration: 300 \t| Log-Likelihood:-3.187776237830788 \t|  theta: tensor([[0.0501, 3.0279]], requires_grad=True)  |  Time needed: 0:00:09.357100  \n",
      "Run: 326\t| Iteration: 400 \t| Log-Likelihood:-3.1872815198717155 \t|  theta: tensor([[0.0501, 3.0072]], requires_grad=True)  |  Time needed: 0:00:09.296988  \n",
      "Run: 326\t| Iteration: 500 \t| Log-Likelihood:-3.187241318068376 \t|  theta: tensor([[0.0501, 3.0012]], requires_grad=True)  |  Time needed: 0:00:09.288499  \n",
      "Run: 326\t| Iteration: 600 \t| Log-Likelihood:-3.1872380382124006 \t|  theta: tensor([[0.0501, 2.9995]], requires_grad=True)  |  Time needed: 0:00:09.273437  \n",
      "Run: 326\t| Iteration: 700 \t| Log-Likelihood:-3.1872377498590043 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.301788  \n",
      "Run: 326\t| Iteration: 800 \t| Log-Likelihood:-3.187237765554633 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.296892  \n",
      "Run: 326\t| Iteration: 900 \t| Log-Likelihood:-3.1872377563316383 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.285461  \n",
      "Run: 327\t| Iteration: 0 \t| Log-Likelihood:-4.909547292842554 \t|  theta: tensor([[0.3980, 4.4605]], requires_grad=True)  |  Time needed: 0:00:00.089051  \n",
      "Run: 327\t| Iteration: 100 \t| Log-Likelihood:-3.297568373399907 \t|  theta: tensor([[0.0501, 3.4138]], requires_grad=True)  |  Time needed: 0:00:09.171499  \n",
      "Run: 327\t| Iteration: 200 \t| Log-Likelihood:-3.1961503741739814 \t|  theta: tensor([[0.0501, 3.1169]], requires_grad=True)  |  Time needed: 0:00:09.200456  \n",
      "Run: 327\t| Iteration: 300 \t| Log-Likelihood:-3.1879613607012227 \t|  theta: tensor([[0.0501, 3.0325]], requires_grad=True)  |  Time needed: 0:00:09.233339  \n",
      "Run: 327\t| Iteration: 400 \t| Log-Likelihood:-3.187296548757015 \t|  theta: tensor([[0.0501, 3.0085]], requires_grad=True)  |  Time needed: 0:00:09.671486  \n",
      "Run: 327\t| Iteration: 500 \t| Log-Likelihood:-3.1872425493058083 \t|  theta: tensor([[0.0501, 3.0016]], requires_grad=True)  |  Time needed: 0:00:10.115720  \n",
      "Run: 327\t| Iteration: 600 \t| Log-Likelihood:-3.1872381572777675 \t|  theta: tensor([[0.0501, 2.9997]], requires_grad=True)  |  Time needed: 0:00:09.215403  \n",
      "Run: 327\t| Iteration: 700 \t| Log-Likelihood:-3.18723776554563 \t|  theta: tensor([[0.0501, 2.9991]], requires_grad=True)  |  Time needed: 0:00:09.211018  \n",
      "Run: 327\t| Iteration: 800 \t| Log-Likelihood:-3.187237766198799 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.258734  \n",
      "Run: 327\t| Iteration: 900 \t| Log-Likelihood:-3.187237756396702 \t|  theta: tensor([[0.0501, 2.9989]], requires_grad=True)  |  Time needed: 0:00:09.184212  \n",
      "Run: 328\t| Iteration: 0 \t| Log-Likelihood:-3.8235566118729087 \t|  theta: tensor([[0.2905, 1.8749]], requires_grad=True)  |  Time needed: 0:00:00.093596  \n",
      "Run: 328\t| Iteration: 100 \t| Log-Likelihood:-3.464304863389587 \t|  theta: tensor([[0.0575, 2.3143]], requires_grad=True)  |  Time needed: 0:00:09.265895  \n",
      "Run: 328\t| Iteration: 200 \t| Log-Likelihood:-3.214863458420754 \t|  theta: tensor([[0.0502, 2.7904]], requires_grad=True)  |  Time needed: 0:00:09.156021  \n",
      "Run: 328\t| Iteration: 300 \t| Log-Likelihood:-3.189519121967616 \t|  theta: tensor([[0.0501, 2.9391]], requires_grad=True)  |  Time needed: 0:00:09.494794  \n",
      "Run: 328\t| Iteration: 400 \t| Log-Likelihood:-3.187423654323143 \t|  theta: tensor([[0.0501, 2.9818]], requires_grad=True)  |  Time needed: 0:00:10.151278  \n",
      "Run: 328\t| Iteration: 500 \t| Log-Likelihood:-3.1872528769824804 \t|  theta: tensor([[0.0501, 2.9940]], requires_grad=True)  |  Time needed: 0:00:09.690277  \n",
      "Run: 328\t| Iteration: 600 \t| Log-Likelihood:-3.1872389627686375 \t|  theta: tensor([[0.0501, 2.9975]], requires_grad=True)  |  Time needed: 0:00:09.559368  \n",
      "Run: 328\t| Iteration: 700 \t| Log-Likelihood:-3.187237830373112 \t|  theta: tensor([[0.0501, 2.9985]], requires_grad=True)  |  Time needed: 0:00:09.528310  \n",
      "Run: 328\t| Iteration: 800 \t| Log-Likelihood:-3.187237727082218 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.553749  \n",
      "Run: 328\t| Iteration: 900 \t| Log-Likelihood:-3.1872377344832032 \t|  theta: tensor([[0.0501, 2.9988]], requires_grad=True)  |  Time needed: 0:00:09.476584  \n",
      "Run: 329\t| Iteration: 0 \t| Log-Likelihood:-3.3463653972585834 \t|  theta: tensor([[0.2522, 3.0374]], requires_grad=True)  |  Time needed: 0:00:00.094887  \n",
      "Run: 329\t| Iteration: 100 \t| Log-Likelihood:-3.1873145560424265 \t|  theta: tensor([[0.0501, 3.0098]], requires_grad=True)  |  Time needed: 0:00:11.382911  \n",
      "Run: 329\t| Iteration: 200 \t| Log-Likelihood:-3.1872439698510515 \t|  theta: tensor([[0.0501, 3.0020]], requires_grad=True)  |  Time needed: 0:00:09.958335  \n",
      "Run: 329\t| Iteration: 300 \t| Log-Likelihood:-3.1872382388779643 \t|  theta: tensor([[0.0501, 2.9998]], requires_grad=True)  |  Time needed: 0:00:12.363495  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-988a3c7759ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                            \u001b[0mlearningrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                            \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                            print_info=True)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_gt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MaastrichtDKEGroup2/Auxillaries.py\u001b[0m in \u001b[0;36mgradient_ascent_torch\u001b[0;34m(func, param, data, max_iterations, learningrate, run_id, print_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Evaluate loglikelihood of each data point: L(param | X_i) for all i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mloglikelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# has dimension 1 x num_data_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Build mean of all log-likelihoods to get actual loglikelihood value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dabee8bcf717>\u001b[0m in \u001b[0;36mLogLikelihood\u001b[0;34m(theta, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     '''\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mg_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mlog_g_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MaastrichtDKEGroup2/Auxillaries.py\u001b[0m in \u001b[0;36mphi_torch\u001b[0;34m(x, mu, sigma)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# Calculating and returning probs via: prob = exp(log_prob)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Ascent\n",
    "'''\n",
    "theta_gt = np.array([[0.4309934, 1.0573411]])\n",
    "theta_loc = theta_loc\n",
    "#X = torch.from_numpy(X)\n",
    "# Set parameters here\n",
    "n_iterations = 5000 #max number of iterations # TODO: alternatively/ additionally a error-based threshold?\n",
    "lr = 0.01 # learning rate / stepsize\n",
    "n_runs =1000\n",
    "\n",
    "# Initializing Loss as minus infinity to make sure first run achieves higher likelihood\n",
    "max_likelihood = -1*np.inf\n",
    "# trajectory_dict is a cache to save the gradient ascent trajectory of all gradient ascent runs\n",
    "trajectory_dict = {}\n",
    "\n",
    "glob_max_counter = 0\n",
    "loc_max_counter = 0\n",
    "rest_counter = 0\n",
    "# Running Gradient Ascent multiple (M=n_runs) times\n",
    "for run in range(n_runs):\n",
    "\n",
    "    # Create/ Initialize variable ' TODO: make initialization more flexible\n",
    "    theta = torch.tensor([[uniform.Uniform(0., .6).sample(), uniform.Uniform(0., 5.).sample()]], requires_grad = True)\n",
    "\n",
    "    # Run complete Gradient ascent\n",
    "    theta, L, trajectory = gradient_ascent_torch(func = LogLikelihood,\n",
    "                                           param=theta,\n",
    "                                           data=X,\n",
    "                                           max_iterations=1000,\n",
    "                                           learningrate=lr,\n",
    "                                           run_id=run,\n",
    "                                           print_info=True)\n",
    "\n",
    "    if np.linalg.norm(theta_gt-theta.clone().data.numpy())<0.1:\n",
    "        glob_max_counter+=1\n",
    "    elif np.linalg.norm(theta_loc-theta.clone().data.numpy())<0.1:\n",
    "        loc_max_counter+=1\n",
    "    else:\n",
    "        rest_counter +=1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated q_1: 0.3597560975609756\n",
      "\n",
      "Estimated q_2: 0.6402439024390244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = glob_max_counter+ loc_max_counter+ rest_counter\n",
    "print(f'Estimated q_1: {glob_max_counter/total}\\n')\n",
    "print(f'Estimated q_2: {loc_max_counter/total}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(glob_max_counter, loc_max_counter, rest_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient Ascent\n",
    "'''\n",
    "#X = torch.from_numpy(X)\n",
    "# Set parameters here\n",
    "n_iterations = 5000 #max number of iterations # TODO: alternatively/ additionally a error-based threshold?\n",
    "lr = 0.001 # learning rate / stepsize\n",
    "n_runs = 20\n",
    "\n",
    "# Initializing Loss as minus infinity to make sure first run achieves higher likelihood\n",
    "max_likelihood = -1*np.inf\n",
    "# trajectory_dict is a cache to save the gradient ascent trajectory of all gradient ascent runs\n",
    "trajectory_dict = {}\n",
    "\n",
    "# Running Gradient Ascent multiple (M=n_runs) times\n",
    "for run in range(n_runs):\n",
    "\n",
    "    # Create/ Initialize variable ' TODO: make initialization more flexible\n",
    "    theta = torch.tensor([[uniform.Uniform(0., .6).sample(),uniform.Uniform(0., 5.).sample()]], requires_grad = True)\n",
    "\n",
    "    # Run complete Gradient ascent\n",
    "    theta, L, trajectory = gradient_ascent_torch(func = LogLikelihood,\n",
    "                                           param=theta,\n",
    "                                           data=X,\n",
    "                                           max_iterations=n_iterations,\n",
    "                                           learningrate=lr,\n",
    "                                           run_id=run,\n",
    "                                           print_info=True)\n",
    "\n",
    "    # Save optimization trajectory\n",
    "    trajectory_dict.update({run : trajectory})\n",
    "    # Updating Quantities if new max is found\n",
    "\n",
    "    # compare likelihood value to previous runs\n",
    "    if L > max_likelihood:\n",
    "        # This takes forever if n is large. As it is torch implementation I don't see a way to get this faster\n",
    "        print(f'New Maximum found! old:{max_likelihood} -> new:{L}')\n",
    "\n",
    "        # Update highest likelihood and theta estimate\n",
    "        max_likelihood = L\n",
    "        theta_hat = theta.clone().data.numpy()\n",
    "\n",
    "        # get derivatives\n",
    "        Scores, Hessian = get_derivatives_torch(func=LogLikelihood,\n",
    "                                                param=theta,\n",
    "                                                data=X,\n",
    "                                                print_dims=True)\n",
    "\n",
    "\n",
    "CI = normal_CI(0.05, Scores, Hessian, theta_hat)\n",
    "\n",
    "print(f'theta:\\n {theta_hat}')\n",
    "print(f'normal CI borders:\\n {CI}')\n",
    "\n",
    "\n",
    "# Starting Plot\n",
    "if make_plots:\n",
    "    fig, ax = plt.subplots(1,1, figsize = (7,7))\n",
    "    for run in range(n_runs):\n",
    "        trajectory = trajectory_dict[run]\n",
    "        m = len(trajectory_dict[run])\n",
    "        ax.plot([trajectory[i][0,1] for i in range(m)], [trajectory[i][0,0] for i in range(m)], label = f'run: {run}')\n",
    "    ax.imshow(Colourplot, cmap='Reds', extent = [0,5,0,.6], aspect='auto') #extent = [0,5,0,6]\n",
    "    ax.set_xlabel('mu')\n",
    "    ax.set_ylabel('rho')\n",
    "    plt.title('Contourplot of Log-Likelihood function with gradient ascent trajectories')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_n_M(data, n_runs, func, max_iterations = 1000, learningrate = 0.01, print_info=True):\n",
    "    \n",
    "    # Initializing Loss as minus infinity to make sure first run achieves higher likelihood\n",
    "    max_likelihood = -1*np.inf\n",
    "    # trajectory_dict is a cache to save the gradient ascent trajectory of all gradient ascent runs\n",
    "    trajectory_dict = {}\n",
    "\n",
    "    # Running Gradient Ascent multiple (M=n_runs) times\n",
    "    for run in range(n_runs):\n",
    "\n",
    "        # Create/ Initialize variable ' TODO: make initialization more flexible\n",
    "        theta = torch.tensor([[uniform.Uniform(0., .6).sample(),uniform.Uniform(0., 5.).sample()]], requires_grad = True)\n",
    "\n",
    "        # Run complete Gradient ascent\n",
    "        theta, L, trajectory = gradient_ascent_torch(func = func,\n",
    "                                               param=theta,\n",
    "                                               data=data,\n",
    "                                               max_iterations=max_iterations,\n",
    "                                               learningrate=learningrate,\n",
    "                                               run_id=run,\n",
    "                                               print_info=print_info)\n",
    "\n",
    "        # Save optimization trajectory\n",
    "        trajectory_dict.update({run : trajectory})\n",
    "        # Updating Quantities if new max is found\n",
    "\n",
    "        # compare likelihood value to previous runs\n",
    "        if L > max_likelihood:\n",
    "            # This takes forever if n is large. As it is torch implementation I don't see a way to get this faster\n",
    "            print(f'New Maximum found! old:{max_likelihood} -> new:{L}')\n",
    "\n",
    "            # Update highest likelihood and theta estimate\n",
    "            max_likelihood = L\n",
    "            theta_hat = theta.clone().data.numpy()\n",
    "\n",
    "    # get derivatives\n",
    "    Scores, Hessian = get_derivatives_torch(func=func,\n",
    "                                            param=torch.tensor(theta_hat, requires_grad = True),\n",
    "                                            data=data,\n",
    "                                            print_dims=True)\n",
    "\n",
    "\n",
    "            \n",
    "    return theta_hat, Scores, Hessian, trajectory_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\t| Iteration: 0 \t| Log-Likelihood:-49.4559211730957 \t|  theta: tensor([[0.1246, 4.2537]], requires_grad=True)  |  Time needed: 0:00:00.001253  \n",
      "Run: 1\t| Iteration: 100 \t| Log-Likelihood:-48.80320739746094 \t|  theta: tensor([[-0.6651,  4.2537]], requires_grad=True)  |  Time needed: 0:00:00.070844  \n",
      "New Maximum found! old:-inf -> new:-48.53196334838867\n",
      "Run: 2\t| Iteration: 0 \t| Log-Likelihood:-0.2195502519607544 \t|  theta: tensor([[0.4274, 2.0008]], requires_grad=True)  |  Time needed: 0:00:00.001081  \n",
      "Run: 2\t| Iteration: 100 \t| Log-Likelihood:1.0790475606918335 \t|  theta: tensor([[1.4816, 2.0000]], requires_grad=True)  |  Time needed: 0:00:00.072013  \n",
      "New Maximum found! old:-48.53196334838867 -> new:1.4030635356903076\n",
      "Run: 3\t| Iteration: 0 \t| Log-Likelihood:-39.919315338134766 \t|  theta: tensor([[0.5263, 3.3405]], requires_grad=True)  |  Time needed: 0:00:00.001076  \n",
      "Run: 3\t| Iteration: 100 \t| Log-Likelihood:1.099851131439209 \t|  theta: tensor([[1.5125, 2.0000]], requires_grad=True)  |  Time needed: 0:00:00.066861  \n",
      "New Maximum found! old:1.4030635356903076 -> new:1.414041519165039\n",
      "Run: 4\t| Iteration: 0 \t| Log-Likelihood:-49.34818649291992 \t|  theta: tensor([[0.0276, 4.8787]], requires_grad=True)  |  Time needed: 0:00:00.001101  \n",
      "Run: 4\t| Iteration: 100 \t| Log-Likelihood:-48.771766662597656 \t|  theta: tensor([[-0.7179,  4.8787]], requires_grad=True)  |  Time needed: 0:00:00.069092  \n",
      "Run: 5\t| Iteration: 0 \t| Log-Likelihood:-2.9904119968414307 \t|  theta: tensor([[0.2005, 2.2424]], requires_grad=True)  |  Time needed: 0:00:00.001042  \n",
      "Run: 5\t| Iteration: 100 \t| Log-Likelihood:1.0471034049987793 \t|  theta: tensor([[1.4355, 2.0000]], requires_grad=True)  |  Time needed: 0:00:00.075531  \n",
      "Scores: [ 4.8389280e-01 -1.1920927e-05]\n",
      "Scores: (2,)\n",
      "Actual Gradient: 0.241940438747406 (~ 0)\n",
      "Hessian [[-2.3415226e-01  3.5433191e-13]\n",
      " [ 4.5474735e-13 -2.4999996e+01]]\n",
      "Hessian shape (2, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Gradient Ascent\n",
    "'''\n",
    "X2 = gaussian_mixture_model_sample(10**6, means, covs, weights, test=False) # we can alternatively use pytorchs MixtureFamily\n",
    "X2 = torch.from_numpy(X2)\n",
    "\n",
    "theta_hat_test, Scores_test, Hessian_test, trajectory_dict_test = theta_n_M(data = 2,\n",
    "                                                                            n_runs = 5,\n",
    "                                                                            func = LogLikelihood,\n",
    "                                                                            max_iterations = 200,\n",
    "                                                                            learningrate = 0.01,\n",
    "                                                                            print_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
